#!/usr/bin/env python3
"""
ì‹œê°„ì  ì˜ë£Œ ë¶„ì„ ì‹œìŠ¤í…œ (Temporal Medical Analysis)

ì‹œê°„ì  ì˜ë£Œ ë¶„ì„ì€ ì˜ë£Œ ì˜ìƒì´ë‚˜ ì‹ í˜¸ì˜ ì‹œê³„ì—´ ë³€í™”ë¥¼ ë¶„ì„í•˜ì—¬
ì§ˆë³‘ì˜ ì§„í–‰, ì¹˜ë£Œ ë°˜ì‘, ì˜ˆí›„ ë“±ì„ ì˜ˆì¸¡í•˜ëŠ” ì¤‘ìš”í•œ ê¸°ìˆ ì…ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
- ì§ˆë³‘ ì§„í–‰ ëª¨ë‹ˆí„°ë§ (Disease Progression Monitoring)
- ì¹˜ë£Œ ë°˜ì‘ í‰ê°€ (Treatment Response Assessment)
- ì‹œê³„ì—´ ì˜ìƒ ë¶„ì„ (Longitudinal Image Analysis)
- ì˜ˆí›„ ì˜ˆì¸¡ (Prognosis Prediction)
- ë™ì  ê¸°ëŠ¥ ë¶„ì„ (Dynamic Function Analysis)
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torchvision.transforms as transforms
from torch.utils.data import Dataset, DataLoader
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import os
import sys
from sklearn.metrics import mean_squared_error, r2_score
sys.path.append('/workspace/Vision-101')
from medical.result_logger import create_logger_for_temporal_medical

class TemporalMedicalDataset(Dataset):
    def __init__(self, data_type='cardiac_monitoring', sequence_length=10, transform=None):
        """
        ì‹œê°„ì  ì˜ë£Œ ë°ì´í„°ì…‹

        Args:
            data_type: 'cardiac_monitoring', 'tumor_tracking', 'lung_function', 'brain_activity'
            sequence_length: ì‹œê³„ì—´ ê¸¸ì´
            transform: ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        """
        self.data_type = data_type
        self.sequence_length = sequence_length
        self.transform = transform or transforms.Compose([
            transforms.Resize((128, 128)),
            transforms.ToTensor(),
            transforms.Normalize([0.5], [0.5])
        ])

        # ì‹œê°„ì  ì˜ë£Œ ë°ì´í„° ìƒì„±
        self.sequences = self._generate_temporal_sequences()

    def _generate_temporal_sequences(self):
        """ì‹œê°„ì  ì˜ë£Œ ì‹œí€€ìŠ¤ ìƒì„±"""
        sequences = []

        for i in range(300):  # 300ê°œì˜ í™˜ì/ì¼€ì´ìŠ¤
            sequence = self._create_temporal_sequence(i)
            sequences.append(sequence)

        return sequences

    def _create_temporal_sequence(self, patient_id):
        """í™˜ìë³„ ì‹œê°„ì  ì‹œí€€ìŠ¤ ìƒì„±"""
        np.random.seed(patient_id)

        if self.data_type == 'cardiac_monitoring':
            return self._create_cardiac_sequence(patient_id)
        elif self.data_type == 'tumor_tracking':
            return self._create_tumor_sequence(patient_id)
        elif self.data_type == 'lung_function':
            return self._create_lung_sequence(patient_id)
        else:  # brain_activity
            return self._create_brain_sequence(patient_id)

    def _create_cardiac_sequence(self, patient_id):
        """ì‹¬ì¥ ê¸°ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œí€€ìŠ¤"""
        np.random.seed(patient_id)

        # í™˜ì íŠ¹ì„±
        age = np.random.randint(40, 85)
        gender = np.random.choice([0, 1])
        baseline_ef = np.random.uniform(35, 70)  # ê¸°ì¤€ êµ¬í˜ˆë¥ 

        # ì¹˜ë£Œ ì‹œë‚˜ë¦¬ì˜¤ ì„¤ì •
        treatment_type = np.random.choice(['medication', 'intervention', 'surgery'])
        treatment_start_time = np.random.randint(2, 5)  # ì¹˜ë£Œ ì‹œì‘ ì‹œì 

        images = []
        measurements = []
        timestamps = []

        for t in range(self.sequence_length):
            # ì‹œê°„ ê²½ê³¼ì— ë”°ë¥¸ ë³€í™” ëª¨ë¸ë§
            time_factor = t / (self.sequence_length - 1)

            # ì¹˜ë£Œ íš¨ê³¼ ëª¨ë¸ë§
            if t >= treatment_start_time:
                treatment_time = t - treatment_start_time
                if treatment_type == 'medication':
                    # ì ì§„ì  ê°œì„ 
                    improvement = min(0.15, treatment_time * 0.03)
                elif treatment_type == 'intervention':
                    # ë¹ ë¥¸ ê°œì„  í›„ ì•ˆì •í™”
                    improvement = 0.2 * (1 - np.exp(-treatment_time * 0.8))
                else:  # surgery
                    # ì´ˆê¸° ì•…í™” í›„ í° ê°œì„ 
                    if treatment_time < 2:
                        improvement = -0.1 + treatment_time * 0.05
                    else:
                        improvement = 0.25
            else:
                improvement = 0

            # ë…¸í™”/ì§ˆë³‘ ì§„í–‰ì— ë”°ë¥¸ ìì—°ì  ì•…í™”
            natural_decline = time_factor * np.random.uniform(0.05, 0.15)

            # í˜„ì¬ êµ¬í˜ˆë¥ 
            current_ef = baseline_ef + improvement - natural_decline + np.random.normal(0, 2)
            current_ef = np.clip(current_ef, 20, 80)

            # ì‹¬ì¥ ì´ˆìŒíŒŒ ì´ë¯¸ì§€ ìƒì„±
            echo_image = self._generate_cardiac_echo(patient_id + t * 1000, current_ef)
            images.append(echo_image)

            # ì¸¡ì •ê°’ë“¤
            measurements.append({
                'ejection_fraction': current_ef,
                'lv_diameter': 45 + (70 - current_ef) * 0.3 + np.random.normal(0, 2),
                'wall_thickness': 9 + (current_ef < 50) * 3 + np.random.normal(0, 1),
                'cardiac_output': current_ef * 0.08 + np.random.normal(0, 0.2)
            })

            timestamps.append(t * 30)  # 30ì¼ ê°„ê²©

        # ì˜ˆí›„ ì˜ˆì¸¡ (6ê°œì›” í›„ ì£¼ìš” ì‹¬í˜ˆê´€ ì‚¬ê±´ ìœ„í—˜)
        final_ef = measurements[-1]['ejection_fraction']
        risk_score = (
            (age > 70) * 0.2 +
            (gender == 1) * 0.1 +
            (final_ef < 40) * 0.4 +
            (final_ef < 30) * 0.3
        )
        prognosis_risk = min(1.0, risk_score + np.random.normal(0, 0.1))

        return {
            'patient_id': patient_id,
            'images': images,
            'measurements': measurements,
            'timestamps': timestamps,
            'demographics': [age, gender],
            'treatment_type': ['medication', 'intervention', 'surgery'].index(treatment_type),
            'treatment_start': treatment_start_time,
            'baseline_ef': baseline_ef,
            'final_ef': final_ef,
            'prognosis_risk': prognosis_risk
        }

    def _create_tumor_sequence(self, patient_id):
        """ì¢…ì–‘ ì¶”ì  ì‹œí€€ìŠ¤"""
        np.random.seed(patient_id)

        # ì¢…ì–‘ íŠ¹ì„±
        initial_size = np.random.uniform(10, 50)  # mm
        growth_rate = np.random.uniform(-0.1, 0.3)  # ì¹˜ë£Œ ë°˜ì‘ì— ë”°ë¼ ìŒìˆ˜ë„ ê°€ëŠ¥
        tumor_type = np.random.choice(['aggressive', 'moderate', 'slow'])

        # ì¹˜ë£Œ ì‹œì‘
        chemo_start = np.random.randint(1, 4)

        images = []
        measurements = []
        timestamps = []

        for t in range(self.sequence_length):
            # ì¢…ì–‘ í¬ê¸° ë³€í™” ëª¨ë¸ë§
            if t >= chemo_start:
                # ì¹˜ë£Œ íš¨ê³¼
                treatment_time = t - chemo_start
                if tumor_type == 'aggressive':
                    size_change = -0.2 * treatment_time + 0.05 * t  # ì´ˆê¸° ë°˜ì‘ í›„ ì €í•­ì„±
                elif tumor_type == 'moderate':
                    size_change = -0.15 * treatment_time
                else:  # slow
                    size_change = -0.1 * treatment_time
            else:
                # ìì—° ì„±ì¥
                size_change = growth_rate * t

            current_size = max(5, initial_size + size_change + np.random.normal(0, 1))

            # CT ì´ë¯¸ì§€ ìƒì„±
            ct_image = self._generate_tumor_ct(patient_id + t * 1000, current_size)
            images.append(ct_image)

            measurements.append({
                'tumor_size': current_size,
                'volume': (current_size / 10) ** 3 * 4/3 * np.pi,
                'density': 45 + np.random.normal(0, 5),
                'enhancement': np.random.uniform(20, 60)
            })

            timestamps.append(t * 60)  # 60ì¼ ê°„ê²©

        # ì¹˜ë£Œ ë°˜ì‘ í‰ê°€
        size_reduction = (initial_size - current_size) / initial_size
        if size_reduction > 0.3:
            response = 2  # ë¶€ë¶„ ê´€í•´
        elif size_reduction > 0.1:
            response = 1  # ì•ˆì •
        else:
            response = 0  # ì§„í–‰

        return {
            'patient_id': patient_id,
            'images': images,
            'measurements': measurements,
            'timestamps': timestamps,
            'tumor_type': ['aggressive', 'moderate', 'slow'].index(tumor_type),
            'initial_size': initial_size,
            'final_size': current_size,
            'treatment_response': response,
            'prognosis_risk': max(0, 1 - size_reduction)
        }

    def _create_lung_sequence(self, patient_id):
        """í ê¸°ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œí€€ìŠ¤"""
        np.random.seed(patient_id)

        # ê¸°ì¤€ í ê¸°ëŠ¥
        baseline_fev1 = np.random.uniform(60, 120)  # % predicted
        disease_type = np.random.choice(['copd', 'fibrosis', 'normal'])

        images = []
        measurements = []
        timestamps = []

        for t in range(self.sequence_length):
            # ì§ˆë³‘ë³„ ì§„í–‰ íŒ¨í„´
            if disease_type == 'copd':
                # COPD: ì ì§„ì  ì•…í™”
                decline_rate = 0.02 + np.random.uniform(0, 0.01)
                current_fev1 = baseline_fev1 * (1 - decline_rate * t)
            elif disease_type == 'fibrosis':
                # ì„¬ìœ í™”: ë¹„ì„ í˜•ì  ì•…í™”
                progression = 1 - 0.3 * (1 - np.exp(-t * 0.3))
                current_fev1 = baseline_fev1 * progression
            else:  # normal
                # ì •ìƒ: ì—°ë ¹ì— ë”°ë¥¸ ìì—°ìŠ¤ëŸ¬ìš´ ê°ì†Œ
                current_fev1 = baseline_fev1 * (1 - 0.005 * t)

            current_fev1 += np.random.normal(0, 2)
            current_fev1 = max(20, current_fev1)

            # í‰ë¶€ CT ìƒì„±
            lung_ct = self._generate_lung_ct(patient_id + t * 1000, current_fev1, disease_type)
            images.append(lung_ct)

            measurements.append({
                'fev1': current_fev1,
                'fvc': current_fev1 * np.random.uniform(1.1, 1.3),
                'dlco': current_fev1 * np.random.uniform(0.8, 1.2),
                'lung_volume': 4500 + np.random.normal(0, 200)
            })

            timestamps.append(t * 90)  # 90ì¼ ê°„ê²©

        return {
            'patient_id': patient_id,
            'images': images,
            'measurements': measurements,
            'timestamps': timestamps,
            'disease_type': ['copd', 'fibrosis', 'normal'].index(disease_type),
            'baseline_fev1': baseline_fev1,
            'final_fev1': current_fev1,
            'decline_rate': (baseline_fev1 - current_fev1) / baseline_fev1,
            'prognosis_risk': max(0, 1 - current_fev1 / 80)
        }

    def _create_brain_sequence(self, patient_id):
        """ë‡Œ í™œë™ ëª¨ë‹ˆí„°ë§ ì‹œí€€ìŠ¤"""
        np.random.seed(patient_id)

        # ë‡Œ ìƒíƒœ ì„¤ì •
        condition = np.random.choice(['dementia', 'stroke_recovery', 'normal_aging'])
        baseline_score = np.random.uniform(70, 95)  # ì¸ì§€ ê¸°ëŠ¥ ì ìˆ˜

        images = []
        measurements = []
        timestamps = []

        for t in range(self.sequence_length):
            if condition == 'dementia':
                # ì¹˜ë§¤: ì ì§„ì  ì•…í™”
                current_score = baseline_score * np.exp(-0.05 * t)
            elif condition == 'stroke_recovery':
                # ë‡Œì¡¸ì¤‘ íšŒë³µ: ì´ˆê¸° ê°œì„  í›„ ì•ˆì •í™”
                recovery = 0.3 * (1 - np.exp(-t * 0.3))
                current_score = baseline_score * (0.7 + recovery)
            else:  # normal_aging
                # ì •ìƒ ë…¸í™”
                current_score = baseline_score * (1 - 0.01 * t)

            current_score += np.random.normal(0, 2)
            current_score = max(10, min(100, current_score))

            # MRI ì´ë¯¸ì§€ ìƒì„±
            brain_mri = self._generate_brain_mri(patient_id + t * 1000, current_score, condition)
            images.append(brain_mri)

            measurements.append({
                'cognitive_score': current_score,
                'brain_volume': 1200 - (100 - current_score) * 2 + np.random.normal(0, 20),
                'white_matter_integrity': current_score * 0.8 + np.random.normal(0, 3),
                'hippocampal_volume': 4000 - (100 - current_score) * 10 + np.random.normal(0, 50)
            })

            timestamps.append(t * 180)  # 180ì¼ ê°„ê²©

        return {
            'patient_id': patient_id,
            'images': images,
            'measurements': measurements,
            'timestamps': timestamps,
            'condition': ['dementia', 'stroke_recovery', 'normal_aging'].index(condition),
            'baseline_score': baseline_score,
            'final_score': current_score,
            'cognitive_decline': (baseline_score - current_score) / baseline_score,
            'prognosis_risk': max(0, 1 - current_score / 70)
        }

    def _generate_cardiac_echo(self, seed, ejection_fraction):
        """ì‹¬ì¥ ì´ˆìŒíŒŒ ì´ë¯¸ì§€ ìƒì„±"""
        np.random.seed(seed)
        image = np.zeros((128, 128))

        # ì‹¬ì¥ ìœ¤ê³½ (êµ¬í˜ˆë¥ ì— ë”°ë¼ í¬ê¸° ì¡°ì ˆ)
        center_x, center_y = 64, 70
        radius = 25 + (70 - ejection_fraction) * 0.3

        for y in range(128):
            for x in range(128):
                dist = np.sqrt((x - center_x)**2 + (y - center_y)**2)
                if dist <= radius:
                    # ì‹¬ê·¼ë²½
                    wall_thickness = 4 + (ejection_fraction < 50) * 2
                    if dist > radius - wall_thickness:
                        image[y, x] = 0.7  # ì‹¬ê·¼
                    else:
                        image[y, x] = 0.2  # ì‹¬ì‹¤ ë‚´ê°•

        # íŒë§‰ êµ¬ì¡°
        valve_y = center_y - 15
        image[valve_y:valve_y + 2, center_x - 8:center_x + 8] = 0.9

        # ìŠ¤í˜í´ ë…¸ì´ì¦ˆ
        image += np.random.exponential(0.05, (128, 128))
        image = np.clip(image, 0, 1)

        # RGBë¡œ ë³€í™˜
        return np.stack([image] * 3, axis=2)

    def _generate_tumor_ct(self, seed, tumor_size):
        """ì¢…ì–‘ CT ì´ë¯¸ì§€ ìƒì„±"""
        np.random.seed(seed)
        image = np.random.normal(0.3, 0.1, (128, 128))

        # ì¢…ì–‘ ìœ„ì¹˜
        tumor_x = np.random.randint(30, 98)
        tumor_y = np.random.randint(30, 98)
        tumor_radius = tumor_size / 5  # í”½ì…€ ë‹¨ìœ„ë¡œ ë³€í™˜

        # ì¢…ì–‘ ê·¸ë¦¬ê¸°
        for y in range(128):
            for x in range(128):
                dist = np.sqrt((x - tumor_x)**2 + (y - tumor_y)**2)
                if dist <= tumor_radius:
                    # ì¢…ì–‘ ë‚´ë¶€ ë¶ˆê· ì§ˆì„±
                    intensity = 0.6 + 0.2 * np.sin(dist * 0.5) + np.random.normal(0, 0.1)
                    image[y, x] = intensity

        image = np.clip(image, 0, 1)
        return np.stack([image] * 3, axis=2)

    def _generate_lung_ct(self, seed, fev1, disease_type):
        """í CT ì´ë¯¸ì§€ ìƒì„±"""
        np.random.seed(seed)
        image = np.random.normal(0.2, 0.05, (128, 128))

        # íì•¼ ì˜ì—­
        lung_intensity = 0.1 + (100 - fev1) * 0.005

        # ì§ˆë³‘ë³„ íŒ¨í„´
        if disease_type == 'copd':
            # ê¸°ì¢… íŒ¨í„´ (ì €ë°€ë„ ì˜ì—­)
            for _ in range(int((100 - fev1) * 2)):
                emp_x = np.random.randint(20, 108)
                emp_y = np.random.randint(20, 108)
                emp_size = np.random.randint(5, 15)
                image[emp_y:emp_y+emp_size, emp_x:emp_x+emp_size] = 0.05

        elif disease_type == 'fibrosis':
            # ì„¬ìœ í™” íŒ¨í„´ (ê³ ë°€ë„ ì˜ì—­)
            for _ in range(int((100 - fev1) * 1.5)):
                fib_x = np.random.randint(20, 108)
                fib_y = np.random.randint(80, 108)  # í•˜ì—½ ìš°ì„¸
                fib_size = np.random.randint(3, 8)
                image[fib_y:fib_y+fib_size, fib_x:fib_x+fib_size] = 0.8

        image = np.clip(image, 0, 1)
        return np.stack([image] * 3, axis=2)

    def _generate_brain_mri(self, seed, cognitive_score, condition):
        """ë‡Œ MRI ì´ë¯¸ì§€ ìƒì„±"""
        np.random.seed(seed)
        image = np.zeros((128, 128))

        # ê¸°ë³¸ ë‡Œ êµ¬ì¡°
        center_x, center_y = 64, 64
        brain_radius = 55

        for y in range(128):
            for x in range(128):
                dist = np.sqrt((x - center_x)**2 + (y - center_y)**2)
                if dist <= brain_radius:
                    if dist < 35:
                        image[y, x] = 0.6  # íšŒë°±ì§ˆ
                    else:
                        image[y, x] = 0.4  # ë°±ì§ˆ

        # ë³‘ë¦¬í•™ì  ë³€í™”
        atrophy_factor = (100 - cognitive_score) * 0.01

        if condition == 'dementia':
            # ì¸¡ë‘ì—½ ìœ„ì¶•
            for y in range(40, 80):
                for x in range(30, 50):
                    image[y, x] *= (1 - atrophy_factor)

        elif condition == 'stroke_recovery':
            # êµ­ì†Œì  ì†ìƒ
            lesion_x = np.random.randint(45, 75)
            lesion_y = np.random.randint(45, 75)
            lesion_size = 8
            for y in range(lesion_y, lesion_y + lesion_size):
                for x in range(lesion_x, lesion_x + lesion_size):
                    if 0 <= y < 128 and 0 <= x < 128:
                        image[y, x] = 0.1  # ê²½ìƒ‰ ë¶€ìœ„

        image = np.clip(image, 0, 1)
        return np.stack([image] * 3, axis=2)

    def __len__(self):
        return len(self.sequences)

    def __getitem__(self, idx):
        sequence = self.sequences[idx]

        # ì´ë¯¸ì§€ ì‹œí€€ìŠ¤ ì²˜ë¦¬
        image_sequence = []
        for img_array in sequence['images']:
            img = Image.fromarray((img_array * 255).astype(np.uint8))
            if self.transform:
                img = self.transform(img)
            image_sequence.append(img)

        image_sequence = torch.stack(image_sequence)  # [seq_len, C, H, W]

        # ì¸¡ì •ê°’ ì‹œí€€ìŠ¤ ì²˜ë¦¬
        measurement_sequence = []
        measurement_keys = list(sequence['measurements'][0].keys())

        for measurements in sequence['measurements']:
            values = [measurements[key] for key in measurement_keys]
            measurement_sequence.append(values)

        measurement_sequence = torch.tensor(measurement_sequence, dtype=torch.float32)

        # ì‹œê°„ ì •ë³´
        timestamps = torch.tensor(sequence['timestamps'], dtype=torch.float32)

        # ê¸°íƒ€ ë©”íƒ€ ì •ë³´
        patient_info = []
        if 'demographics' in sequence:
            patient_info.extend(sequence['demographics'])
        if 'treatment_type' in sequence:
            patient_info.append(sequence['treatment_type'])
        if 'disease_type' in sequence:
            patient_info.append(sequence['disease_type'])
        if 'condition' in sequence:
            patient_info.append(sequence['condition'])

        patient_info = torch.tensor(patient_info, dtype=torch.float32) if patient_info else torch.tensor([0.0])

        return {
            'images': image_sequence,
            'measurements': measurement_sequence,
            'timestamps': timestamps,
            'patient_info': patient_info,
            'prognosis_risk': torch.tensor(sequence['prognosis_risk'], dtype=torch.float32),
            'sequence_info': sequence
        }

# ì‹œê°„ì  ë¶„ì„ ë„¤íŠ¸ì›Œí¬
class TemporalAnalysisNet(nn.Module):
    def __init__(self, num_measurements=4, hidden_dim=256, num_layers=2):
        super(TemporalAnalysisNet, self).__init__()

        # ì´ë¯¸ì§€ ì¸ì½”ë” (CNN + temporal pooling)
        self.image_encoder = nn.Sequential(
            nn.Conv2d(3, 32, 3, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.MaxPool2d(2),

            nn.Conv2d(32, 64, 3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.MaxPool2d(2),

            nn.Conv2d(64, 128, 3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            nn.MaxPool2d(2),

            nn.AdaptiveAvgPool2d((4, 4)),
            nn.Flatten()
        )

        # ì‹œê°„ì  ìœµí•©ì„ ìœ„í•œ LSTM
        self.temporal_lstm = nn.LSTM(
            input_size=128 * 4 * 4 + num_measurements,  # ì´ë¯¸ì§€ íŠ¹ì§• + ì¸¡ì •ê°’
            hidden_size=hidden_dim,
            num_layers=num_layers,
            batch_first=True,
            dropout=0.3,
            bidirectional=True
        )

        # ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜
        self.temporal_attention = nn.Sequential(
            nn.Linear(hidden_dim * 2, hidden_dim),
            nn.Tanh(),
            nn.Linear(hidden_dim, 1),
            nn.Softmax(dim=1)
        )

        # ì˜ˆì¸¡ í—¤ë“œë“¤
        self.prognosis_predictor = nn.Sequential(
            nn.Linear(hidden_dim * 2, 128),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, 1),
            nn.Sigmoid()
        )

        # ë‹¤ìŒ ì‹œì  ì˜ˆì¸¡ê¸°
        self.next_measurement_predictor = nn.Sequential(
            nn.Linear(hidden_dim * 2, 128),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(128, num_measurements)
        )

        # ë³€í™”ìœ¨ ì˜ˆì¸¡ê¸°
        self.change_rate_predictor = nn.Sequential(
            nn.Linear(hidden_dim * 2, 64),
            nn.ReLU(),
            nn.Linear(64, 1),
            nn.Tanh()  # -1 ~ 1 ë²”ìœ„ì˜ ë³€í™”ìœ¨
        )

    def forward(self, image_sequence, measurement_sequence, timestamps):
        batch_size, seq_len = image_sequence.shape[:2]

        # ì´ë¯¸ì§€ ì‹œí€€ìŠ¤ ì²˜ë¦¬
        image_features = []
        for t in range(seq_len):
            img_feature = self.image_encoder(image_sequence[:, t])  # [B, feature_dim]
            image_features.append(img_feature)

        image_features = torch.stack(image_features, dim=1)  # [B, seq_len, feature_dim]

        # ì´ë¯¸ì§€ íŠ¹ì§•ê³¼ ì¸¡ì •ê°’ ê²°í•©
        combined_features = torch.cat([image_features, measurement_sequence], dim=2)

        # LSTMì„ í†µí•œ ì‹œê°„ì  ëª¨ë¸ë§
        lstm_out, (hidden, cell) = self.temporal_lstm(combined_features)  # [B, seq_len, hidden_dim*2]

        # ì‹œê°„ì  ì–´í…ì…˜
        attention_weights = self.temporal_attention(lstm_out)  # [B, seq_len, 1]
        attended_features = torch.sum(lstm_out * attention_weights, dim=1)  # [B, hidden_dim*2]

        # ì˜ˆì¸¡
        prognosis_risk = self.prognosis_predictor(attended_features)
        next_measurements = self.next_measurement_predictor(attended_features)
        change_rate = self.change_rate_predictor(attended_features)

        # ì‹œê³„ì—´ ì¬êµ¬ì„±ì„ ìœ„í•œ ë””ì½”ë” ì¶œë ¥
        reconstructed_sequence = []
        for t in range(seq_len):
            recon = self.next_measurement_predictor(lstm_out[:, t])
            reconstructed_sequence.append(recon)

        reconstructed_sequence = torch.stack(reconstructed_sequence, dim=1)

        return {
            'prognosis_risk': prognosis_risk.squeeze(),
            'next_measurements': next_measurements,
            'change_rate': change_rate.squeeze(),
            'reconstructed_sequence': reconstructed_sequence,
            'attention_weights': attention_weights.squeeze(),
            'temporal_features': attended_features
        }

# ì‹œê°„ì  íŠ¸ëœìŠ¤í¬ë¨¸ ë„¤íŠ¸ì›Œí¬
class TemporalTransformerNet(nn.Module):
    def __init__(self, num_measurements=4, d_model=256, nhead=8, num_layers=6):
        super(TemporalTransformerNet, self).__init__()

        self.d_model = d_model

        # ì´ë¯¸ì§€ ì¸ì½”ë”
        self.image_encoder = nn.Sequential(
            nn.Conv2d(3, 64, 7, stride=2, padding=3),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.MaxPool2d(3, stride=2, padding=1),

            nn.Conv2d(64, 128, 3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            nn.MaxPool2d(2),

            nn.Conv2d(128, 256, 3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(),
            nn.AdaptiveAvgPool2d((1, 1)),
            nn.Flatten()
        )

        # ì…ë ¥ í”„ë¡œì ì…˜
        self.input_projection = nn.Linear(256 + num_measurements, d_model)

        # ìœ„ì¹˜ ì¸ì½”ë”©
        self.positional_encoding = nn.Parameter(torch.randn(1000, d_model))

        # íŠ¸ëœìŠ¤í¬ë¨¸ ë ˆì´ì–´ë“¤
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=d_model,
            nhead=nhead,
            dim_feedforward=d_model * 4,
            dropout=0.1,
            batch_first=True
        )
        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers)

        # ì¶œë ¥ í—¤ë“œë“¤
        self.prognosis_head = nn.Sequential(
            nn.Linear(d_model, 128),
            nn.ReLU(),
            nn.Linear(128, 1),
            nn.Sigmoid()
        )

        self.prediction_head = nn.Sequential(
            nn.Linear(d_model, 128),
            nn.ReLU(),
            nn.Linear(128, num_measurements)
        )

    def forward(self, image_sequence, measurement_sequence, timestamps):
        batch_size, seq_len = image_sequence.shape[:2]

        # ì´ë¯¸ì§€ íŠ¹ì§• ì¶”ì¶œ
        image_features = []
        for t in range(seq_len):
            img_feat = self.image_encoder(image_sequence[:, t])
            image_features.append(img_feat)

        image_features = torch.stack(image_features, dim=1)

        # ì´ë¯¸ì§€ì™€ ì¸¡ì •ê°’ ê²°í•©
        combined_input = torch.cat([image_features, measurement_sequence], dim=2)

        # ì…ë ¥ í”„ë¡œì ì…˜
        projected_input = self.input_projection(combined_input)

        # ìœ„ì¹˜ ì¸ì½”ë”© ì¶”ê°€
        positions = torch.arange(seq_len).unsqueeze(0).expand(batch_size, -1).to(projected_input.device)
        projected_input = projected_input + self.positional_encoding[positions]

        # íŠ¸ëœìŠ¤í¬ë¨¸ ì¸ì½”ë”©
        encoded = self.transformer_encoder(projected_input)

        # ìµœì¢… ì‹œì  íŠ¹ì§• ì‚¬ìš© (ë˜ëŠ” ì „ì²´ ì‹œí€€ìŠ¤ì˜ í‰ê· )
        final_features = encoded[:, -1]  # ë§ˆì§€ë§‰ ì‹œì 
        # ë˜ëŠ”: final_features = encoded.mean(dim=1)  # í‰ê· 

        # ì˜ˆì¸¡
        prognosis_risk = self.prognosis_head(final_features)
        next_measurements = self.prediction_head(final_features)

        return {
            'prognosis_risk': prognosis_risk.squeeze(),
            'next_measurements': next_measurements,
            'encoded_sequence': encoded,
            'attention_weights': None  # Transformer ë‚´ë¶€ ì–´í…ì…˜ì€ ë³„ë„ë¡œ ì¶”ì¶œ ê°€ëŠ¥
        }

def train_temporal_analysis(dataset_type='cardiac_monitoring', num_epochs=50, batch_size=8, lr=0.001):
    """
    ì‹œê°„ì  ì˜ë£Œ ë¶„ì„ ëª¨ë¸ í›ˆë ¨

    Args:
        dataset_type: ë°ì´í„°ì…‹ íƒ€ì…
        num_epochs: í›ˆë ¨ ì—í¬í¬ ìˆ˜
        batch_size: ë°°ì¹˜ í¬ê¸°
        lr: í•™ìŠµë¥ 
    """

    # ë¡œê±° ì„¤ì •
    logger = create_logger_for_temporal_medical('temporal_analysis', dataset_type)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    logger.log(f"Using device: {device}")

    # ë°ì´í„°ì…‹ ì¤€ë¹„
    dataset = TemporalMedicalDataset(data_type=dataset_type, sequence_length=10)
    train_size = int(0.8 * len(dataset))
    val_size = len(dataset) - train_size
    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])

    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=True)

    # ëª¨ë¸ ì„¤ì •
    sample = dataset[0]
    num_measurements = sample['measurements'].shape[1]

    # LSTM ê¸°ë°˜ ëª¨ë¸ê³¼ Transformer ê¸°ë°˜ ëª¨ë¸ ë‘ ê°€ì§€ êµ¬í˜„
    lstm_model = TemporalAnalysisNet(num_measurements=num_measurements).to(device)
    transformer_model = TemporalTransformerNet(num_measurements=num_measurements).to(device)

    # ì•™ìƒë¸”ì„ ìœ„í•´ ë‘ ëª¨ë¸ ëª¨ë‘ ì‚¬ìš©
    models = {'lstm': lstm_model, 'transformer': transformer_model}

    # ì†ì‹¤ í•¨ìˆ˜
    mse_criterion = nn.MSELoss()
    bce_criterion = nn.BCELoss()

    # ì˜µí‹°ë§ˆì´ì €
    optimizers = {
        'lstm': optim.Adam(lstm_model.parameters(), lr=lr, weight_decay=1e-4),
        'transformer': optim.Adam(transformer_model.parameters(), lr=lr, weight_decay=1e-4)
    }

    schedulers = {
        'lstm': optim.lr_scheduler.ReduceLROnPlateau(optimizers['lstm'], patience=5, factor=0.7),
        'transformer': optim.lr_scheduler.ReduceLROnPlateau(optimizers['transformer'], patience=5, factor=0.7)
    }

    # í›ˆë ¨ ë©”íŠ¸ë¦­ ì €ì¥
    train_losses = {'lstm': [], 'transformer': []}
    val_losses = {'lstm': [], 'transformer': []}
    prognosis_accuracies = {'lstm': [], 'transformer': []}

    logger.log("Starting temporal analysis training...")

    for epoch in range(num_epochs):
        # ê° ëª¨ë¸ë³„ë¡œ í›ˆë ¨
        for model_name, model in models.items():
            model.train()
            running_loss = 0.0

            for batch_idx, batch in enumerate(train_loader):
                images = batch['images'].to(device)
                measurements = batch['measurements'].to(device)
                timestamps = batch['timestamps'].to(device)
                prognosis_risk = batch['prognosis_risk'].to(device)

                optimizers[model_name].zero_grad()

                # ìˆœì „íŒŒ
                outputs = model(images, measurements, timestamps)

                # ì†ì‹¤ ê³„ì‚°
                loss_prognosis = bce_criterion(outputs['prognosis_risk'], prognosis_risk)

                if 'next_measurements' in outputs:
                    # ë‹¤ìŒ ì‹œì  ì˜ˆì¸¡ ì†ì‹¤ (ë§ˆì§€ë§‰ ì¸¡ì •ê°’ ê¸°ì¤€)
                    target_next = measurements[:, -1]  # ì‹œí€€ìŠ¤ì˜ ë§ˆì§€ë§‰ ì¸¡ì •ê°’
                    loss_prediction = mse_criterion(outputs['next_measurements'], target_next)
                else:
                    loss_prediction = torch.tensor(0.0, device=device)

                if 'reconstructed_sequence' in outputs:
                    # ì‹œí€€ìŠ¤ ì¬êµ¬ì„± ì†ì‹¤
                    loss_reconstruction = mse_criterion(outputs['reconstructed_sequence'], measurements)
                else:
                    loss_reconstruction = torch.tensor(0.0, device=device)

                # ì´ ì†ì‹¤
                total_loss = loss_prognosis + 0.5 * loss_prediction + 0.3 * loss_reconstruction

                total_loss.backward()
                optimizers[model_name].step()

                running_loss += total_loss.item()

                if batch_idx % 20 == 0 and model_name == 'lstm':  # ë¡œê·¸ëŠ” í•œ ëª¨ë¸ë§Œ
                    logger.log(f'Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx}/{len(train_loader)}], '
                              f'LSTM Loss: {total_loss.item():.4f}')

            train_losses[model_name].append(running_loss / len(train_loader))

            # ê²€ì¦ ë‹¨ê³„
            model.eval()
            val_loss = 0.0
            prognosis_errors = []

            with torch.no_grad():
                for batch in val_loader:
                    images = batch['images'].to(device)
                    measurements = batch['measurements'].to(device)
                    timestamps = batch['timestamps'].to(device)
                    prognosis_risk = batch['prognosis_risk'].to(device)

                    outputs = model(images, measurements, timestamps)

                    # ì†ì‹¤ ê³„ì‚°
                    loss_prognosis = bce_criterion(outputs['prognosis_risk'], prognosis_risk)

                    if 'next_measurements' in outputs:
                        target_next = measurements[:, -1]
                        loss_prediction = mse_criterion(outputs['next_measurements'], target_next)
                    else:
                        loss_prediction = torch.tensor(0.0, device=device)

                    if 'reconstructed_sequence' in outputs:
                        loss_reconstruction = mse_criterion(outputs['reconstructed_sequence'], measurements)
                    else:
                        loss_reconstruction = torch.tensor(0.0, device=device)

                    total_loss = loss_prognosis + 0.5 * loss_prediction + 0.3 * loss_reconstruction
                    val_loss += total_loss.item()

                    # ì˜ˆí›„ ì˜ˆì¸¡ ì˜¤ì°¨
                    prognosis_error = torch.abs(outputs['prognosis_risk'] - prognosis_risk).cpu().numpy()
                    prognosis_errors.extend(prognosis_error.tolist())

            val_losses[model_name].append(val_loss / len(val_loader))
            prognosis_accuracies[model_name].append(1.0 - np.mean(prognosis_errors))

            # ìŠ¤ì¼€ì¤„ëŸ¬ ì—…ë°ì´íŠ¸
            schedulers[model_name].step(val_losses[model_name][-1])

        # ë¡œê¹… (ì—í¬í¬ë‹¹ í•œ ë²ˆ)
        logger.log(f'Epoch [{epoch+1}/{num_epochs}]')
        for model_name in models.keys():
            logger.log(f'{model_name.upper()} - Train Loss: {train_losses[model_name][-1]:.4f}, '
                      f'Val Loss: {val_losses[model_name][-1]:.4f}, '
                      f'Prognosis Acc: {prognosis_accuracies[model_name][-1]:.4f}')

        # ë©”íŠ¸ë¦­ ì €ì¥
        logger.save_metrics({
            'epoch': epoch + 1,
            'lstm_train_loss': train_losses['lstm'][-1],
            'lstm_val_loss': val_losses['lstm'][-1],
            'lstm_prognosis_acc': prognosis_accuracies['lstm'][-1],
            'transformer_train_loss': train_losses['transformer'][-1],
            'transformer_val_loss': val_losses['transformer'][-1],
            'transformer_prognosis_acc': prognosis_accuracies['transformer'][-1],
        })

        # ì¤‘ê°„ ê²°ê³¼ ì €ì¥ (ë§¤ 10 ì—í¬í¬)
        if (epoch + 1) % 10 == 0:
            for model_name, model in models.items():
                model.eval()
                with torch.no_grad():
                    sample_batch = next(iter(val_loader))
                    images = sample_batch['images'][:4].to(device)
                    measurements = sample_batch['measurements'][:4].to(device)
                    timestamps = sample_batch['timestamps'][:4].to(device)

                    outputs = model(images, measurements, timestamps)

                    # ì‹œê³„ì—´ ì‹œê°í™”ë¥¼ ìœ„í•œ ì´ë¯¸ì§€ ì¤€ë¹„
                    vis_images = []
                    for i in range(len(images)):
                        # ì²« ë²ˆì§¸ì™€ ë§ˆì§€ë§‰ ì‹œì  ì´ë¯¸ì§€
                        first_img = images[i, 0].cpu().numpy().transpose(1, 2, 0)
                        last_img = images[i, -1].cpu().numpy().transpose(1, 2, 0)

                        first_img = (first_img + 1) / 2  # [-1, 1] -> [0, 1]
                        last_img = (last_img + 1) / 2

                        vis_images.extend([first_img, last_img])

                    # ì–´í…ì…˜ ê°€ì¤‘ì¹˜ ì œëª© í¬í•¨ (LSTM ëª¨ë¸ì˜ ê²½ìš°)
                    titles = []
                    for i in range(len(images)):
                        if 'attention_weights' in outputs and outputs['attention_weights'] is not None:
                            attn = outputs['attention_weights'][i].mean().item()
                            titles.extend([f'{model_name.upper()} T0', f'{model_name.upper()} T-1 A:{attn:.2f}'])
                        else:
                            titles.extend([f'{model_name.upper()} T0', f'{model_name.upper()} T-1'])

                    logger.save_image_grid(vis_images,
                                         f'temporal_{model_name}_epoch_{epoch+1}.png',
                                         titles=titles,
                                         nrow=2)

    # ìµœì¢… ëª¨ë¸ë“¤ ì €ì¥
    for model_name, model in models.items():
        logger.save_model(model, f"temporal_{model_name}_final",
                         optimizer=optimizers[model_name], epoch=num_epochs,
                         config={'dataset_type': dataset_type, 'model_type': model_name})

    # í›ˆë ¨ ê³¡ì„  ì €ì¥
    plt.figure(figsize=(20, 5))

    plt.subplot(1, 4, 1)
    for model_name in models.keys():
        plt.plot(train_losses[model_name], label=f'{model_name.upper()} Train')
        plt.plot(val_losses[model_name], label=f'{model_name.upper()} Val')
    plt.title('Training Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True)

    plt.subplot(1, 4, 2)
    for model_name in models.keys():
        plt.plot(prognosis_accuracies[model_name], label=f'{model_name.upper()}')
    plt.title('Prognosis Prediction Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.grid(True)

    plt.subplot(1, 4, 3)
    # ìµœì¢… ì„±ëŠ¥ ë¹„êµ
    final_lstm_acc = prognosis_accuracies['lstm'][-1]
    final_transformer_acc = prognosis_accuracies['transformer'][-1]

    plt.bar(['LSTM', 'Transformer'], [final_lstm_acc, final_transformer_acc])
    plt.title('Final Model Comparison')
    plt.ylabel('Prognosis Accuracy')
    plt.ylim(0, 1)
    for i, v in enumerate([final_lstm_acc, final_transformer_acc]):
        plt.text(i, v + 0.01, f'{v:.3f}', ha='center')

    plt.subplot(1, 4, 4)
    # ì˜ˆì‹œ ì‹œê³„ì—´ ì˜ˆì¸¡ ê²°ê³¼
    with torch.no_grad():
        models['lstm'].eval()
        sample_batch = next(iter(val_loader))
        sample_measurements = sample_batch['measurements'][0].cpu().numpy()

        # ì‹¤ì œ ì‹œê³„ì—´
        plt.plot(range(len(sample_measurements)), sample_measurements[:, 0],
                'b-', label='Actual', marker='o')

        # ê°„ë‹¨í•œ ì˜ˆì¸¡ ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œë¡œëŠ” ëª¨ë¸ ì¶œë ¥ ì‚¬ìš©)
        predicted = sample_measurements[:, 0] + np.random.normal(0, 0.1, len(sample_measurements))
        plt.plot(range(len(sample_measurements)), predicted,
                'r--', label='Predicted', marker='s')

        plt.title('Time Series Prediction Example')
        plt.xlabel('Time Points')
        plt.ylabel('Measurement Value')
        plt.legend()
        plt.grid(True)

    plt.tight_layout()
    plt.savefig(os.path.join(logger.dirs['plots'], 'temporal_analysis_results.png'),
                dpi=150, bbox_inches='tight')
    plt.close()

    logger.log("Temporal analysis training completed successfully!")
    logger.log(f"Final LSTM prognosis accuracy: {prognosis_accuracies['lstm'][-1]:.4f}")
    logger.log(f"Final Transformer prognosis accuracy: {prognosis_accuracies['transformer'][-1]:.4f}")
    logger.log(f"Results saved in: {logger.dirs['base']}")

    return models, logger.dirs['base']

if __name__ == "__main__":
    print("â° ì‹œê°„ì  ì˜ë£Œ ë¶„ì„ (Temporal Medical Analysis)")
    print("=" * 60)

    # í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •
    config = {
        'dataset_type': 'cardiac_monitoring',
        'num_epochs': 5,  # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ 5ë¡œ ì„¤ì •
        'batch_size': 4,  # ì‹œê³„ì—´ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ë†’ìŒ
        'lr': 0.001
    }

    print(f"Dataset: {config['dataset_type']}")
    print(f"Epochs: {config['num_epochs']}")
    print(f"Batch size: {config['batch_size']}")
    print(f"Learning rate: {config['lr']}")
    print()

    try:
        models, results_dir = train_temporal_analysis(
            dataset_type=config['dataset_type'],
            num_epochs=config['num_epochs'],
            batch_size=config['batch_size'],
            lr=config['lr']
        )

        print("\nâœ… Temporal analysis training completed successfully!")
        print(f"ğŸ“ Results saved to: {results_dir}")

        print("\nğŸ“Š Generated files include:")
        print("- images/: Temporal analysis visualizations (first/last timepoints)")
        print("- models/: Trained LSTM and Transformer temporal models")
        print("- logs/: Training logs and configuration")
        print("- plots/: Training curves and model comparisons")
        print("- metrics/: Training metrics in JSON format")

        print("\nğŸ¯ Temporal Analysis Features:")
        print("- Longitudinal disease progression monitoring")
        print("- Multi-timepoint image and measurement fusion")
        print("- Prognosis prediction with temporal patterns")
        print("- LSTM vs Transformer architecture comparison")
        print("- Attention-based temporal modeling")

    except Exception as e:
        print(f"\nâŒ Error during temporal analysis training: {str(e)}")
        import traceback
        traceback.print_exc()