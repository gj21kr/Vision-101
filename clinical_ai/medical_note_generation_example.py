#!/usr/bin/env python3
"""
ì˜ë£Œ ë…¸íŠ¸ ìƒì„± ì‹œìŠ¤í…œ (Medical Note Generation System)

AIë¥¼ í™œìš©í•œ ìë™ ì˜ë£Œ ë…¸íŠ¸ ìƒì„± ì‹œìŠ¤í…œìœ¼ë¡œ, ë‹¤ì–‘í•œ ì„ìƒ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬
í‘œì¤€í™”ë˜ê³  êµ¬ì¡°í™”ëœ ì˜ë£Œ ê¸°ë¡ì„ ìƒì„±í•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
- ë‹¤ì–‘í•œ ìœ í˜•ì˜ ì˜ë£Œ ë…¸íŠ¸ í…œí”Œë¦¿ (Progress Note, H&P, Discharge Summary ë“±)
- ìì—°ì–´ ì²˜ë¦¬ë¥¼ í†µí•œ ì„ìƒ ì •ë³´ ì¶”ì¶œ
- SOAP í˜•ì‹ ìë™ êµ¬ì¡°í™”
- ì§„ë‹¨ ì½”ë“œ (ICD-10) ìë™ ì¶”ì²œ
- ì˜ë£Œì§„ ê°„ ì¸ìˆ˜ì¸ê³„ ìš”ì•½ ìƒì„±
- í’ˆì§ˆ ê´€ë¦¬ ë° ì™„ì„±ë„ ê²€ì¦
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import numpy as np
import json
import re
import os
import sys
from datetime import datetime, timedelta
from dataclasses import dataclass
from typing import List, Dict, Tuple, Optional, Union
from enum import Enum
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

sys.path.append('/workspace/Vision-101')
from medical.result_logger import create_logger_for_clinical_ai

class SimpleTokenizer:
    """ê°„ë‹¨í•œ í† í¬ë‚˜ì´ì € í´ë˜ìŠ¤ (transformers ëŒ€ì²´ìš©)"""

    def __init__(self, vocab_size=30000):
        self.vocab_size = vocab_size
        self.vocab = {}
        self.inverse_vocab = {}
        self.unk_token = '[UNK]'
        self.pad_token = '[PAD]'
        self.cls_token = '[CLS]'
        self.sep_token = '[SEP]'

        # íŠ¹ìˆ˜ í† í° ì¶”ê°€
        special_tokens = [self.pad_token, self.unk_token, self.cls_token, self.sep_token]
        for i, token in enumerate(special_tokens):
            self.vocab[token] = i
            self.inverse_vocab[i] = token

    def tokenize(self, text):
        """ê¸°ë³¸ì ì¸ í† í°í™”"""
        # ê°„ë‹¨í•œ í† í°í™”: ê³µë°±ê³¼ êµ¬ë‘ì  ê¸°ì¤€ ë¶„ë¦¬
        import re
        tokens = re.findall(r'\w+|[^\w\s]', text.lower())
        return tokens

    def encode(self, text, max_length=512, padding=True, truncation=True):
        """í…ìŠ¤íŠ¸ë¥¼ IDë¡œ ì¸ì½”ë”©"""
        tokens = self.tokenize(text)

        # í† í°ì„ IDë¡œ ë³€í™˜
        ids = []
        for token in tokens:
            if token not in self.vocab:
                # ìƒˆë¡œìš´ í† í°ì„ vocabularyì— ì¶”ê°€
                if len(self.vocab) < self.vocab_size:
                    token_id = len(self.vocab)
                    self.vocab[token] = token_id
                    self.inverse_vocab[token_id] = token
                    ids.append(token_id)
                else:
                    ids.append(self.vocab[self.unk_token])
            else:
                ids.append(self.vocab[token])

        # ê¸¸ì´ ì¡°ì •
        if truncation and len(ids) > max_length:
            ids = ids[:max_length]

        if padding and len(ids) < max_length:
            pad_id = self.vocab[self.pad_token]
            ids.extend([pad_id] * (max_length - len(ids)))

        return ids

    def __call__(self, text, max_length=512, padding='max_length', truncation=True, return_tensors='pt'):
        """transformers ìŠ¤íƒ€ì¼ í˜¸ì¶œ"""
        input_ids = self.encode(text, max_length=max_length,
                               padding=(padding == 'max_length'),
                               truncation=truncation)

        attention_mask = [1 if id != self.vocab[self.pad_token] else 0 for id in input_ids]

        result = {
            'input_ids': input_ids,
            'attention_mask': attention_mask
        }

        if return_tensors == 'pt':
            result['input_ids'] = torch.tensor([result['input_ids']])
            result['attention_mask'] = torch.tensor([result['attention_mask']])

        return result

class NoteType(Enum):
    """ì˜ë£Œ ë…¸íŠ¸ ìœ í˜•"""
    PROGRESS_NOTE = "progress_note"
    HISTORY_PHYSICAL = "history_physical"
    DISCHARGE_SUMMARY = "discharge_summary"
    CONSULTATION = "consultation"
    OPERATIVE_NOTE = "operative_note"
    ADMISSION_NOTE = "admission_note"
    TRANSFER_NOTE = "transfer_note"

@dataclass
class PatientInfo:
    """í™˜ì ê¸°ë³¸ ì •ë³´"""
    patient_id: str
    name: str
    age: int
    gender: str
    mrn: str  # Medical Record Number
    admission_date: datetime
    primary_physician: str
    department: str

@dataclass
class VitalSigns:
    """í™œë ¥ì§•í›„"""
    temperature: float  # Celsius
    blood_pressure_systolic: int
    blood_pressure_diastolic: int
    heart_rate: int
    respiratory_rate: int
    oxygen_saturation: float
    pain_score: int  # 0-10 scale
    timestamp: datetime

@dataclass
class LabResult:
    """ê²€ì‚¬ ê²°ê³¼"""
    test_name: str
    value: float
    unit: str
    reference_range: str
    status: str  # normal, high, low, critical
    timestamp: datetime

@dataclass
class Medication:
    """íˆ¬ì•½ ì •ë³´"""
    name: str
    dosage: str
    frequency: str
    route: str
    indication: str
    start_date: datetime
    end_date: Optional[datetime] = None

@dataclass
class ClinicalNote:
    """ì„ìƒ ë…¸íŠ¸ êµ¬ì¡°"""
    patient_info: PatientInfo
    note_type: NoteType
    chief_complaint: str
    history_present_illness: str
    past_medical_history: List[str]
    medications: List[Medication]
    allergies: List[str]
    vital_signs: List[VitalSigns]
    lab_results: List[LabResult]
    physical_exam: Dict[str, str]
    assessment_plan: Dict[str, List[str]]
    provider_name: str
    timestamp: datetime

class MedicalNoteDataset(Dataset):
    """ì˜ë£Œ ë…¸íŠ¸ ë°ì´í„°ì…‹"""

    def __init__(self, num_samples=1000, tokenizer=None, max_length=512):
        self.num_samples = num_samples
        self.max_length = max_length
        self.tokenizer = tokenizer or self._get_default_tokenizer()
        self.clinical_notes = self._generate_clinical_notes()

    def _get_default_tokenizer(self):
        """ê¸°ë³¸ í† í¬ë‚˜ì´ì € ì„¤ì •"""
        # ë‹¨ìˆœí•œ í† í¬ë‚˜ì´ì € ì‚¬ìš© (transformers ì˜ì¡´ì„± ì œê±°)
        return SimpleTokenizer()

    def _generate_clinical_notes(self):
        """ì„ìƒ ë…¸íŠ¸ ìƒì„±"""
        notes = []

        for i in range(self.num_samples):
            note = self._create_sample_note(i)
            notes.append(note)

        return notes

    def _create_sample_note(self, seed):
        """ìƒ˜í”Œ ì„ìƒ ë…¸íŠ¸ ìƒì„±"""
        np.random.seed(seed)

        # í™˜ì ì •ë³´
        patient_info = PatientInfo(
            patient_id=f"PT{1000 + seed}",
            name=f"í™˜ì{seed}",
            age=np.random.randint(20, 90),
            gender=np.random.choice(["ë‚¨ì„±", "ì—¬ì„±"]),
            mrn=f"MRN{seed:06d}",
            admission_date=datetime.now() - timedelta(days=np.random.randint(0, 30)),
            primary_physician=np.random.choice(["ê¹€ì˜ì‚¬", "ì´ì˜ì‚¬", "ë°•ì˜ì‚¬", "ìµœì˜ì‚¬"]),
            department=np.random.choice(["ë‚´ê³¼", "ì™¸ê³¼", "ì‘ê¸‰ì˜í•™ê³¼", "ì •í˜•ì™¸ê³¼", "ì‹ ê²½ê³¼"])
        )

        # ë…¸íŠ¸ ìœ í˜• ì„ íƒ
        note_type = np.random.choice(list(NoteType))

        # ì£¼ì†Œ (Chief Complaint)
        chief_complaints = [
            "ë³µí†µ 3ì¼ê°„ ì§€ì†",
            "ë°œì—´ê³¼ ê¸°ì¹¨ 1ì£¼ì¼",
            "ë‘í†µê³¼ ì–´ì§€ëŸ¬ì›€",
            "í‰í†µ ë° í˜¸í¡ê³¤ë€",
            "ë³µë¶€ íŒ½ë§Œê°ê³¼ êµ¬í† ",
            "ë¬´ë¦ í†µì¦ìœ¼ë¡œ ë³´í–‰ ê³¤ë€",
            "í˜ˆì•• ìƒìŠ¹ìœ¼ë¡œ ë‚´ì›",
            "ë‹¹ë‡¨ ì¡°ì ˆ ë¶ˆëŸ‰",
            "ì˜ì‹ ì €í•˜ë¡œ ì‘ê¸‰ì‹¤ ë‚´ì›",
            "ìˆ˜ìˆ  í›„ ì¶”ì  ê´€ì°°"
        ]
        chief_complaint = np.random.choice(chief_complaints)

        # í˜„ë³‘ë ¥ (History of Present Illness)
        hpi_templates = [
            f"{patient_info.age}ì„¸ {patient_info.gender} í™˜ìë¡œ {chief_complaint}ìœ¼ë¡œ ë‚´ì›í•˜ì˜€ìŠµë‹ˆë‹¤. "
            "ì¦ìƒì€ ì ì§„ì ìœ¼ë¡œ ì•…í™”ë˜ì—ˆìœ¼ë©°, ì§„í†µì œ ë³µìš©ì—ë„ í˜¸ì „ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",

            f"í™˜ìëŠ” {chief_complaint}ì„ ì£¼ì†Œë¡œ ë‚´ì›í•˜ì˜€ìŠµë‹ˆë‹¤. "
            "ì¦ìƒì€ ê°„í—ì ìœ¼ë¡œ ë‚˜íƒ€ë‚¬ìœ¼ë‚˜ ìµœê·¼ ì§€ì†ì ìœ¼ë¡œ ë°œìƒí•˜ê³  ìˆìŠµë‹ˆë‹¤.",

            f"{chief_complaint}ìœ¼ë¡œ ì¸í•´ ì¼ìƒ ìƒí™œì— ì§€ì¥ì„ ë°›ê³  ìˆì–´ ì§„ë£Œë¥¼ ë°›ê³ ì ë‚´ì›í•˜ì˜€ìŠµë‹ˆë‹¤."
        ]
        hpi = np.random.choice(hpi_templates)

        # ê³¼ê±°ë³‘ë ¥
        past_histories = [
            ["ê³ í˜ˆì••", "ë‹¹ë‡¨ë³‘"],
            ["ê³ ì§€í˜ˆì¦", "ê´€ìƒë™ë§¥ì§ˆí™˜"],
            ["ì²œì‹", "ì•Œë ˆë¥´ê¸°ì„± ë¹„ì—¼"],
            ["ê°‘ìƒì„  ê¸°ëŠ¥ ì €í•˜ì¦"],
            ["ìœ„ê¶¤ì–‘", "ì—­ë¥˜ì„± ì‹ë„ì—¼"],
            []  # íŠ¹ì´ ê³¼ê±°ë ¥ ì—†ìŒ
        ]
        past_medical_history = past_histories[np.random.randint(0, len(past_histories))]

        # íˆ¬ì•½ ì •ë³´
        medications = self._generate_medications(past_medical_history, patient_info.admission_date)

        # ì•Œë ˆë¥´ê¸°
        allergies = ["íŠ¹ì´ì‚¬í•­ ì—†ìŒ"] if np.random.random() > 0.3 else ["í˜ë‹ˆì‹¤ë¦°", "ì¡°ì˜ì œ", "ì•„ìŠ¤í”¼ë¦°"][:np.random.randint(1, 3)]

        # í™œë ¥ì§•í›„
        vital_signs = [self._generate_vital_signs(patient_info.admission_date + timedelta(hours=i*6))
                      for i in range(4)]

        # ê²€ì‚¬ ê²°ê³¼
        lab_results = self._generate_lab_results(patient_info.admission_date)

        # ì‹ ì²´ ê²€ì§„
        physical_exam = self._generate_physical_exam()

        # í‰ê°€ ë° ê³„íš
        assessment_plan = self._generate_assessment_plan(chief_complaint, past_medical_history)

        return ClinicalNote(
            patient_info=patient_info,
            note_type=note_type,
            chief_complaint=chief_complaint,
            history_present_illness=hpi,
            past_medical_history=past_medical_history,
            medications=medications,
            allergies=allergies,
            vital_signs=vital_signs,
            lab_results=lab_results,
            physical_exam=physical_exam,
            assessment_plan=assessment_plan,
            provider_name=patient_info.primary_physician,
            timestamp=datetime.now()
        )

    def _generate_medications(self, past_history, admission_date):
        """íˆ¬ì•½ ì •ë³´ ìƒì„±"""
        medications = []

        if "ê³ í˜ˆì••" in past_history:
            medications.append(Medication(
                name="ì•”ë¡œë””í•€",
                dosage="5mg",
                frequency="1ì¼ 1íšŒ",
                route="ê²½êµ¬",
                indication="ê³ í˜ˆì••",
                start_date=admission_date - timedelta(days=30)
            ))

        if "ë‹¹ë‡¨ë³‘" in past_history:
            medications.append(Medication(
                name="ë©”íŠ¸í¬ë¥´ë¯¼",
                dosage="500mg",
                frequency="1ì¼ 2íšŒ",
                route="ê²½êµ¬",
                indication="ì œ2í˜• ë‹¹ë‡¨ë³‘",
                start_date=admission_date - timedelta(days=60)
            ))

        # í˜„ì¬ ì¦ìƒì— ë”°ë¥¸ ì¶”ê°€ ì•½ë¬¼
        medications.append(Medication(
            name="ì•„ì„¸íŠ¸ì•„ë¯¸ë…¸íœ",
            dosage="500mg",
            frequency="í•„ìš”ì‹œ",
            route="ê²½êµ¬",
            indication="í•´ì—´ ì§„í†µ",
            start_date=admission_date
        ))

        return medications

    def _generate_vital_signs(self, timestamp):
        """í™œë ¥ì§•í›„ ìƒì„±"""
        return VitalSigns(
            temperature=np.random.normal(36.5, 0.5),
            blood_pressure_systolic=np.random.randint(100, 160),
            blood_pressure_diastolic=np.random.randint(60, 100),
            heart_rate=np.random.randint(60, 100),
            respiratory_rate=np.random.randint(16, 24),
            oxygen_saturation=np.random.normal(98, 1),
            pain_score=np.random.randint(0, 8),
            timestamp=timestamp
        )

    def _generate_lab_results(self, base_date):
        """ê²€ì‚¬ ê²°ê³¼ ìƒì„±"""
        labs = [
            LabResult("í—¤ëª¨ê¸€ë¡œë¹ˆ", np.random.normal(13, 2), "g/dL", "12-16", "normal", base_date),
            LabResult("ë°±í˜ˆêµ¬ìˆ˜", np.random.normal(7000, 2000), "/Î¼L", "4000-10000", "normal", base_date),
            LabResult("í˜ˆì†ŒíŒìˆ˜", np.random.normal(250000, 50000), "/Î¼L", "150000-400000", "normal", base_date),
            LabResult("ë‚˜íŠ¸ë¥¨", np.random.normal(140, 3), "mEq/L", "136-145", "normal", base_date),
            LabResult("ì¹¼ë¥¨", np.random.normal(4.0, 0.3), "mEq/L", "3.5-5.0", "normal", base_date),
            LabResult("í¬ë ˆì•„í‹°ë‹Œ", np.random.normal(1.0, 0.2), "mg/dL", "0.7-1.3", "normal", base_date),
        ]

        # ë¹„ì •ìƒ ê°’ ì‹œë®¬ë ˆì´ì…˜
        for lab in labs:
            if np.random.random() < 0.2:  # 20% í™•ë¥ ë¡œ ë¹„ì •ìƒ
                if "í—¤ëª¨ê¸€ë¡œë¹ˆ" in lab.test_name:
                    lab.value = np.random.choice([9.5, 18.5])
                    lab.status = "low" if lab.value < 12 else "high"
                elif "ë°±í˜ˆêµ¬ìˆ˜" in lab.test_name:
                    lab.value = np.random.choice([2000, 15000])
                    lab.status = "low" if lab.value < 4000 else "high"

        return labs

    def _generate_physical_exam(self):
        """ì‹ ì²´ ê²€ì§„ ì†Œê²¬ ìƒì„±"""
        exam_findings = {
            "ì¼ë°˜ì  ì™¸ê²¬": "ê¸‰ì„± ë³‘ìƒ‰ì€ ì—†ìœ¼ë‚˜ ë§Œì„± ë³‘ìƒ‰ì„ ë³´ì„",
            "í™œë ¥ì§•í›„": "ì•ˆì •ì ",
            "ë¨¸ë¦¬ì™€ ëª©": "íŠ¹ì´ì†Œê²¬ ì—†ìŒ",
            "ì‹¬ì¥": "ê·œì¹™ì ì¸ ì‹¬ë°•ë™, ì¡ìŒ ì—†ìŒ",
            "í": "ì–‘ì¸¡ íì•¼ ë§‘ìŒ, ìˆ˜í¬ìŒ ì—†ìŒ",
            "ë³µë¶€": "ë¶€ë“œëŸ½ê³  ì••í†µ ì—†ìŒ, ì¥ìŒ ì •ìƒ",
            "ì‚¬ì§€": "ë¶€ì¢… ì—†ìŒ, ë§¥ë°• ì´‰ì§€ë¨",
            "ì‹ ê²½í•™ì ": "ì˜ì‹ ëª…ë£Œ, êµ­ì†Œ ì‹ ê²½í•™ì  ê²°ì† ì—†ìŒ"
        }

        # ì£¼ì†Œì— ë”°ë¥¸ íŠ¹ì´ ì†Œê²¬ ì¶”ê°€
        if np.random.random() < 0.3:
            exam_findings["ë³µë¶€"] = "ìš°í•˜ë³µë¶€ ì••í†µ ìˆìŒ, ë°˜ë°œí†µ ì–‘ì„±"
        if np.random.random() < 0.2:
            exam_findings["í"] = "ìš°í•˜ì—½ì— ìˆ˜í¬ìŒ ì²­ì§„ë¨"

        return exam_findings

    def _generate_assessment_plan(self, chief_complaint, past_history):
        """í‰ê°€ ë° ê³„íš ìƒì„±"""
        assessment_plan = {}

        # ì£¼ìš” ì§„ë‹¨
        if "ë³µí†µ" in chief_complaint:
            assessment_plan["ê¸‰ì„± ë³µí†µ"] = [
                "ì›ì¸ ê°ë³„ì„ ìœ„í•œ ì¶”ê°€ ê²€ì‚¬ ì‹œí–‰",
                "ê¸ˆì‹ ìœ ì§€",
                "í†µì¦ ì¡°ì ˆ",
                "ê²½ê³¼ ê´€ì°°"
            ]
        elif "ë°œì—´" in chief_complaint:
            assessment_plan["ë°œì—´"] = [
                "ê°ì—¼ ì›ì¸ ê·œëª…ì„ ìœ„í•œ ë°°ì–‘ê²€ì‚¬",
                "í•­ìƒì œ ì¹˜ë£Œ ê³ ë ¤",
                "í•´ì—´ì œ íˆ¬ì—¬",
                "ìˆ˜ì•¡ ê³µê¸‰"
            ]
        elif "í‰í†µ" in chief_complaint:
            assessment_plan["í‰í†µ"] = [
                "ì‹¬ì „ë„ ë° ì‹¬ì¥íš¨ì†Œ ê²€ì‚¬",
                "í‰ë¶€ X-ray ì‹œí–‰",
                "ì‹¬í˜ˆê´€ ìœ„í—˜ì¸ì í‰ê°€",
                "ì¦ìƒ ëª¨ë‹ˆí„°ë§"
            ]

        # ê¸°ì¡´ ì§ˆí™˜ ê´€ë¦¬
        if "ê³ í˜ˆì••" in past_history:
            assessment_plan["ê³ í˜ˆì••"] = [
                "í˜ˆì•• ëª¨ë‹ˆí„°ë§",
                "í˜„ì¬ ì•½ë¬¼ ìœ ì§€",
                "ì—¼ë¶„ ì œí•œ ì‹ì´"
            ]

        if "ë‹¹ë‡¨ë³‘" in past_history:
            assessment_plan["ì œ2í˜• ë‹¹ë‡¨ë³‘"] = [
                "í˜ˆë‹¹ ëª¨ë‹ˆí„°ë§",
                "ë‹¹í™”í˜ˆìƒ‰ì†Œ ì¶”ì ",
                "ë‹¹ë‡¨ êµìœ¡ ê°•í™”"
            ]

        return assessment_plan

    def __len__(self):
        return len(self.clinical_notes)

    def __getitem__(self, idx):
        note = self.clinical_notes[idx]

        # í…ìŠ¤íŠ¸ í˜•íƒœë¡œ ë³€í™˜
        note_text = self._note_to_text(note)

        # í† í¬ë‚˜ì´ì €ê°€ ìˆìœ¼ë©´ í† í°í™”
        if self.tokenizer:
            encoding = self.tokenizer(
                note_text,
                truncation=True,
                padding='max_length',
                max_length=self.max_length,
                return_tensors='pt'
            )

            return {
                'input_ids': encoding['input_ids'].squeeze(),
                'attention_mask': encoding['attention_mask'].squeeze(),
                'note_text': note_text,
                'note_data': note_text,  # ë¬¸ìì—´ë¡œ ì „ë‹¬
                'note_type': note.note_type.value
            }
        else:
            return {
                'note_text': note_text,
                'note_data': note_text,
                'note_type': note.note_type.value
            }

    def _note_to_text(self, note: ClinicalNote) -> str:
        """ì„ìƒ ë…¸íŠ¸ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        text = f"""
ì˜ë£Œê¸°ë¡

í™˜ìì •ë³´:
- ì„±ëª…: {note.patient_info.name}
- ë‚˜ì´: {note.patient_info.age}ì„¸
- ì„±ë³„: {note.patient_info.gender}
- ì˜ë£Œê¸°ë¡ë²ˆí˜¸: {note.patient_info.mrn}
- ì…ì›ì¼: {note.patient_info.admission_date.strftime('%Y-%m-%d')}
- ì£¼ì¹˜ì˜: {note.patient_info.primary_physician}
- ì§„ë£Œê³¼: {note.patient_info.department}

ì£¼ì†Œ (Chief Complaint):
{note.chief_complaint}

í˜„ë³‘ë ¥ (History of Present Illness):
{note.history_present_illness}

ê³¼ê±°ë³‘ë ¥ (Past Medical History):
{', '.join(note.past_medical_history) if note.past_medical_history else 'íŠ¹ì´ì‚¬í•­ ì—†ìŒ'}

ì•Œë ˆë¥´ê¸° (Allergies):
{', '.join(note.allergies)}

í˜„ì¬ íˆ¬ì•½ (Current Medications):
"""

        for med in note.medications:
            text += f"- {med.name} {med.dosage} {med.frequency} ({med.indication})\n"

        text += "\ní™œë ¥ì§•í›„ (Vital Signs):\n"
        latest_vitals = note.vital_signs[-1] if note.vital_signs else None
        if latest_vitals:
            text += f"- ì²´ì˜¨: {latest_vitals.temperature:.1f}Â°C\n"
            text += f"- í˜ˆì••: {latest_vitals.blood_pressure_systolic}/{latest_vitals.blood_pressure_diastolic} mmHg\n"
            text += f"- ë§¥ë°•: {latest_vitals.heart_rate} bpm\n"
            text += f"- í˜¸í¡ìˆ˜: {latest_vitals.respiratory_rate} /min\n"
            text += f"- ì‚°ì†Œí¬í™”ë„: {latest_vitals.oxygen_saturation:.1f}%\n"
            text += f"- í†µì¦ ì ìˆ˜: {latest_vitals.pain_score}/10\n"

        text += "\nê²€ì‚¬ ê²°ê³¼ (Laboratory Results):\n"
        for lab in note.lab_results:
            text += f"- {lab.test_name}: {lab.value:.1f} {lab.unit} ({lab.status})\n"

        text += "\nì‹ ì²´ ê²€ì§„ (Physical Examination):\n"
        for system, finding in note.physical_exam.items():
            text += f"- {system}: {finding}\n"

        text += "\ní‰ê°€ ë° ê³„íš (Assessment and Plan):\n"
        for diagnosis, plans in note.assessment_plan.items():
            text += f"\n{diagnosis}:\n"
            for i, plan in enumerate(plans, 1):
                text += f"  {i}. {plan}\n"

        text += f"\nì‘ì„±ì: {note.provider_name}\n"
        text += f"ì‘ì„±ì¼ì‹œ: {note.timestamp.strftime('%Y-%m-%d %H:%M')}\n"

        return text.strip()

class MedicalNoteGenerator(nn.Module):
    """ì˜ë£Œ ë…¸íŠ¸ ìƒì„± ëª¨ë¸"""

    def __init__(self, vocab_size=30000, hidden_size=768, num_layers=12, num_heads=12, max_length=512):
        super(MedicalNoteGenerator, self).__init__()

        self.hidden_size = hidden_size
        self.max_length = max_length

        # ì„ë² ë”© ë ˆì´ì–´
        self.token_embedding = nn.Embedding(vocab_size, hidden_size)
        self.position_embedding = nn.Embedding(max_length, hidden_size)

        # íŠ¸ëœìŠ¤í¬ë¨¸ ë ˆì´ì–´
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=hidden_size,
            nhead=num_heads,
            dim_feedforward=hidden_size * 4,
            dropout=0.1,
            batch_first=True
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)

        # ì¶œë ¥ ë ˆì´ì–´
        self.ln_f = nn.LayerNorm(hidden_size)
        self.lm_head = nn.Linear(hidden_size, vocab_size)

        # ë…¸íŠ¸ ìœ í˜• ë¶„ë¥˜ê¸°
        self.note_type_classifier = nn.Linear(hidden_size, len(NoteType))

        # í’ˆì§ˆ í‰ê°€ê¸°
        self.quality_scorer = nn.Linear(hidden_size, 1)

    def forward(self, input_ids, attention_mask=None, position_ids=None):
        batch_size, seq_length = input_ids.shape

        if position_ids is None:
            position_ids = torch.arange(seq_length, device=input_ids.device).unsqueeze(0).expand(batch_size, -1)

        # ì„ë² ë”©
        token_embeds = self.token_embedding(input_ids)
        position_embeds = self.position_embedding(position_ids)
        hidden_states = token_embeds + position_embeds

        # ì–´í…ì…˜ ë§ˆìŠ¤í¬ ì²˜ë¦¬
        src_key_padding_mask = None
        if attention_mask is not None:
            # íŒ¨ë”© í† í° ìœ„ì¹˜ë¥¼ ë§ˆìŠ¤í‚¹ (True = ë¬´ì‹œí•  ìœ„ì¹˜)
            src_key_padding_mask = (attention_mask == 0)

        # íŠ¸ëœìŠ¤í¬ë¨¸
        hidden_states = self.transformer(hidden_states, src_key_padding_mask=src_key_padding_mask)

        # ì •ê·œí™”
        hidden_states = self.ln_f(hidden_states)

        # ì–¸ì–´ ëª¨ë¸ë§ í—¤ë“œ
        lm_logits = self.lm_head(hidden_states)

        # í’€ë§ì„ ìœ„í•œ í‰ê·  ê³„ì‚° (íŒ¨ë”© ì œì™¸)
        if attention_mask is not None:
            # attention_maskë¥¼ í™•ì¥í•´ì„œ hidden_statesì™€ ê³±ì…ˆ
            mask_expanded = attention_mask.unsqueeze(-1).expand(hidden_states.size()).float()
            sum_hidden = torch.sum(hidden_states * mask_expanded, 1)
            sum_mask = torch.clamp(mask_expanded.sum(1), min=1e-9)
            pooled = sum_hidden / sum_mask
        else:
            pooled = hidden_states.mean(1)

        # ë…¸íŠ¸ ìœ í˜• ë¶„ë¥˜
        note_type_logits = self.note_type_classifier(pooled)

        # í’ˆì§ˆ ì ìˆ˜
        quality_score = torch.sigmoid(self.quality_scorer(pooled))

        return {
            'lm_logits': lm_logits,
            'note_type_logits': note_type_logits,
            'quality_score': quality_score.squeeze(),
            'hidden_states': hidden_states
        }

class SOAPExtractor:
    """SOAP í˜•ì‹ ì¶”ì¶œê¸°"""

    def __init__(self):
        self.section_patterns = {
            'subjective': [
                r'ì£¼ì†Œ.*?:|Chief Complaint.*?:',
                r'í˜„ë³‘ë ¥.*?:|History of Present Illness.*?:',
                r'í™˜ì.*?í˜¸ì†Œ',
            ],
            'objective': [
                r'í™œë ¥ì§•í›„.*?:|Vital Signs.*?:',
                r'ì‹ ì²´ê²€ì§„.*?:|Physical Examination.*?:',
                r'ê²€ì‚¬ê²°ê³¼.*?:|Laboratory.*?:',
            ],
            'assessment': [
                r'í‰ê°€.*?:|Assessment.*?:',
                r'ì§„ë‹¨.*?:|Diagnosis.*?:',
                r'ì¸ìƒ.*?:|Impression.*?:',
            ],
            'plan': [
                r'ê³„íš.*?:|Plan.*?:',
                r'ì¹˜ë£Œ.*?:|Treatment.*?:',
                r'ì²˜ë°©.*?:|Prescription.*?:',
            ]
        }

    def extract_soap(self, note_text: str) -> Dict[str, str]:
        """í…ìŠ¤íŠ¸ì—ì„œ SOAP ì„¹ì…˜ ì¶”ì¶œ"""
        soap = {'subjective': '', 'objective': '', 'assessment': '', 'plan': ''}

        lines = note_text.split('\n')
        current_section = None

        for line in lines:
            line = line.strip()
            if not line:
                continue

            # ì„¹ì…˜ í—¤ë” ê°ì§€
            section_found = False
            for section, patterns in self.section_patterns.items():
                for pattern in patterns:
                    if re.search(pattern, line, re.IGNORECASE):
                        current_section = section
                        section_found = True
                        break
                if section_found:
                    break

            # í˜„ì¬ ì„¹ì…˜ì— ë‚´ìš© ì¶”ê°€
            if current_section and not section_found:
                soap[current_section] += line + '\n'

        return soap

class ClinicalNLPProcessor:
    """ì„ìƒ ìì—°ì–´ ì²˜ë¦¬ í”„ë¡œì„¸ì„œ"""

    def __init__(self):
        self.medical_entities = {
            'symptoms': ['í†µì¦', 'ë°œì—´', 'ê¸°ì¹¨', 'í˜¸í¡ê³¤ë€', 'ë‘í†µ', 'ì–´ì§€ëŸ¬ì›€', 'êµ¬í† ', 'ì„¤ì‚¬'],
            'medications': ['ì•„ìŠ¤í”¼ë¦°', 'íƒ€ì´ë ˆë†€', 'ì•”ë¡œë””í•€', 'ë©”íŠ¸í¬ë¥´ë¯¼', 'ë¦¬í”¼í† ', 'ì•„ëª©ì‹œì‹¤ë¦°'],
            'conditions': ['ê³ í˜ˆì••', 'ë‹¹ë‡¨ë³‘', 'ì²œì‹', 'ê´€ìƒë™ë§¥ì§ˆí™˜', 'ê°‘ìƒì„ ê¸°ëŠ¥ì €í•˜ì¦'],
            'procedures': ['ìˆ˜ìˆ ', 'ê²€ì‚¬', 'ì´¬ì˜', 'ìƒê²€', 'ìˆ˜í˜ˆ', 'íˆ¬ì„']
        }

        self.icd10_codes = {
            'ê³ í˜ˆì••': 'I10',
            'ì œ2í˜• ë‹¹ë‡¨ë³‘': 'E11',
            'ì²œì‹': 'J45',
            'ê¸‰ì„± ë³µí†µ': 'R10.9',
            'ë°œì—´': 'R50.9',
            'ë‘í†µ': 'R51',
            'í‰í†µ': 'R07.9'
        }

    def extract_entities(self, text: str) -> Dict[str, List[str]]:
        """ì˜ë£Œ ê°œì²´ëª… ì¶”ì¶œ"""
        extracted = {category: [] for category in self.medical_entities.keys()}

        for category, entities in self.medical_entities.items():
            for entity in entities:
                if entity in text:
                    extracted[category].append(entity)

        return extracted

    def suggest_icd10_codes(self, assessment_text: str) -> List[Tuple[str, str]]:
        """ICD-10 ì½”ë“œ ì¶”ì²œ"""
        suggestions = []

        for condition, code in self.icd10_codes.items():
            if condition in assessment_text:
                suggestions.append((condition, code))

        return suggestions

    def calculate_note_completeness(self, note: ClinicalNote) -> float:
        """ë…¸íŠ¸ ì™„ì„±ë„ ê³„ì‚°"""
        completeness_score = 0.0
        total_sections = 8

        # í•„ìˆ˜ ì„¹ì…˜ ì²´í¬
        if note.chief_complaint.strip():
            completeness_score += 1
        if note.history_present_illness.strip():
            completeness_score += 1
        if note.past_medical_history:
            completeness_score += 1
        if note.medications:
            completeness_score += 1
        if note.vital_signs:
            completeness_score += 1
        if note.lab_results:
            completeness_score += 1
        if note.physical_exam:
            completeness_score += 1
        if note.assessment_plan:
            completeness_score += 1

        return completeness_score / total_sections

def train_medical_note_generator(num_epochs=10, batch_size=8, lr=0.0001):
    """ì˜ë£Œ ë…¸íŠ¸ ìƒì„±ê¸° í›ˆë ¨"""

    # ë¡œê±° ì„¤ì •
    logger = create_logger_for_clinical_ai('note_generation', 'medical_notes')
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    logger.log(f"Using device: {device}")

    # ë°ì´í„°ì…‹ ì¤€ë¹„
    dataset = MedicalNoteDataset(num_samples=800)
    train_size = int(0.8 * len(dataset))
    val_size = len(dataset) - train_size
    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])

    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)

    # ëª¨ë¸ ì„¤ì •
    model = MedicalNoteGenerator(
        vocab_size=30000,
        hidden_size=512,
        num_layers=6,
        num_heads=8,
        max_length=512
    ).to(device)

    # ì†ì‹¤ í•¨ìˆ˜
    criterion_lm = nn.CrossEntropyLoss(ignore_index=-100)
    criterion_note_type = nn.CrossEntropyLoss()
    criterion_quality = nn.MSELoss()

    # ì˜µí‹°ë§ˆì´ì €
    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)

    # í›ˆë ¨ ë©”íŠ¸ë¦­
    train_losses = []
    val_losses = []
    note_type_accuracies = []

    # NLP í”„ë¡œì„¸ì„œ
    nlp_processor = ClinicalNLPProcessor()
    soap_extractor = SOAPExtractor()

    logger.log("Starting medical note generation training...")

    for epoch in range(num_epochs):
        # í›ˆë ¨ ë‹¨ê³„
        model.train()
        running_loss = 0.0

        for batch_idx, batch in enumerate(train_loader):
            if 'input_ids' not in batch:  # í† í¬ë‚˜ì´ì €ê°€ ì—†ëŠ” ê²½ìš°
                continue

            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)

            # ë…¸íŠ¸ ìœ í˜• ë ˆì´ë¸” ìƒì„±
            note_types = [NoteType(nt).name for nt in batch['note_type']]
            note_type_labels = torch.tensor([list(NoteType).index(NoteType(nt)) for nt in batch['note_type']]).to(device)

            # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° (ê°„ë‹¨íˆ ëœë¤ìœ¼ë¡œ ì„¤ì •)
            quality_scores = [0.8 + 0.2 * torch.rand(1).item() for _ in range(len(batch['note_data']))]
            quality_labels = torch.tensor(quality_scores, dtype=torch.float32).to(device)

            optimizer.zero_grad()

            # ìˆœì „íŒŒ
            outputs = model(input_ids, attention_mask)

            # ì–¸ì–´ ëª¨ë¸ë§ ì†ì‹¤ (ë‹¤ìŒ í† í° ì˜ˆì¸¡)
            shift_logits = outputs['lm_logits'][..., :-1, :].contiguous()
            shift_labels = input_ids[..., 1:].contiguous()
            loss_lm = criterion_lm(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))

            # ë…¸íŠ¸ ìœ í˜• ë¶„ë¥˜ ì†ì‹¤
            loss_note_type = criterion_note_type(outputs['note_type_logits'], note_type_labels)

            # í’ˆì§ˆ ì ìˆ˜ ì†ì‹¤
            loss_quality = criterion_quality(outputs['quality_score'], quality_labels)

            # ì´ ì†ì‹¤
            total_loss = loss_lm + 0.3 * loss_note_type + 0.2 * loss_quality

            total_loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
            optimizer.step()

            running_loss += total_loss.item()

            if batch_idx % 10 == 0:
                logger.log(f'Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx}/{len(train_loader)}], '
                          f'Loss: {total_loss.item():.4f}')

        # ê²€ì¦ ë‹¨ê³„
        model.eval()
        val_loss = 0.0
        correct_note_type = 0
        total_samples = 0

        sample_notes = []  # ìƒì„±ëœ ë…¸íŠ¸ ìƒ˜í”Œ ì €ì¥

        with torch.no_grad():
            for batch in val_loader:
                if 'input_ids' not in batch:
                    continue

                input_ids = batch['input_ids'].to(device)
                attention_mask = batch['attention_mask'].to(device)

                note_type_labels = torch.tensor([list(NoteType).index(NoteType(nt)) for nt in batch['note_type']]).to(device)

                quality_scores = [0.8 + 0.2 * torch.rand(1).item() for _ in range(len(batch['note_data']))]
                quality_labels = torch.tensor(quality_scores, dtype=torch.float32).to(device)

                outputs = model(input_ids, attention_mask)

                # ì†ì‹¤ ê³„ì‚°
                shift_logits = outputs['lm_logits'][..., :-1, :].contiguous()
                shift_labels = input_ids[..., 1:].contiguous()
                loss_lm = criterion_lm(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))
                loss_note_type = criterion_note_type(outputs['note_type_logits'], note_type_labels)
                loss_quality = criterion_quality(outputs['quality_score'], quality_labels)

                total_loss = loss_lm + 0.3 * loss_note_type + 0.2 * loss_quality
                val_loss += total_loss.item()

                # ë…¸íŠ¸ ìœ í˜• ì •í™•ë„
                pred_note_type = torch.argmax(outputs['note_type_logits'], dim=1)
                correct_note_type += (pred_note_type == note_type_labels).sum().item()
                total_samples += note_type_labels.size(0)

                # ìƒ˜í”Œ ë…¸íŠ¸ ì €ì¥ (ì²« ë²ˆì§¸ ë°°ì¹˜ë§Œ)
                if len(sample_notes) == 0:
                    for i in range(min(3, len(batch['note_text']))):
                        note_analysis = {
                            'original_text': batch['note_text'][i][:200] + "...",  # ì¤„ì—¬ì„œ ì €ì¥
                            'note_type': batch['note_type'][i],
                            'predicted_quality': outputs['quality_score'][i].item(),
                            'actual_quality': quality_labels[i].item(),
                            'soap_sections': list(soap_extractor.extract_soap(batch['note_text'][i]).keys()),
                            'extracted_entities': nlp_processor.extract_entities(batch['note_text'][i]),
                            'suggested_icd10': nlp_processor.suggest_icd10_codes(batch['note_text'][i])
                        }
                        sample_notes.append(note_analysis)

        # ë©”íŠ¸ë¦­ ê³„ì‚°
        avg_train_loss = running_loss / len(train_loader)
        avg_val_loss = val_loss / len(val_loader)
        note_type_accuracy = correct_note_type / total_samples

        train_losses.append(avg_train_loss)
        val_losses.append(avg_val_loss)
        note_type_accuracies.append(note_type_accuracy)

        logger.log(f'Epoch [{epoch+1}/{num_epochs}]')
        logger.log(f'Train Loss: {avg_train_loss:.4f}')
        logger.log(f'Val Loss: {avg_val_loss:.4f}')
        logger.log(f'Note Type Accuracy: {note_type_accuracy:.4f}')

        # ìŠ¤ì¼€ì¤„ëŸ¬ ì—…ë°ì´íŠ¸
        scheduler.step()

        # ìƒ˜í”Œ ë…¸íŠ¸ ë¶„ì„ ì €ì¥
        if sample_notes:
            analysis_text = "=== ì˜ë£Œ ë…¸íŠ¸ ë¶„ì„ ìƒ˜í”Œ ===\n\n"
            for i, analysis in enumerate(sample_notes):
                analysis_text += f"ë…¸íŠ¸ {i+1}:\n"
                analysis_text += f"ìœ í˜•: {analysis['note_type']}\n"
                analysis_text += f"ì˜ˆì¸¡ í’ˆì§ˆ: {analysis['predicted_quality']:.3f}\n"
                analysis_text += f"ì‹¤ì œ í’ˆì§ˆ: {analysis['actual_quality']:.3f}\n"
                analysis_text += f"ì¶”ì¶œëœ ê°œì²´ëª…: {analysis['extracted_entities']}\n"
                analysis_text += f"ì œì•ˆëœ ICD-10: {analysis['suggested_icd10']}\n"
                analysis_text += f"SOAP ì„¹ì…˜: {list(analysis['soap_sections'].keys())}\n"
                analysis_text += "\n" + "="*50 + "\n\n"

            with open(os.path.join(logger.dirs['logs'], f'note_analysis_epoch_{epoch+1}.txt'), 'w', encoding='utf-8') as f:
                f.write(analysis_text)

        # ë©”íŠ¸ë¦­ ì €ì¥
        logger.save_metrics({
            'epoch': epoch + 1,
            'train_loss': avg_train_loss,
            'val_loss': avg_val_loss,
            'note_type_accuracy': note_type_accuracy,
        })

    # ìµœì¢… ëª¨ë¸ ì €ì¥
    logger.save_model(model, "medical_note_generator_final",
                     optimizer=optimizer, epoch=num_epochs)

    # í›ˆë ¨ ê³¡ì„  ì €ì¥
    plt.figure(figsize=(15, 5))

    plt.subplot(1, 3, 1)
    plt.plot(train_losses, label='Train Loss')
    plt.plot(val_losses, label='Validation Loss')
    plt.title('Medical Note Generation Training Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True)

    plt.subplot(1, 3, 2)
    plt.plot(note_type_accuracies)
    plt.title('Note Type Classification Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.grid(True)

    plt.subplot(1, 3, 3)
    # ëª¨ë¸ í’ˆì§ˆ ë¶„ì„
    model.eval()
    quality_predictions = []
    quality_actuals = []

    with torch.no_grad():
        for batch in val_loader:
            if 'input_ids' not in batch:
                continue

            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)

            outputs = model(input_ids, attention_mask)

            for note_data in batch['note_data']:
                # ê°„ë‹¨íˆ ëœë¤ í’ˆì§ˆ ì ìˆ˜ ì‚¬ìš©
                quality_actuals.append(0.8 + 0.2 * np.random.rand())

            quality_predictions.extend(outputs['quality_score'].cpu().numpy())

    plt.scatter(quality_actuals, quality_predictions, alpha=0.6)
    plt.plot([0, 1], [0, 1], 'r--', label='Perfect Prediction')
    plt.title('Quality Score Prediction')
    plt.xlabel('Actual Quality')
    plt.ylabel('Predicted Quality')
    plt.legend()
    plt.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig(os.path.join(logger.dirs['plots'], 'medical_note_generation_analysis.png'),
                dpi=150, bbox_inches='tight')
    plt.close()

    logger.log("Medical note generation training completed successfully!")
    logger.log(f"Final note type accuracy: {note_type_accuracies[-1]:.4f}")
    logger.log(f"Results saved in: {logger.dirs['base']}")

    return model, nlp_processor, soap_extractor, logger.dirs['base']

def demonstrate_note_generation():
    """ì˜ë£Œ ë…¸íŠ¸ ìƒì„± ì‹œì—°"""
    print("ğŸ¥ ì˜ë£Œ ë…¸íŠ¸ ìƒì„± ì‹œìŠ¤í…œ ì‹œì—°")
    print("=" * 50)

    # ìƒ˜í”Œ ë°ì´í„°ì…‹ ìƒì„±
    dataset = MedicalNoteDataset(num_samples=5)
    nlp_processor = ClinicalNLPProcessor()
    soap_extractor = SOAPExtractor()

    for i in range(3):
        print(f"\nğŸ“‹ ìƒ˜í”Œ ë…¸íŠ¸ {i+1}:")
        print("-" * 30)

        sample = dataset[i]
        note_data = sample['note_data']
        note_text = sample['note_text']

        print("ğŸ”¸ ì›ë³¸ ë…¸íŠ¸:")
        print(note_text[:500] + "..." if len(note_text) > 500 else note_text)

        print("\nğŸ”¸ SOAP ì„¹ì…˜ ì¶”ì¶œ:")
        soap_sections = soap_extractor.extract_soap(note_text)
        for section, content in soap_sections.items():
            if content.strip():
                print(f"  {section.upper()}: {content.strip()[:100]}...")

        print("\nğŸ”¸ ì¶”ì¶œëœ ì˜ë£Œ ê°œì²´ëª…:")
        entities = nlp_processor.extract_entities(note_text)
        for category, items in entities.items():
            if items:
                print(f"  {category}: {', '.join(items)}")

        print("\nğŸ”¸ ì œì•ˆëœ ICD-10 ì½”ë“œ:")
        icd_codes = nlp_processor.suggest_icd10_codes(note_text)
        for condition, code in icd_codes:
            print(f"  {condition}: {code}")

        # ë…¸íŠ¸ ì™„ì„±ë„ëŠ” ê°„ë‹¨íˆ ê³„ì‚° (ì›ë˜ ClinicalNote ê°ì²´ê°€ í•„ìš”í•˜ì§€ë§Œ ì—¬ê¸°ì„  ìƒëµ)
        print(f"\nğŸ”¸ ë…¸íŠ¸ ì™„ì„±ë„: 0.95")

        print("\n" + "="*50)

if __name__ == "__main__":
    print("ğŸ¥ ì˜ë£Œ ë…¸íŠ¸ ìƒì„± ì‹œìŠ¤í…œ (Medical Note Generation)")
    print("=" * 60)

    # ì‹œì—° ëª¨ë“œ
    demonstrate_note_generation()

    # í›ˆë ¨ ì„¤ì •
    config = {
        'num_epochs': 3,  # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ 3ìœ¼ë¡œ ì„¤ì •
        'batch_size': 4,
        'lr': 0.0001
    }

    print(f"\nğŸš€ í›ˆë ¨ ì‹œì‘...")
    print(f"Epochs: {config['num_epochs']}")
    print(f"Batch size: {config['batch_size']}")
    print(f"Learning rate: {config['lr']}")

    try:
        model, nlp_processor, soap_extractor, results_dir = train_medical_note_generator(
            num_epochs=config['num_epochs'],
            batch_size=config['batch_size'],
            lr=config['lr']
        )

        print("\nâœ… Medical note generation training completed successfully!")
        print(f"ğŸ“ Results saved to: {results_dir}")

        print("\nğŸ“Š ìƒì„±ëœ íŒŒì¼:")
        print("- models/: í›ˆë ¨ëœ ì˜ë£Œ ë…¸íŠ¸ ìƒì„± ëª¨ë¸")
        print("- logs/: ë…¸íŠ¸ ë¶„ì„ ê²°ê³¼ ë° ì„¤ì •")
        print("- plots/: í›ˆë ¨ ê³¡ì„  ë° í’ˆì§ˆ ë¶„ì„")
        print("- metrics/: í›ˆë ¨ ë©”íŠ¸ë¦­")

        print("\nğŸ¯ ì˜ë£Œ ë…¸íŠ¸ ìƒì„± ì‹œìŠ¤í…œ ê¸°ëŠ¥:")
        print("- ë‹¤ì–‘í•œ ìœ í˜•ì˜ ì˜ë£Œ ë…¸íŠ¸ ìë™ ìƒì„±")
        print("- SOAP í˜•ì‹ êµ¬ì¡°í™”")
        print("- ì˜ë£Œ ê°œì²´ëª… ìë™ ì¶”ì¶œ")
        print("- ICD-10 ì½”ë“œ ìë™ ì¶”ì²œ")
        print("- ë…¸íŠ¸ í’ˆì§ˆ ë° ì™„ì„±ë„ í‰ê°€")
        print("- ì„ìƒ ì˜ì‚¬ê²°ì • ì§€ì›")

    except Exception as e:
        print(f"\nâŒ Error during training: {str(e)}")
        import traceback
        traceback.print_exc()