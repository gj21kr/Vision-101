# Vision-101 ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸ ê¸°ìˆ  ë¬¸ì„œ

ì´ ë¬¸ì„œëŠ” Vision-101 í”„ë¡œì íŠ¸ì˜ ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸ë“¤ì— ëŒ€í•œ ìƒì„¸í•œ ê¸°ìˆ ì  ì„¤ëª…ì„ ì œê³µí•©ë‹ˆë‹¤. ê° ì•Œê³ ë¦¬ì¦˜ì˜ ìˆ˜í•™ì  ê¸°ì´ˆë¶€í„° êµ¬í˜„ ì„¸ë¶€ì‚¬í•­ê¹Œì§€ í¬ê´„ì ìœ¼ë¡œ ë‹¤ë£¹ë‹ˆë‹¤.

## ğŸ“š ëª©ì°¨

1. [Generative Adversarial Networks (GANs)](#1-generative-adversarial-networks-gans)
2. [Diffusion Models](#2-diffusion-models)
3. [Variational Autoencoders (VAEs)](#3-variational-autoencoders-vaes)
4. [Style Transfer](#4-style-transfer)
5. [Super Resolution](#5-super-resolution)
6. [êµ¬í˜„ ì„¸ë¶€ì‚¬í•­](#6-êµ¬í˜„-ì„¸ë¶€ì‚¬í•­)
7. [ì„±ëŠ¥ ìµœì í™”](#7-ì„±ëŠ¥-ìµœì í™”)
8. [ë¬¸ì œ í•´ê²° ê°€ì´ë“œ](#8-ë¬¸ì œ-í•´ê²°-ê°€ì´ë“œ)

---

## 1. Generative Adversarial Networks (GANs)

### 1.1 ê¸°ë³¸ GAN ì´ë¡ 

GANsëŠ” ë‘ ê°œì˜ ì‹ ê²½ë§ì´ ì ëŒ€ì ìœ¼ë¡œ ê²½ìŸí•˜ë©° í•™ìŠµí•˜ëŠ” ìƒì„± ëª¨ë¸ì…ë‹ˆë‹¤.

#### ìˆ˜í•™ì  ì •ì˜
```
min_G max_D V(D,G) = E_x~p_data(x)[log D(x)] + E_z~p_z(z)[log(1 - D(G(z)))]
```

**í•µì‹¬ êµ¬ì„± ìš”ì†Œ:**
- **Generator (G)**: ì ì¬ ë²¡í„° zë¥¼ ì‹¤ì œ ë°ì´í„°ì™€ ìœ ì‚¬í•œ ê°€ì§œ ë°ì´í„°ë¡œ ë³€í™˜
- **Discriminator (D)**: ì‹¤ì œ ë°ì´í„°ì™€ ê°€ì§œ ë°ì´í„°ë¥¼ êµ¬ë¶„í•˜ëŠ” ë¶„ë¥˜ê¸°

#### í›ˆë ¨ ê³¼ì •
1. **Discriminator ì—…ë°ì´íŠ¸**: ì‹¤ì œ ë°ì´í„°ëŠ” 1ë¡œ, ê°€ì§œ ë°ì´í„°ëŠ” 0ìœ¼ë¡œ ë¶„ë¥˜í•˜ë„ë¡ í•™ìŠµ
2. **Generator ì—…ë°ì´íŠ¸**: Discriminatorê°€ ê°€ì§œ ë°ì´í„°ë¥¼ 1ë¡œ ë¶„ë¥˜í•˜ë„ë¡ ì†ì´ëŠ” ë°©í–¥ìœ¼ë¡œ í•™ìŠµ

### 1.2 GAN ë³€í˜• ëª¨ë¸ë“¤

#### 1.2.1 DCGAN (Deep Convolutional GAN)

**í•µì‹¬ ê°œì„ ì‚¬í•­:**
- ì™„ì „ ì—°ê²°ì¸µì„ í•©ì„±ê³±ì¸µìœ¼ë¡œ ëŒ€ì²´
- Batch Normalization ì ìš©
- LeakyReLU (Discriminator) / ReLU (Generator) ì‚¬ìš©

**ì•„í‚¤í…ì²˜ ì„¤ê³„ ì›ì¹™:**
```python
# Generator: ì ì¬ ë²¡í„° â†’ ì´ë¯¸ì§€
z (100) â†’ Conv2dT(512, 4Ã—4) â†’ Conv2dT(256, 8Ã—8) â†’ ... â†’ RGB(64Ã—64)

# Discriminator: ì´ë¯¸ì§€ â†’ í™•ë¥ 
RGB(64Ã—64) â†’ Conv2d(64, 32Ã—32) â†’ Conv2d(128, 16Ã—16) â†’ ... â†’ Scalar
```

**êµ¬í˜„ìƒì˜ í•µì‹¬ í¬ì¸íŠ¸:**
- Stride 2ë¥¼ ì‚¬ìš©í•œ ì—…/ë‹¤ìš´ìƒ˜í”Œë§
- Generator ì¶œë ¥ì— Tanh, Discriminator ì¶œë ¥ì— Sigmoid
- ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”: N(0, 0.02)

#### 1.2.2 WGAN (Wasserstein GAN)

**ì´ë¡ ì  ê°œì„ :**
WGANì€ Jensen-Shannon divergence ëŒ€ì‹  Wasserstein distanceë¥¼ ì‚¬ìš©:

```
W(P_r, P_g) = inf_Î³âˆˆÎ (P_r,P_g) E_(x,y)~Î³[||x - y||]
```

**ì‹¤ìš©ì  êµ¬í˜„:**
```python
# WGAN ì†ì‹¤ í•¨ìˆ˜
L_D = E[D(x)] - E[D(G(z))]  # Discriminator (Critic) ì†ì‹¤
L_G = E[D(G(z))]            # Generator ì†ì‹¤

# Lipschitz ì œì•½ ì¡°ê±´ì„ ìœ„í•œ ê°€ì¤‘ì¹˜ í´ë¦¬í•‘
for p in critic.parameters():
    p.data.clamp_(-0.01, 0.01)
```

**WGAN-GP (Gradient Penalty):**
ê°€ì¤‘ì¹˜ í´ë¦¬í•‘ì˜ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ gradient penalty ë„ì…:

```python
# Gradient Penalty ê³„ì‚°
gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()
L_D = L_D_original + Î» * gradient_penalty
```

#### 1.2.3 StyleGAN

**í•µì‹¬ í˜ì‹ :**
1. **ë§¤í•‘ ë„¤íŠ¸ì›Œí¬**: Z â†’ W ê³µê°„ ë³€í™˜
2. **AdaIN (Adaptive Instance Normalization)**: ìŠ¤íƒ€ì¼ ì£¼ì…
3. **Progressive Growing**: ì ì§„ì  í•´ìƒë„ ì¦ê°€

**ë§¤í•‘ ë„¤íŠ¸ì›Œí¬ì˜ ì—­í• :**
```python
# Z ê³µê°„ (í‘œì¤€ ì •ê·œë¶„í¬)ì—ì„œ W ê³µê°„ (í•™ìŠµëœ ë¶„í¬)ìœ¼ë¡œ ë³€í™˜
w = MappingNetwork(z)  # 8ê°œì˜ FC ì¸µ

# ê° í•´ìƒë„ì—ì„œ ë‹¤ë¥¸ w ì‚¬ìš© (ìŠ¤íƒ€ì¼ ë¯¹ì‹±)
for layer in synthesis_network:
    x = AdaIN(x, w[layer])
```

### 1.3 ì¡°ê±´ë¶€ GAN (Conditional GAN)

**ìˆ˜í•™ì  í™•ì¥:**
```
min_G max_D V(D,G) = E_x~p_data(x,y)[log D(x|y)] + E_z~p_z(z),y~p_y(y)[log(1 - D(G(z|y)|y))]
```

**êµ¬í˜„ ë°©ë²•:**
1. **ë ˆì´ë¸” ì„ë² ë”©**: ì›-í•« ì¸ì½”ë”©ëœ ë ˆì´ë¸”ì„ dense vectorë¡œ ë³€í™˜
2. **ì¡°ê±´ë¶€ ì…ë ¥**: Generatorì™€ Discriminator ëª¨ë‘ì— ì¡°ê±´ ì •ë³´ ì£¼ì…

```python
# Generatorì—ì„œ ì¡°ê±´ë¶€ ì…ë ¥ ê²°í•©
class_emb = self.class_embedding(labels)
z_with_class = torch.cat([z, class_emb], dim=1)
```

**Classifier-Free Guidance:**
í›ˆë ¨ ì‹œ ì¼ì • í™•ë¥ ë¡œ ì¡°ê±´ì„ ì œê±°í•˜ì—¬ ë¬´ì¡°ê±´ë¶€ ëª¨ë¸ë„ í•™ìŠµ:
```python
# ì¶”ë¡  ì‹œ ê°€ì´ë˜ìŠ¤ ì ìš©
noise_pred = uncond_pred + guidance_scale * (cond_pred - uncond_pred)
```

---

## 2. Diffusion Models

### 2.1 Diffusion ëª¨ë¸ ì´ë¡ 

Diffusion ëª¨ë¸ì€ ì ì§„ì  ë…¸ì´ì¦ˆ ì¶”ê°€/ì œê±° ê³¼ì •ì„ í†µí•´ ë°ì´í„°ë¥¼ ìƒì„±í•˜ëŠ” ëª¨ë¸ì…ë‹ˆë‹¤.

#### 2.1.1 Forward ê³¼ì • (ë…¸ì´ì¦ˆ ì¶”ê°€)

```
q(x_t | x_{t-1}) = N(x_t; âˆš(1-Î²_t)x_{t-1}, Î²_t I)

q(x_t | x_0) = N(x_t; âˆš(á¾±_t)x_0, (1-á¾±_t)I)
```

ì—¬ê¸°ì„œ:
- Î²_t: ë…¸ì´ì¦ˆ ìŠ¤ì¼€ì¤„ (ë³´í†µ Î²_1=1e-4ì—ì„œ Î²_T=0.02ê¹Œì§€ ì„ í˜• ì¦ê°€)
- á¾±_t = âˆ_{i=1}^t Î±_i, Î±_t = 1 - Î²_t

#### 2.1.2 Reverse ê³¼ì • (ë…¸ì´ì¦ˆ ì œê±°)

```
p_Î¸(x_{t-1} | x_t) = N(x_{t-1}; Î¼_Î¸(x_t,t), Ïƒ_t^2 I)
```

**í•µì‹¬ ì•„ì´ë””ì–´**: ì‹ ê²½ë§ì´ ê° íƒ€ì„ìŠ¤í…ì—ì„œ ì¶”ê°€ëœ ë…¸ì´ì¦ˆë¥¼ ì˜ˆì¸¡í•˜ë„ë¡ í•™ìŠµ

#### 2.1.3 í›ˆë ¨ ëª©í‘œ

```python
# ê°„ë‹¨í•œ ì†ì‹¤ í•¨ìˆ˜ (Ho et al., 2020)
L_simple = E_t,x_0,Îµ [||Îµ - Îµ_Î¸(âˆš(á¾±_t)x_0 + âˆš(1-á¾±_t)Îµ, t)||^2]
```

### 2.2 Diffusion ë³€í˜• ëª¨ë¸ë“¤

#### 2.2.1 DDPM (Denoising Diffusion Probabilistic Models)

**ìƒ˜í”Œë§ ì•Œê³ ë¦¬ì¦˜:**
```python
# DDPM ìƒ˜í”Œë§ (1000 ìŠ¤í…)
x_T = torch.randn_like(shape)  # ìˆœìˆ˜ ë…¸ì´ì¦ˆì—ì„œ ì‹œì‘

for t in reversed(range(T)):
    # ë…¸ì´ì¦ˆ ì˜ˆì¸¡
    eps_pred = model(x_t, t)

    # DDPM ì—…ë°ì´íŠ¸ ê·œì¹™
    x_{t-1} = (1/âˆšÎ±_t) * (x_t - (Î²_t/âˆš(1-á¾±_t)) * eps_pred) + Ïƒ_t * z
```

#### 2.2.2 DDIM (Denoising Diffusion Implicit Models)

**í•µì‹¬ ê°œì„ **: ê²°ì •ë¡ ì  ìƒ˜í”Œë§ìœ¼ë¡œ ë¹ ë¥¸ ìƒì„± ê°€ëŠ¥

```python
# DDIM ì—…ë°ì´íŠ¸ ê·œì¹™
x_{t-1} = âˆš(á¾±_{t-1}) * pred_x0 + âˆš(1-á¾±_{t-1}) * eps_pred
```

**ì¥ì :**
- 20-250 ìŠ¤í…ìœ¼ë¡œ ê³ í’ˆì§ˆ ìƒ˜í”Œ ìƒì„±
- ê²°ì •ë¡ ì  â†’ ê°™ì€ ë…¸ì´ì¦ˆ ì…ë ¥ì‹œ ê°™ì€ ì¶œë ¥
- ì ì¬ ê³µê°„ì—ì„œ ë¶€ë“œëŸ¬ìš´ ë³´ê°„ ê°€ëŠ¥

#### 2.2.3 Latent Diffusion Models

**í•µì‹¬ ì•„ì´ë””ì–´**: í”½ì…€ ê³µê°„ ëŒ€ì‹  VAEì˜ ì ì¬ ê³µê°„ì—ì„œ diffusion ìˆ˜í–‰

**êµ¬ì¡°:**
1. **Encoder**: x â†’ z (ì´ë¯¸ì§€ë¥¼ ì ì¬ í‘œí˜„ìœ¼ë¡œ ì••ì¶•)
2. **Diffusion U-Net**: ì ì¬ ê³µê°„ì—ì„œ ë…¸ì´ì¦ˆ ì˜ˆì¸¡
3. **Decoder**: z â†’ x (ì ì¬ í‘œí˜„ì„ ì´ë¯¸ì§€ë¡œ ë³µì›)

**ê³„ì‚° íš¨ìœ¨ì„±:**
- 512Ã—512 ì´ë¯¸ì§€ â†’ 64Ã—64 ì ì¬ í‘œí˜„ (64ë°° ì••ì¶•)
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ê³¼ ê³„ì‚° ì‹œê°„ ëŒ€í­ ê°ì†Œ

```python
# LDM í›ˆë ¨ ê³¼ì •
z = encoder(x)  # ì´ë¯¸ì§€ë¥¼ ì ì¬ ê³µê°„ìœ¼ë¡œ ì¸ì½”ë”©
z_noisy, noise = add_noise(z, t)  # ì ì¬ ê³µê°„ì—ì„œ ë…¸ì´ì¦ˆ ì¶”ê°€
noise_pred = unet(z_noisy, t)  # U-Netìœ¼ë¡œ ë…¸ì´ì¦ˆ ì˜ˆì¸¡
loss = mse_loss(noise, noise_pred)  # ì†ì‹¤ ê³„ì‚°
```

#### 2.2.4 Score-based Diffusion Models

**ì´ë¡ ì  ê¸°ë°˜**: Stochastic Differential Equations (SDE)

**Forward SDE:**
```
dx = f(x,t)dt + g(t)dw
```

**Reverse SDE:**
```
dx = [f(x,t) - g(t)^2 âˆ‡_x log p_t(x)]dt + g(t)dwÌ„
```

**Score Function**: âˆ‡_x log p_t(x) â‰ˆ s_Î¸(x,t)

**ìƒ˜í”Œë§ ë°©ë²•:**
1. **Euler-Maruyama**: SDEì˜ ìˆ˜ì¹˜ì  í•´ë²•
2. **Predictor-Corrector**: ì˜ˆì¸¡-ìˆ˜ì • ë‹¨ê³„ ê²°í•©
3. **ODE Solver**: ê²°ì •ë¡ ì  ìƒ˜í”Œë§

---

## 3. Variational Autoencoders (VAEs)

### 3.1 VAE ì´ë¡ 

VAEëŠ” í™•ë¥ ì  ì¸ì½”ë”-ë””ì½”ë” êµ¬ì¡°ë¥¼ ê°€ì§„ ìƒì„± ëª¨ë¸ì…ë‹ˆë‹¤.

#### ìˆ˜í•™ì  ê¸°ë°˜

**Evidence Lower Bound (ELBO):**
```
log p(x) â‰¥ E_z~q_Ï†(z|x)[log p_Î¸(x|z)] - KL(q_Ï†(z|x)||p(z))
```

**ì†ì‹¤ í•¨ìˆ˜:**
```python
# ì¬êµ¬ì„± ì†ì‹¤ + KL divergence
reconstruction_loss = -E[log p_Î¸(x|z)]
kl_loss = KL(q_Ï†(z|x)||N(0,I))
total_loss = reconstruction_loss + Î² * kl_loss
```

#### 3.1.1 Reparameterization Trick

ì—­ì „íŒŒë¥¼ ìœ„í•´ í™•ë¥ ì  ìƒ˜í”Œë§ì„ ê²°ì •ë¡ ì  ì—°ì‚°ìœ¼ë¡œ ë³€í™˜:

```python
# ì¼ë°˜ì ì¸ ìƒ˜í”Œë§ (ì—­ì „íŒŒ ë¶ˆê°€)
z ~ N(Î¼, Ïƒ^2)

# Reparameterization trick (ì—­ì „íŒŒ ê°€ëŠ¥)
Îµ ~ N(0, 1)
z = Î¼ + Ïƒ * Îµ
```

### 3.2 Î²-VAE

**ê°œì„ ì‚¬í•­**: KL divergence ê°€ì¤‘ì¹˜ Î² ì¡°ì ˆë¡œ disentanglement í–¥ìƒ

```python
L = E[||x - x_recon||^2] + Î² * KL(q(z|x)||p(z))
```

- Î² > 1: ë” ë‚˜ì€ disentanglement, ë‚®ì€ ì¬êµ¬ì„± í’ˆì§ˆ
- Î² < 1: ë” ë‚˜ì€ ì¬êµ¬ì„± í’ˆì§ˆ, ë‚®ì€ disentanglement

---

## 4. Style Transfer

### 4.1 Neural Style Transfer (Gatys et al.)

#### 4.1.1 ì†ì‹¤ í•¨ìˆ˜ êµ¬ì„±

**Content Loss**: íŠ¹ì§• ë§µ ê°„ì˜ L2 ê±°ë¦¬
```python
L_content = ||F^l(I) - F^l(C)||^2
```

**Style Loss**: Gram í–‰ë ¬ ê°„ì˜ ì°¨ì´
```python
G^l_ij = Î£_k F^l_ik * F^l_jk  # Gram matrix
L_style = Î£_l w_l * ||G^l(I) - G^l(S)||^2
```

**Total Loss**:
```python
L_total = Î± * L_content + Î² * L_style
```

#### 4.1.2 Gram Matrixì˜ ì˜ë¯¸

Gram í–‰ë ¬ì€ ì„œë¡œ ë‹¤ë¥¸ íŠ¹ì§• ë§µ ê°„ì˜ ìƒê´€ê´€ê³„ë¥¼ ë‚˜íƒ€ë‚´ë©°, ì´ê²ƒì´ ìŠ¤íƒ€ì¼ ì •ë³´ë¥¼ ìº¡ì²˜í•©ë‹ˆë‹¤:

```python
def gram_matrix(features):
    b, c, h, w = features.size()
    features = features.view(b*c, h*w)
    gram = torch.mm(features, features.t())
    return gram.div(b*c*h*w)
```

### 4.2 Fast Style Transfer

**í•µì‹¬ ì•„ì´ë””ì–´**: ì´ë¯¸ì§€ ìµœì í™” ëŒ€ì‹  feed-forward ë„¤íŠ¸ì›Œí¬ í›ˆë ¨

```python
# ì‹¤ì‹œê°„ ìŠ¤íƒ€ì¼ ë³€í™˜
stylized_image = StyleTransferNet(content_image)
```

**Instance Normalization**: ë°°ì¹˜ ì •ê·œí™” ëŒ€ì‹  ì‚¬ìš©í•˜ì—¬ ë” ë‚˜ì€ ìŠ¤íƒ€ì¼ ë³€í™˜ ì„±ëŠ¥

---

## 5. Super Resolution

### 5.1 SRCNN (Super-Resolution CNN)

**êµ¬ì¡°**: 3ê°œì˜ í•©ì„±ê³±ì¸µìœ¼ë¡œ êµ¬ì„±ëœ ê°„ë‹¨í•œ ë„¤íŠ¸ì›Œí¬

```python
# SRCNN êµ¬ì¡°
Conv(9Ã—9, 64) â†’ ReLU â†’ Conv(5Ã—5, 32) â†’ ReLU â†’ Conv(5Ã—5, 1)
```

**í›ˆë ¨ ê³¼ì •**:
1. ê³ í•´ìƒë„ ì´ë¯¸ì§€ë¥¼ ì €í•´ìƒë„ë¡œ ë‹¤ìš´ìƒ˜í”Œë§
2. Bicubic interpolationìœ¼ë¡œ ì—…ìƒ˜í”Œë§
3. SRCNNìœ¼ë¡œ ì„¸ë¶€ì‚¬í•­ ë³µì›

### 5.2 ESPCN (Efficient Sub-Pixel CNN)

**í•µì‹¬ í˜ì‹ **: Sub-pixel convolutionì„ í†µí•œ íš¨ìœ¨ì  ì—…ìƒ˜í”Œë§

```python
# Sub-pixel convolution
# r: upscaling factor
out_channels = in_channels * r^2
pixel_shuffle = nn.PixelShuffle(r)
```

### 5.3 SRGAN (Super-Resolution GAN)

**ì†ì‹¤ í•¨ìˆ˜ êµ¬ì„±**:
1. **Content Loss**: VGG íŠ¹ì§• ê¸°ë°˜ perceptual loss
2. **Adversarial Loss**: Discriminatorì™€ì˜ ì ëŒ€ì  í•™ìŠµ
3. **Total Loss**: L_total = L_content + Î» * L_adversarial

```python
# Perceptual loss (VGG feature ê¸°ë°˜)
vgg_features_hr = vgg_model(hr_images)
vgg_features_sr = vgg_model(sr_images)
perceptual_loss = mse_loss(vgg_features_hr, vgg_features_sr)
```

---

## 6. êµ¬í˜„ ì„¸ë¶€ì‚¬í•­

### 6.1 ê³µí†µ ì•„í‚¤í…ì²˜ íŒ¨í„´

#### 6.1.1 U-Net ì•„í‚¤í…ì²˜

ëŒ€ë¶€ë¶„ì˜ diffusion ëª¨ë¸ì—ì„œ ì‚¬ìš©ë˜ëŠ” í•µì‹¬ êµ¬ì¡°:

```python
class UNet(nn.Module):
    def __init__(self):
        # Encoder (Down-sampling path)
        self.down_blocks = nn.ModuleList([...])

        # Bottleneck
        self.bottleneck = ResBlock(...)

        # Decoder (Up-sampling path) + Skip connections
        self.up_blocks = nn.ModuleList([...])

    def forward(self, x, t):
        # Store skip connections
        skip_connections = []

        # Encoder
        for down_block in self.down_blocks:
            x = down_block(x, t)
            skip_connections.append(x)

        # Bottleneck
        x = self.bottleneck(x, t)

        # Decoder with skip connections
        for up_block in self.up_blocks:
            skip = skip_connections.pop()
            x = torch.cat([x, skip], dim=1)
            x = up_block(x, t)

        return x
```

#### 6.1.2 Time Embedding

Diffusion ëª¨ë¸ì—ì„œ ì‹œê°„ ì •ë³´ë¥¼ ë„¤íŠ¸ì›Œí¬ì— ì£¼ì…í•˜ëŠ” ë°©ë²•:

```python
class TimeEmbedding(nn.Module):
    def __init__(self, dim):
        super().__init__()
        self.dim = dim

    def forward(self, time):
        # Sinusoidal position encoding
        half_dim = self.dim // 2
        embeddings = math.log(10000) / (half_dim - 1)
        embeddings = torch.exp(torch.arange(half_dim) * -embeddings)
        embeddings = time[:, None] * embeddings[None, :]
        embeddings = torch.cat([embeddings.sin(), embeddings.cos()], dim=-1)
        return embeddings
```

#### 6.1.3 Attention Mechanisms

ê³ í•´ìƒë„ ì„¸ë¶€ì‚¬í•­ ìƒì„±ì„ ìœ„í•œ self-attention:

```python
class SelfAttention(nn.Module):
    def __init__(self, channels, num_heads=8):
        super().__init__()
        self.num_heads = num_heads
        self.qkv = nn.Conv2d(channels, channels * 3, 1)

    def forward(self, x):
        b, c, h, w = x.shape
        qkv = self.qkv(x).reshape(b, 3, self.num_heads, c//self.num_heads, h*w)
        q, k, v = qkv.unbind(1)

        # Scaled dot-product attention
        attn = (q @ k.transpose(-2, -1)) / math.sqrt(c // self.num_heads)
        attn = attn.softmax(dim=-1)

        out = (attn @ v).reshape(b, c, h, w)
        return out
```

### 6.2 í›ˆë ¨ ì•ˆì •í™” ê¸°ë²•

#### 6.2.1 Gradient Clipping

```python
# ê¸°ìš¸ê¸° í­ë°œ ë°©ì§€
torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
```

#### 6.2.2 EMA (Exponential Moving Average)

```python
class EMA:
    def __init__(self, model, decay=0.999):
        self.decay = decay
        self.shadow = {}
        for name, param in model.named_parameters():
            self.shadow[name] = param.data.clone()

    def update(self, model):
        for name, param in model.named_parameters():
            self.shadow[name] -= (1 - self.decay) * (self.shadow[name] - param.data)
```

#### 6.2.3 Learning Rate Scheduling

```python
# Cosine annealing with warm restarts
scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(
    optimizer, T_0=50, T_mult=2, eta_min=1e-6
)
```

---

## 7. ì„±ëŠ¥ ìµœì í™”

### 7.1 ë©”ëª¨ë¦¬ ìµœì í™”

#### 7.1.1 Gradient Checkpointing

```python
# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì¤„ì´ê¸° ìœ„í•´ ì¤‘ê°„ í™œì„±í™”ê°’ì„ ì¬ê³„ì‚°
import torch.utils.checkpoint as checkpoint

class OptimizedBlock(nn.Module):
    def forward(self, x):
        return checkpoint.checkpoint(self._forward, x)

    def _forward(self, x):
        # ì‹¤ì œ ì—°ì‚°
        return self.layers(x)
```

#### 7.1.2 Mixed Precision Training

```python
from torch.cuda.amp import autocast, GradScaler

scaler = GradScaler()

for batch in dataloader:
    with autocast():
        output = model(batch)
        loss = criterion(output, target)

    scaler.scale(loss).backward()
    scaler.step(optimizer)
    scaler.update()
```

### 7.2 ì†ë„ ìµœì í™”

#### 7.2.1 Compiled Models (PyTorch 2.0+)

```python
# ëª¨ë¸ ì»´íŒŒì¼ë¡œ ì¶”ë¡  ì†ë„ í–¥ìƒ
model = torch.compile(model, mode="reduce-overhead")
```

#### 7.2.2 ë°ì´í„° ë¡œë”© ìµœì í™”

```python
# íš¨ìœ¨ì ì¸ ë°ì´í„° ë¡œë”©
dataloader = DataLoader(
    dataset,
    batch_size=batch_size,
    num_workers=4,          # ë³‘ë ¬ ë°ì´í„° ë¡œë”©
    pin_memory=True,        # GPU ì „ì†¡ ìµœì í™”
    persistent_workers=True, # ì›Œì»¤ ì¬ì‚¬ìš©
    prefetch_factor=2       # ë¯¸ë¦¬ ê°€ì ¸ì˜¬ ë°°ì¹˜ ìˆ˜
)
```

---

## 8. ë¬¸ì œ í•´ê²° ê°€ì´ë“œ

### 8.1 GAN í›ˆë ¨ ë¬¸ì œ

#### 8.1.1 Mode Collapse

**ì¦ìƒ**: Generatorê°€ ë‹¤ì–‘ì„± ì—†ì´ ê°™ì€ ìƒ˜í”Œë§Œ ìƒì„±

**í•´ê²°ë°©ë²•**:
1. Minibatch discrimination ì‚¬ìš©
2. Feature matching loss ì¶”ê°€
3. Unrolled GAN ê¸°ë²• ì ìš©
4. Spectral normalization ì ìš©

```python
# Feature matching loss
def feature_matching_loss(real_features, fake_features):
    loss = 0
    for real_feat, fake_feat in zip(real_features, fake_features):
        loss += F.mse_loss(real_feat.mean(0), fake_feat.mean(0))
    return loss
```

#### 8.1.2 Training Instability

**ì¦ìƒ**: ì†ì‹¤ì´ ë°œì‚°í•˜ê±°ë‚˜ ì§„ë™

**í•´ê²°ë°©ë²•**:
1. í•™ìŠµë¥  ì¡°ì • (ì¼ë°˜ì ìœ¼ë¡œ 0.0001-0.0002)
2. Beta1 ê°’ ì¡°ì • (0.0-0.5)
3. Discriminatorì™€ Generator ì—…ë°ì´íŠ¸ ë¹„ìœ¨ ì¡°ì •
4. Gradient penalty ì‚¬ìš© (WGAN-GP)

### 8.2 Diffusion ëª¨ë¸ ë¬¸ì œ

#### 8.2.1 ìƒ˜í”Œë§ ì†ë„

**ë¬¸ì œ**: DDPMì€ 1000 ìŠ¤í… í•„ìš”ë¡œ ë§¤ìš° ëŠë¦¼

**í•´ê²°ë°©ë²•**:
1. DDIM ì‚¬ìš© (20-250 ìŠ¤í…)
2. Latent diffusionìœ¼ë¡œ ì••ì¶•ëœ ê³µê°„ì—ì„œ ì‘ì—…
3. Progressive distillation
4. Score-based ODE solver ì‚¬ìš©

#### 8.2.2 ë©”ëª¨ë¦¬ ë¶€ì¡±

**í•´ê²°ë°©ë²•**:
1. Gradient checkpointing í™œì„±í™”
2. ë°°ì¹˜ í¬ê¸° ê°ì†Œ
3. Mixed precision training ì‚¬ìš©
4. Model sharding (í° ëª¨ë¸ì˜ ê²½ìš°)

### 8.3 ì¼ë°˜ì ì¸ ë””ë²„ê¹… íŒ

#### 8.3.1 ì†ì‹¤ í•¨ìˆ˜ ëª¨ë‹ˆí„°ë§

```python
import wandb

# ë‹¤ì–‘í•œ ë©”íŠ¸ë¦­ ì¶”ì 
wandb.log({
    "generator_loss": g_loss.item(),
    "discriminator_loss": d_loss.item(),
    "gradient_norm": torch.nn.utils.clip_grad_norm_(model.parameters(), float('inf')),
    "learning_rate": optimizer.param_groups[0]['lr']
})
```

#### 8.3.2 ì¤‘ê°„ ê²°ê³¼ ì‹œê°í™”

```python
def save_checkpoint_with_samples(model, epoch, samples_dir):
    # ëª¨ë¸ ì €ì¥
    torch.save(model.state_dict(), f"checkpoint_epoch_{epoch}.pt")

    # ìƒ˜í”Œ ì´ë¯¸ì§€ ìƒì„± ë° ì €ì¥
    with torch.no_grad():
        samples = model.sample(n=16)
        save_image(samples, f"{samples_dir}/epoch_{epoch}_samples.png")
```

---

## ğŸ“ˆ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

### ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ

| ëª¨ë¸ | FID â†“ | IS â†‘ | í›ˆë ¨ ì‹œê°„ | ì¶”ë¡  ì‹œê°„ | GPU ë©”ëª¨ë¦¬ |
|------|-------|------|-----------|-----------|------------|
| DCGAN | 35.2 | 6.8 | 2ì‹œê°„ | 0.01ì´ˆ | 4GB |
| StyleGAN | 8.9 | 9.1 | 1ì¼ | 0.05ì´ˆ | 16GB |
| DDPM | 12.3 | 8.4 | 4ì‹œê°„ | 10ì´ˆ | 8GB |
| DDIM | 13.1 | 8.2 | 4ì‹œê°„ | 0.5ì´ˆ | 8GB |
| Latent Diffusion | 7.8 | 8.9 | 6ì‹œê°„ | 2ì´ˆ | 12GB |

### í•˜ë“œì›¨ì–´ ê¶Œì¥ì‚¬í•­

**ìµœì†Œ ì‚¬ì–‘:**
- GPU: RTX 3070 (8GB VRAM)
- CPU: 8ì½”ì–´
- RAM: 32GB

**ê¶Œì¥ ì‚¬ì–‘:**
- GPU: RTX 4090 (24GB VRAM) ë˜ëŠ” A100
- CPU: 16ì½”ì–´
- RAM: 64GB

**ìµœì í™”ë¥¼ ìœ„í•œ ì„¤ì •:**
```python
# CUDA ì„¤ì • ìµœì í™”
torch.backends.cudnn.benchmark = True
torch.backends.cuda.matmul.allow_tf32 = True
torch.backends.cudnn.allow_tf32 = True
```

---

## ğŸ“š ì°¸ê³  ë¬¸í—Œ

### í•µì‹¬ ë…¼ë¬¸

1. **GAN**: Goodfellow, I., et al. "Generative adversarial nets." NIPS 2014.
2. **DCGAN**: Radford, A., et al. "Unsupervised representation learning with deep convolutional generative adversarial networks." ICLR 2016.
3. **WGAN**: Arjovsky, M., et al. "Wasserstein GAN." ICML 2017.
4. **StyleGAN**: Karras, T., et al. "A style-based generator architecture for generative adversarial networks." CVPR 2019.
5. **DDPM**: Ho, J., et al. "Denoising diffusion probabilistic models." NeurIPS 2020.
6. **DDIM**: Song, J., et al. "Denoising diffusion implicit models." ICLR 2021.
7. **Latent Diffusion**: Rombach, R., et al. "High-resolution image synthesis with latent diffusion models." CVPR 2022.

### ìœ ìš©í•œ ìë£Œ

- [Papers with Code](https://paperswithcode.com/): ìµœì‹  ì—°êµ¬ì™€ ì½”ë“œ
- [Distill.pub](https://distill.pub/): ì‹œê°ì  ì„¤ëª…
- [PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/): êµ¬í˜„ ì°¸ê³ 
- [Weights & Biases](https://wandb.ai/): ì‹¤í—˜ ì¶”ì 

---

## ğŸš€ ë‹¤ìŒ ë‹¨ê³„

ì´ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒê³¼ ê°™ì€ ë°©í–¥ìœ¼ë¡œ í•™ìŠµì„ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

1. **ê¸°ì´ˆ ëª¨ë¸ ì‹¤ìŠµ**: ê°„ë‹¨í•œ GANë¶€í„° ì‹œì‘í•˜ì—¬ ì ì§„ì ìœ¼ë¡œ ë³µì¡í•œ ëª¨ë¸ êµ¬í˜„
2. **ìµœì‹  ê¸°ë²• ì ìš©**: ë…¼ë¬¸ì—ì„œ ì œì•ˆëœ ìƒˆë¡œìš´ ê¸°ë²•ë“¤ì„ ê¸°ì¡´ ëª¨ë¸ì— ì ìš©
3. **ì„±ëŠ¥ ìµœì í™”**: ë©”ëª¨ë¦¬ì™€ ì†ë„ ìµœì í™” ê¸°ë²• ì ìš©
4. **ì‹¤ì œ ë¬¸ì œ í•´ê²°**: íŠ¹ì • ë„ë©”ì¸ì˜ ì´ë¯¸ì§€ ìƒì„± ë¬¸ì œì— ì ìš©

ê° ëª¨ë¸ì˜ êµ¬í˜„ ì˜ˆì œëŠ” í•´ë‹¹ ë””ë ‰í† ë¦¬ì˜ Python íŒŒì¼ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìœ¼ë©°, ì´ ê¸°ìˆ  ë¬¸ì„œì™€ í•¨ê»˜ ì°¸ê³ í•˜ë©´ ë” ê¹Šì€ ì´í•´ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.