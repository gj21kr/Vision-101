#!/usr/bin/env python3
"""
Transformer ê¸°ë°˜ ì˜ë£Œ ì˜ìƒ ë¶„í•  (Medical Image Segmentation with Transformers)

Vision Transformerë¥¼ í™œìš©í•œ ì˜ë£Œ ì˜ìƒ ë¶„í•  ì‹œìŠ¤í…œì…ë‹ˆë‹¤.
SETR (SEgmentation TRansformer)ì™€ Segmenter ì•„í‚¤í…ì²˜ë¥¼ ì˜ë£Œ ì˜ìƒì— íŠ¹í™”í•˜ì—¬ êµ¬í˜„í•˜ì˜€ìŠµë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
- Vision Transformer ì¸ì½”ë”
- Multi-scale Feature Processing
- Patch-based Segmentation
- Medical-specific Loss Functions
- Self-attention Visualization
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torchvision.transforms as transforms
from torch.utils.data import Dataset, DataLoader
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import os
import sys
import math
from sklearn.metrics import jaccard_score, f1_score
sys.path.append('/workspace/Vision-101')
from medical.result_logger import create_logger_for_medical_segmentation

class MedicalTransformerSegmentationDataset(Dataset):
    def __init__(self, data_type='brain_mri', split='train', transform=None):
        """
        Transformer ë¶„í• ìš© ì˜ë£Œ ë°ì´í„°ì…‹

        Args:
            data_type: 'brain_mri', 'cardiac_mri', 'liver_ct', 'lung_ct', 'retinal_oct'
            split: 'train', 'val', 'test'
            transform: ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        """
        self.data_type = data_type
        self.split = split
        self.transform = transform or transforms.Compose([
            transforms.Resize((384, 384)),  # TransformerëŠ” í° í•´ìƒë„ ì„ í˜¸
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])

        # ì„¸ê·¸ë©˜í…Œì´ì…˜ í´ë˜ìŠ¤ ì •ì˜
        self.class_names, self.num_classes = self._get_segmentation_classes()

        # í•©ì„± ë°ì´í„° ìƒì„±
        self.images, self.masks = self._generate_segmentation_data()

    def _get_segmentation_classes(self):
        """ì˜ë£Œ ì˜ìƒë³„ ë¶„í•  í´ë˜ìŠ¤ ì •ì˜"""
        class_maps = {
            'brain_mri': (['background', 'gray_matter', 'white_matter', 'csf', 'tumor'], 5),
            'cardiac_mri': (['background', 'lv_cavity', 'lv_myocardium', 'rv_cavity'], 4),
            'liver_ct': (['background', 'liver', 'tumor', 'vessel'], 4),
            'lung_ct': (['background', 'lung', 'vessel', 'airway', 'lesion'], 5),
            'retinal_oct': (['background', 'retina', 'choroid', 'drusen', 'fluid'], 5)
        }
        names, num = class_maps.get(self.data_type, (['background', 'organ', 'lesion'], 3))
        return names, num

    def _generate_segmentation_data(self):
        """ë¶„í•  ë°ì´í„° ìƒì„±"""
        images = []
        masks = []

        num_samples = 400 if self.split == 'train' else 100

        for i in range(num_samples):
            # ì˜ë£Œ ì˜ìƒê³¼ ë§ˆìŠ¤í¬ ìƒì„±
            image, mask = self._create_medical_segmentation_pair(i)

            images.append(image)
            masks.append(mask)

        return images, masks

    def _create_medical_segmentation_pair(self, seed):
        """ì˜ë£Œ ì˜ìƒ-ë§ˆìŠ¤í¬ ìŒ ìƒì„±"""
        np.random.seed(seed)

        if self.data_type == 'brain_mri':
            return self._create_brain_mri_segmentation(seed)
        elif self.data_type == 'cardiac_mri':
            return self._create_cardiac_mri_segmentation(seed)
        elif self.data_type == 'liver_ct':
            return self._create_liver_ct_segmentation(seed)
        elif self.data_type == 'lung_ct':
            return self._create_lung_ct_segmentation(seed)
        else:  # retinal_oct
            return self._create_retinal_oct_segmentation(seed)

    def _create_brain_mri_segmentation(self, seed):
        """ë‡Œ MRI ë¶„í•  ë°ì´í„° ìƒì„±"""
        np.random.seed(seed)
        image = np.zeros((384, 384, 3))
        mask = np.zeros((384, 384), dtype=np.uint8)

        # ë‡Œ ìœ¤ê³½
        center_x, center_y = 192, 192
        brain_radius = 140

        for y in range(384):
            for x in range(384):
                dist = np.sqrt((x - center_x)**2 + (y - center_y)**2)
                if dist <= brain_radius:
                    # íšŒë°±ì§ˆ ì˜ì—­
                    if dist <= 90:
                        image[y, x] = 0.6 + np.random.normal(0, 0.05)
                        mask[y, x] = 1  # gray_matter
                    # ë°±ì§ˆ ì˜ì—­
                    else:
                        image[y, x] = 0.4 + np.random.normal(0, 0.05)
                        mask[y, x] = 2  # white_matter

        # ë‡Œì²™ìˆ˜ì•¡ (CSF) ì˜ì—­
        ventricle_centers = [(160, 160), (224, 160), (160, 224), (224, 224)]
        for vx, vy in ventricle_centers:
            for y in range(max(0, vy-20), min(384, vy+20)):
                for x in range(max(0, vx-20), min(384, vx+20)):
                    dist = np.sqrt((x - vx)**2 + (y - vy)**2)
                    if dist < 15:
                        image[y, x] = 0.1 + np.random.normal(0, 0.02)
                        mask[y, x] = 3  # csf

        # ì¢…ì–‘ ì˜ì—­ (ì¼ë¶€ ì¼€ì´ìŠ¤ì—ì„œë§Œ)
        if np.random.random() > 0.6:
            tumor_x = np.random.randint(120, 264)
            tumor_y = np.random.randint(120, 264)
            tumor_size = np.random.randint(15, 35)

            for y in range(max(0, tumor_y-tumor_size), min(384, tumor_y+tumor_size)):
                for x in range(max(0, tumor_x-tumor_size), min(384, tumor_x+tumor_size)):
                    dist = np.sqrt((x - tumor_x)**2 + (y - tumor_y)**2)
                    if dist < tumor_size:
                        image[y, x] = 0.8 + np.random.normal(0, 0.1)
                        mask[y, x] = 4  # tumor

        image = np.clip(image, 0, 1)
        return (image * 255).astype(np.uint8), mask

    def _create_cardiac_mri_segmentation(self, seed):
        """ì‹¬ì¥ MRI ë¶„í•  ë°ì´í„° ìƒì„±"""
        np.random.seed(seed)
        image = np.zeros((384, 384, 3))
        mask = np.zeros((384, 384), dtype=np.uint8)

        # ì¢Œì‹¬ì‹¤
        lv_center_x, lv_center_y = 200, 200
        lv_outer_radius = 45
        lv_inner_radius = 25

        for y in range(384):
            for x in range(384):
                dist = np.sqrt((x - lv_center_x)**2 + (y - lv_center_y)**2)

                if dist <= lv_inner_radius:
                    # ì¢Œì‹¬ì‹¤ ë‚´ê°•
                    image[y, x] = 0.2 + np.random.normal(0, 0.03)
                    mask[y, x] = 1  # lv_cavity
                elif dist <= lv_outer_radius:
                    # ì¢Œì‹¬ì‹¤ ì‹¬ê·¼
                    image[y, x] = 0.7 + np.random.normal(0, 0.05)
                    mask[y, x] = 2  # lv_myocardium

        # ìš°ì‹¬ì‹¤
        rv_center_x, rv_center_y = 160, 180
        rv_radius = 30

        for y in range(384):
            for x in range(384):
                dist = np.sqrt((x - rv_center_x)**2 + (y - rv_center_y)**2)
                if dist <= rv_radius:
                    image[y, x] = 0.25 + np.random.normal(0, 0.03)
                    mask[y, x] = 3  # rv_cavity

        image = np.clip(image, 0, 1)
        return (image * 255).astype(np.uint8), mask

    def _create_liver_ct_segmentation(self, seed):
        """ê°„ CT ë¶„í•  ë°ì´í„° ìƒì„±"""
        np.random.seed(seed)
        image = np.random.normal(0.35, 0.08, (384, 384, 3))
        mask = np.zeros((384, 384), dtype=np.uint8)

        # ê°„ ì˜ì—­ (ë¶ˆê·œì¹™í•œ ëª¨ì–‘)
        liver_center_x, liver_center_y = 200, 220

        for y in range(150, 320):
            for x in range(120, 300):
                # ë¶ˆê·œì¹™í•œ ê°„ ê²½ê³„
                boundary_noise = 20 * np.sin((x + y) * 0.02) * np.cos(x * 0.03)
                dist = np.sqrt((x - liver_center_x)**2 + (y - liver_center_y)**2)

                if dist < 80 + boundary_noise:
                    image[y, x] = 0.5 + np.random.normal(0, 0.04)
                    mask[y, x] = 1  # liver

        # ê°„ ì¢…ì–‘ (ì¼ë¶€ ì¼€ì´ìŠ¤)
        if np.random.random() > 0.5:
            tumor_x = np.random.randint(150, 250)
            tumor_y = np.random.randint(180, 280)
            tumor_size = np.random.randint(15, 30)

            for y in range(max(0, tumor_y-tumor_size), min(384, tumor_y+tumor_size)):
                for x in range(max(0, tumor_x-tumor_size), min(384, tumor_x+tumor_size)):
                    dist = np.sqrt((x - tumor_x)**2 + (y - tumor_y)**2)
                    if dist < tumor_size:
                        image[y, x] = 0.3 + np.random.normal(0, 0.05)
                        mask[y, x] = 2  # tumor

        # í˜ˆê´€ êµ¬ì¡°
        for vessel in range(5):
            vx = np.random.randint(140, 260)
            vy_start = np.random.randint(160, 200)

            for y in range(vy_start, min(384, vy_start + 80)):
                vessel_width = 3 + np.sin(y * 0.1)
                for dx in range(-int(vessel_width), int(vessel_width)):
                    if 0 <= vx + dx < 384:
                        image[y, vx + dx] = 0.8 + np.random.normal(0, 0.03)
                        mask[y, vx + dx] = 3  # vessel

        image = np.clip(image, 0, 1)
        return (image * 255).astype(np.uint8), mask

    def _create_lung_ct_segmentation(self, seed):
        """í CT ë¶„í•  ë°ì´í„° ìƒì„±"""
        np.random.seed(seed)
        image = np.random.normal(0.2, 0.05, (384, 384, 3))
        mask = np.zeros((384, 384), dtype=np.uint8)

        # ì–‘ì¸¡ íì•¼
        for lung_side in [(-80, 0), (80, 0)]:
            lung_x = 192 + lung_side[0]
            lung_y = 180

            for y in range(80, 280):
                for x in range(max(0, lung_x-60), min(384, lung_x+60)):
                    dist = np.sqrt((x - lung_x)**2 + (y - lung_y)**2)
                    if dist < 55:
                        image[y, x] = 0.1 + np.random.normal(0, 0.02)
                        mask[y, x] = 1  # lung

        # í˜ˆê´€ êµ¬ì¡°
        for vessel in range(15):
            vx = np.random.randint(80, 304)
            vy = np.random.randint(100, 260)

            # í˜ˆê´€ì´ íì•¼ ë‚´ë¶€ì— ìˆëŠ”ì§€ í™•ì¸
            if mask[vy, vx] == 1:
                vessel_length = np.random.randint(20, 50)
                direction = np.random.uniform(0, 2 * np.pi)

                for t in range(vessel_length):
                    x = int(vx + t * np.cos(direction))
                    y = int(vy + t * np.sin(direction))

                    if 0 <= x < 384 and 0 <= y < 384 and mask[y, x] == 1:
                        image[y, x] = 0.6 + np.random.normal(0, 0.03)
                        mask[y, x] = 2  # vessel

        # ê¸°ë„
        for airway in range(8):
            ax = np.random.randint(120, 264)
            ay = np.random.randint(120, 240)

            if mask[ay, ax] == 1:
                airway_size = np.random.randint(3, 8)
                for y in range(max(0, ay-airway_size), min(384, ay+airway_size)):
                    for x in range(max(0, ax-airway_size), min(384, ax+airway_size)):
                        if mask[y, x] == 1:
                            dist = np.sqrt((x - ax)**2 + (y - ay)**2)
                            if dist < airway_size:
                                image[y, x] = 0.05
                                mask[y, x] = 3  # airway

        # ë³‘ë³€ (ì¼ë¶€ ì¼€ì´ìŠ¤)
        if np.random.random() > 0.6:
            lesion_count = np.random.randint(1, 4)
            for _ in range(lesion_count):
                lx = np.random.randint(100, 284)
                ly = np.random.randint(120, 240)

                if mask[ly, lx] == 1:
                    lesion_size = np.random.randint(8, 20)
                    for y in range(max(0, ly-lesion_size), min(384, ly+lesion_size)):
                        for x in range(max(0, lx-lesion_size), min(384, lx+lesion_size)):
                            dist = np.sqrt((x - lx)**2 + (y - ly)**2)
                            if dist < lesion_size and mask[y, x] == 1:
                                image[y, x] = 0.5 + np.random.normal(0, 0.05)
                                mask[y, x] = 4  # lesion

        image = np.clip(image, 0, 1)
        return (image * 255).astype(np.uint8), mask

    def _create_retinal_oct_segmentation(self, seed):
        """ë§ë§‰ OCT ë¶„í•  ë°ì´í„° ìƒì„±"""
        np.random.seed(seed)
        image = np.random.exponential(0.2, (384, 384, 3))
        mask = np.zeros((384, 384), dtype=np.uint8)

        # ë§ë§‰ ì¸µ êµ¬ì¡°
        for layer in range(8):  # 8ê°œ ë§ë§‰ì¸µ
            y_start = 100 + layer * 20
            layer_thickness = np.random.randint(8, 15)

            for y in range(y_start, min(384, y_start + layer_thickness)):
                for x in range(384):
                    # ì¸µë³„ ê°•ë„ ë³€í™”
                    intensity = 0.3 + layer * 0.05 + np.random.normal(0, 0.02)
                    image[y, x] = intensity
                    mask[y, x] = 1  # retina

        # ë§¥ë½ë§‰
        choroid_start = 280
        for y in range(choroid_start, 350):
            for x in range(384):
                image[y, x] = 0.4 + np.random.normal(0, 0.08)
                mask[y, x] = 2  # choroid

        # ë“œë£¨ì   (ì¼ë¶€ ì¼€ì´ìŠ¤)
        if np.random.random() > 0.7:
            drusen_count = np.random.randint(3, 8)
            for _ in range(drusen_count):
                dx = np.random.randint(50, 334)
                dy = np.random.randint(250, 280)
                drusen_size = np.random.randint(5, 15)

                for y in range(max(0, dy-drusen_size), min(384, dy+drusen_size)):
                    for x in range(max(0, dx-drusen_size), min(384, dx+drusen_size)):
                        dist = np.sqrt((x - dx)**2 + (y - dy)**2)
                        if dist < drusen_size:
                            image[y, x] = 0.8 + np.random.normal(0, 0.05)
                            mask[y, x] = 3  # drusen

        # ì•¡ì²´ ì¶•ì  (ì¼ë¶€ ì¼€ì´ìŠ¤)
        if np.random.random() > 0.8:
            fluid_x = np.random.randint(100, 284)
            fluid_y = np.random.randint(150, 220)
            fluid_size = np.random.randint(15, 30)

            for y in range(max(0, fluid_y-fluid_size), min(384, fluid_y+fluid_size)):
                for x in range(max(0, fluid_x-fluid_size), min(384, fluid_x+fluid_size)):
                    dist = np.sqrt((x - fluid_x)**2 + (y - fluid_y)**2)
                    if dist < fluid_size:
                        image[y, x] = 0.1
                        mask[y, x] = 4  # fluid

        image = np.clip(image, 0, 1)
        return (image * 255).astype(np.uint8), mask

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        image = Image.fromarray(self.images[idx])
        mask = self.masks[idx]

        if self.transform:
            image = self.transform(image)

        # ë§ˆìŠ¤í¬ë¥¼ í…ì„œë¡œ ë³€í™˜ (í´ë˜ìŠ¤ ì¸ë±ìŠ¤)
        mask = torch.from_numpy(mask).long()

        return image, mask

# Vision Transformer íŒ¨ì¹˜ ì„ë² ë”© (Segmentationìš©)
class SegmentationPatchEmbedding(nn.Module):
    def __init__(self, img_size=384, patch_size=16, in_chans=3, embed_dim=768):
        super().__init__()
        self.img_size = img_size
        self.patch_size = patch_size
        self.grid_size = img_size // patch_size
        self.n_patches = self.grid_size ** 2

        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)

    def forward(self, x):
        B, C, H, W = x.shape
        x = self.proj(x)  # (B, embed_dim, H', W')

        # ê³µê°„ ì°¨ì› ë³´ì¡´ì„ ìœ„í•´ reshape
        x = x.flatten(2).transpose(1, 2)  # (B, n_patches, embed_dim)
        return x

# ìœ„ì¹˜ ì¸ì½”ë”© (2Dìš©)
class PositionalEncoding2D(nn.Module):
    def __init__(self, embed_dim, grid_size):
        super().__init__()
        self.embed_dim = embed_dim
        self.grid_size = grid_size

        # 2D ìœ„ì¹˜ ì¸ì½”ë”© ìƒì„±
        pos_embed = self._get_2d_sincos_pos_embed(embed_dim, grid_size)
        self.register_buffer('pos_embed', pos_embed)

    def _get_2d_sincos_pos_embed(self, embed_dim, grid_size):
        """2D sin-cos ìœ„ì¹˜ ì¸ì½”ë”©"""
        grid_h = np.arange(grid_size, dtype=np.float32)
        grid_w = np.arange(grid_size, dtype=np.float32)
        grid = np.meshgrid(grid_w, grid_h)  # ì—¬ê¸°ì„œ w, h ìˆœì„œë¡œ
        grid = np.stack(grid, axis=0)

        grid = grid.reshape([2, 1, grid_size, grid_size])
        pos_embed = self._get_2d_sincos_pos_embed_from_grid(embed_dim, grid)
        return torch.from_numpy(pos_embed).float()

    def _get_2d_sincos_pos_embed_from_grid(self, embed_dim, grid):
        assert embed_dim % 2 == 0

        # x, y ì¢Œí‘œ ë¶„ë¦¬
        emb_h = self._get_1d_sincos_pos_embed_from_grid(embed_dim // 2, grid[0])  # (H*W, D/2)
        emb_w = self._get_1d_sincos_pos_embed_from_grid(embed_dim // 2, grid[1])  # (H*W, D/2)

        emb = np.concatenate([emb_h, emb_w], axis=1)  # (H*W, D)
        return emb

    def _get_1d_sincos_pos_embed_from_grid(self, embed_dim, pos):
        """1D sin-cos ìœ„ì¹˜ ì¸ì½”ë”©"""
        assert embed_dim % 2 == 0
        omega = np.arange(embed_dim // 2, dtype=np.float32)
        omega /= embed_dim / 2.
        omega = 1. / 10000**omega  # (D/2,)

        pos = pos.reshape(-1)  # (M,)
        out = np.einsum('m,d->md', pos, omega)  # (M, D/2), outer product

        emb_sin = np.sin(out)  # (M, D/2)
        emb_cos = np.cos(out)  # (M, D/2)

        emb = np.concatenate([emb_sin, emb_cos], axis=1)  # (M, D)
        return emb

    def forward(self, x):
        return x + self.pos_embed

# Transformer ì¸ì½”ë” ë¸”ë¡ (Segmentationìš©)
class SegmentationTransformerBlock(nn.Module):
    def __init__(self, embed_dim, num_heads, mlp_ratio=4, dropout=0.1):
        super().__init__()
        self.norm1 = nn.LayerNorm(embed_dim)
        self.attn = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout, batch_first=True)
        self.norm2 = nn.LayerNorm(embed_dim)

        mlp_hidden_dim = int(embed_dim * mlp_ratio)
        self.mlp = nn.Sequential(
            nn.Linear(embed_dim, mlp_hidden_dim),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(mlp_hidden_dim, embed_dim),
            nn.Dropout(dropout)
        )

    def forward(self, x):
        # ì…€í”„ ì–´í…ì…˜
        x_norm = self.norm1(x)
        attn_out, attn_weights = self.attn(x_norm, x_norm, x_norm)
        x = x + attn_out

        # MLP
        x = x + self.mlp(self.norm2(x))

        return x, attn_weights

# Medical Segmentation Transformer
class MedicalSegmentationTransformer(nn.Module):
    def __init__(self, num_classes, img_size=384, patch_size=16, embed_dim=768,
                 depth=12, num_heads=12, decoder_depth=2):
        super().__init__()

        self.num_classes = num_classes
        self.img_size = img_size
        self.patch_size = patch_size
        self.grid_size = img_size // patch_size
        self.n_patches = self.grid_size ** 2

        # íŒ¨ì¹˜ ì„ë² ë”©
        self.patch_embed = SegmentationPatchEmbedding(img_size, patch_size, 3, embed_dim)

        # ìœ„ì¹˜ ì¸ì½”ë”©
        self.pos_embed = PositionalEncoding2D(embed_dim, self.grid_size)

        # Transformer ì¸ì½”ë”
        self.encoder_blocks = nn.ModuleList([
            SegmentationTransformerBlock(embed_dim, num_heads)
            for _ in range(depth)
        ])

        self.encoder_norm = nn.LayerNorm(embed_dim)

        # ë¶„í•  ë””ì½”ë”
        self.decoder = nn.ModuleList([
            nn.Sequential(
                nn.Conv2d(embed_dim, embed_dim // 2, 3, padding=1),
                nn.BatchNorm2d(embed_dim // 2),
                nn.ReLU(),
                nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)
            ) for _ in range(decoder_depth)
        ])

        # ìµœì¢… ë¶„ë¥˜ í—¤ë“œ
        final_dim = embed_dim // (2 ** decoder_depth)
        self.seg_head = nn.Sequential(
            nn.Conv2d(final_dim, final_dim, 3, padding=1),
            nn.BatchNorm2d(final_dim),
            nn.ReLU(),
            nn.Conv2d(final_dim, num_classes, 1)
        )

        # ì˜ë£Œ ì˜ìƒ íŠ¹í™” ì´ˆê¸°í™”
        self._init_medical_weights()

    def _init_medical_weights(self):
        """ì˜ë£Œ ì˜ìƒ íŠ¹í™” ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”"""
        # íŒ¨ì¹˜ ì„ë² ë”© ì´ˆê¸°í™”
        w = self.patch_embed.proj.weight.data
        torch.nn.init.xavier_uniform_(w.view([w.shape[0], -1]))

        # í´ë˜ìŠ¤ í—¤ë“œ ì´ˆê¸°í™” (ë°°ê²½ í´ë˜ìŠ¤ í¸í–¥)
        nn.init.constant_(self.seg_head[-1].bias, 0)

    def forward(self, x):
        B, C, H, W = x.shape

        # íŒ¨ì¹˜ ì„ë² ë”©
        x = self.patch_embed(x)  # [B, n_patches, embed_dim]

        # ìœ„ì¹˜ ì¸ì½”ë”©
        x = self.pos_embed(x)

        # Transformer ì¸ì½”ë”
        attention_weights = []
        for block in self.encoder_blocks:
            x, attn = block(x)
            attention_weights.append(attn)

        x = self.encoder_norm(x)

        # ê³µê°„ ì°¨ì› ë³µì›
        x = x.transpose(1, 2).reshape(B, -1, self.grid_size, self.grid_size)

        # ë¶„í•  ë””ì½”ë”
        for decoder_layer in self.decoder:
            x = decoder_layer(x)

        # ìµœì¢… ì—…ìƒ˜í”Œë§ìœ¼ë¡œ ì›ë³¸ í¬ê¸° ë³µì›
        x = F.interpolate(x, size=(H, W), mode='bilinear', align_corners=False)

        # ë¶„í•  ì˜ˆì¸¡
        seg_logits = self.seg_head(x)

        return {
            'seg_logits': seg_logits,
            'attention_weights': attention_weights
        }

# ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ Transformer (ê°œì„ ëœ ë²„ì „)
class MultiScaleSegmentationTransformer(nn.Module):
    def __init__(self, num_classes, img_size=384, embed_dim=768):
        super().__init__()

        self.num_classes = num_classes

        # ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ íŒ¨ì¹˜ ì„ë² ë”©
        self.patch_embeds = nn.ModuleList([
            SegmentationPatchEmbedding(img_size, 16, 3, embed_dim),  # 16x16 íŒ¨ì¹˜
            SegmentationPatchEmbedding(img_size, 32, 3, embed_dim),  # 32x32 íŒ¨ì¹˜
        ])

        # ê° ìŠ¤ì¼€ì¼ë³„ ìœ„ì¹˜ ì¸ì½”ë”©
        self.pos_embeds = nn.ModuleList([
            PositionalEncoding2D(embed_dim, img_size // 16),
            PositionalEncoding2D(embed_dim, img_size // 32),
        ])

        # ìŠ¤ì¼€ì¼ ìœµí•©
        self.scale_fusion = nn.MultiheadAttention(embed_dim, 8, batch_first=True)

        # Transformer ì¸ì½”ë”
        self.encoder_blocks = nn.ModuleList([
            SegmentationTransformerBlock(embed_dim, 12)
            for _ in range(8)
        ])

        # ì ì§„ì  ì—…ìƒ˜í”Œë§ ë””ì½”ë”
        self.decoder = nn.Sequential(
            # 24x24 -> 48x48
            nn.ConvTranspose2d(embed_dim, 512, 4, stride=2, padding=1),
            nn.BatchNorm2d(512),
            nn.ReLU(),

            # 48x48 -> 96x96
            nn.ConvTranspose2d(512, 256, 4, stride=2, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(),

            # 96x96 -> 192x192
            nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(),

            # 192x192 -> 384x384
            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(),

            # ìµœì¢… ë¶„ë¥˜
            nn.Conv2d(64, num_classes, 3, padding=1)
        )

    def forward(self, x):
        B, C, H, W = x.shape

        # ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ íŠ¹ì§• ì¶”ì¶œ
        multi_scale_features = []
        for patch_embed, pos_embed in zip(self.patch_embeds, self.pos_embeds):
            features = patch_embed(x)
            features = pos_embed(features)
            multi_scale_features.append(features)

        # ìŠ¤ì¼€ì¼ ê°„ ì–´í…ì…˜ìœ¼ë¡œ ìœµí•©
        # ë” ì„¸ë°€í•œ ìŠ¤ì¼€ì¼(16x16)ì„ ì¿¼ë¦¬ë¡œ ì‚¬ìš©
        fine_features = multi_scale_features[0]
        coarse_features = multi_scale_features[1]

        # í¬ê¸° ë§ì¶”ê¸° (coarseë¥¼ fine í¬ê¸°ë¡œ interpolate)
        if coarse_features.shape[1] != fine_features.shape[1]:
            # coarse featuresë¥¼ fine features í¬ê¸°ë¡œ í™•ì¥
            coarse_upsampled = F.interpolate(
                coarse_features.transpose(1, 2).reshape(B, -1, 12, 12),
                size=(24, 24), mode='bilinear', align_corners=False
            ).flatten(2).transpose(1, 2)

            fused_features, _ = self.scale_fusion(fine_features, coarse_upsampled, coarse_upsampled)
        else:
            fused_features, _ = self.scale_fusion(fine_features, coarse_features, coarse_features)

        # Transformer ì¸ì½”ë”
        x = fused_features
        attention_weights = []
        for block in self.encoder_blocks:
            x, attn = block(x)
            attention_weights.append(attn)

        # ê³µê°„ ì°¨ì› ë³µì› (24x24 ê·¸ë¦¬ë“œ)
        x = x.transpose(1, 2).reshape(B, -1, 24, 24)

        # ë””ì½”ë”ë¡œ ì—…ìƒ˜í”Œë§
        seg_logits = self.decoder(x)

        return {
            'seg_logits': seg_logits,
            'attention_weights': attention_weights
        }

# Dice Loss + Cross Entropy
class DiceCrossEntropyLoss(nn.Module):
    def __init__(self, num_classes, dice_weight=0.5, ce_weight=0.5):
        super().__init__()
        self.num_classes = num_classes
        self.dice_weight = dice_weight
        self.ce_weight = ce_weight
        self.ce_loss = nn.CrossEntropyLoss()

    def dice_loss(self, pred, target):
        """Dice Loss ê³„ì‚°"""
        smooth = 1e-5

        # ì†Œí”„íŠ¸ë§¥ìŠ¤ ì ìš©
        pred = F.softmax(pred, dim=1)

        dice_losses = []
        for c in range(self.num_classes):
            pred_c = pred[:, c]
            target_c = (target == c).float()

            intersection = (pred_c * target_c).sum(dim=(1, 2))
            union = pred_c.sum(dim=(1, 2)) + target_c.sum(dim=(1, 2))

            dice = (2 * intersection + smooth) / (union + smooth)
            dice_losses.append(1 - dice.mean())

        return sum(dice_losses) / len(dice_losses)

    def forward(self, pred, target):
        ce_loss = self.ce_loss(pred, target)
        dice_loss = self.dice_loss(pred, target)

        total_loss = self.ce_weight * ce_loss + self.dice_weight * dice_loss

        return total_loss, {'ce_loss': ce_loss.item(), 'dice_loss': dice_loss.item()}

def calculate_metrics(pred, target, num_classes):
    """ë¶„í•  ë©”íŠ¸ë¦­ ê³„ì‚°"""
    pred = torch.argmax(pred, dim=1).cpu().numpy()
    target = target.cpu().numpy()

    # Flatten
    pred_flat = pred.flatten()
    target_flat = target.flatten()

    # IoU ê³„ì‚° (í´ë˜ìŠ¤ë³„)
    ious = []
    for c in range(num_classes):
        pred_c = (pred_flat == c)
        target_c = (target_flat == c)

        intersection = np.logical_and(pred_c, target_c).sum()
        union = np.logical_or(pred_c, target_c).sum()

        if union > 0:
            iou = intersection / union
        else:
            iou = 1.0 if intersection == 0 else 0.0

        ious.append(iou)

    # mIoU
    miou = np.mean(ious)

    # ì „ì²´ ì •í™•ë„
    accuracy = (pred_flat == target_flat).mean()

    return {
        'miou': miou,
        'accuracy': accuracy,
        'class_ious': ious
    }

def train_medical_transformer_segmentation(dataset_type='brain_mri', num_epochs=50, batch_size=4, lr=1e-4):
    """
    Transformer ê¸°ë°˜ ì˜ë£Œ ì˜ìƒ ë¶„í•  í›ˆë ¨

    Args:
        dataset_type: ì˜ë£Œ ë°ì´í„°ì…‹ íƒ€ì…
        num_epochs: í›ˆë ¨ ì—í¬í¬ ìˆ˜
        batch_size: ë°°ì¹˜ í¬ê¸°
        lr: í•™ìŠµë¥ 
    """

    # ë¡œê±° ì„¤ì •
    logger = create_logger_for_medical_segmentation('transformer_segmentation', dataset_type)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    logger.log(f"Using device: {device}")

    # ë°ì´í„°ì…‹ ì¤€ë¹„
    train_dataset = MedicalTransformerSegmentationDataset(data_type=dataset_type, split='train')
    val_dataset = MedicalTransformerSegmentationDataset(data_type=dataset_type, split='val')

    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=True)

    # ëª¨ë¸ ì„¤ì • (ë‘ ê°€ì§€ ëª¨ë¸ ë¹„êµ)
    models = {
        'basic': MedicalSegmentationTransformer(num_classes=train_dataset.num_classes).to(device),
        'multiscale': MultiScaleSegmentationTransformer(num_classes=train_dataset.num_classes).to(device)
    }

    # ì†ì‹¤ í•¨ìˆ˜
    criterion = DiceCrossEntropyLoss(num_classes=train_dataset.num_classes)

    # ì˜µí‹°ë§ˆì´ì € (ê° ëª¨ë¸ë³„)
    optimizers = {
        name: optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)
        for name, model in models.items()
    }

    schedulers = {
        name: optim.lr_scheduler.CosineAnnealingLR(opt, T_max=num_epochs)
        for name, opt in optimizers.items()
    }

    # í›ˆë ¨ ë©”íŠ¸ë¦­ ì €ì¥
    train_losses = {name: [] for name in models.keys()}
    val_losses = {name: [] for name in models.keys()}
    val_mious = {name: [] for name in models.keys()}

    logger.log("Starting Medical Transformer Segmentation training...")
    for name, model in models.items():
        logger.log(f"{name.upper()} model parameters: {sum(p.numel() for p in model.parameters()):,}")

    for epoch in range(num_epochs):
        # ê° ëª¨ë¸ë³„ë¡œ í›ˆë ¨
        for model_name, model in models.items():
            model.train()
            running_loss = 0.0

            for batch_idx, (images, masks) in enumerate(train_loader):
                images, masks = images.to(device), masks.to(device)

                optimizers[model_name].zero_grad()

                # ìˆœì „íŒŒ
                outputs = model(images)

                # ì†ì‹¤ ê³„ì‚°
                loss, loss_dict = criterion(outputs['seg_logits'], masks)

                # ì—­ì „íŒŒ
                loss.backward()

                # Gradient clipping
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)

                optimizers[model_name].step()

                running_loss += loss.item()

                if batch_idx % 10 == 0 and model_name == 'basic':  # ì²« ë²ˆì§¸ ëª¨ë¸ë§Œ ë¡œê·¸
                    logger.log(f'Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx}/{len(train_loader)}], '
                              f'Loss: {loss.item():.4f} (CE: {loss_dict["ce_loss"]:.4f}, '
                              f'Dice: {loss_dict["dice_loss"]:.4f})')

            train_losses[model_name].append(running_loss / len(train_loader))

            # ê²€ì¦ ë‹¨ê³„
            model.eval()
            val_loss = 0.0
            val_metrics = []

            with torch.no_grad():
                for images, masks in val_loader:
                    images, masks = images.to(device), masks.to(device)

                    outputs = model(images)
                    loss, _ = criterion(outputs['seg_logits'], masks)

                    val_loss += loss.item()

                    # ë©”íŠ¸ë¦­ ê³„ì‚°
                    metrics = calculate_metrics(outputs['seg_logits'], masks, train_dataset.num_classes)
                    val_metrics.append(metrics)

            avg_val_loss = val_loss / len(val_loader)
            avg_val_miou = np.mean([m['miou'] for m in val_metrics])

            val_losses[model_name].append(avg_val_loss)
            val_mious[model_name].append(avg_val_miou)

            schedulers[model_name].step()

        # ì—í¬í¬ë³„ ë¡œê¹…
        logger.log(f'Epoch [{epoch+1}/{num_epochs}]')
        for model_name in models.keys():
            logger.log(f'{model_name.upper()} - Train Loss: {train_losses[model_name][-1]:.4f}, '
                      f'Val Loss: {val_losses[model_name][-1]:.4f}, '
                      f'Val mIoU: {val_mious[model_name][-1]:.4f}')

        # ë©”íŠ¸ë¦­ ì €ì¥
        logger.save_metrics({
            'epoch': epoch + 1,
            **{f'{name}_train_loss': train_losses[name][-1] for name in models.keys()},
            **{f'{name}_val_loss': val_losses[name][-1] for name in models.keys()},
            **{f'{name}_val_miou': val_mious[name][-1] for name in models.keys()},
        })

        # ì¤‘ê°„ ê²°ê³¼ ì €ì¥ (ë§¤ 10 ì—í¬í¬)
        if (epoch + 1) % 10 == 0:
            for model_name, model in models.items():
                model.eval()
                with torch.no_grad():
                    sample_images, sample_masks = next(iter(val_loader))
                    sample_images = sample_images[:2].to(device)
                    sample_masks = sample_masks[:2]

                    outputs = model(sample_images)
                    pred_masks = torch.argmax(outputs['seg_logits'], dim=1)

                    # ì‹œê°í™”ë¥¼ ìœ„í•œ ì´ë¯¸ì§€ ì¤€ë¹„
                    vis_images = []
                    for i in range(len(sample_images)):
                        # ì›ë³¸ ì´ë¯¸ì§€
                        img = sample_images[i].cpu().numpy().transpose(1, 2, 0)
                        img = (img - img.min()) / (img.max() - img.min())

                        # ì‹¤ì œ ë§ˆìŠ¤í¬
                        true_mask = sample_masks[i].numpy() / train_dataset.num_classes

                        # ì˜ˆì¸¡ ë§ˆìŠ¤í¬
                        pred_mask = pred_masks[i].cpu().numpy() / train_dataset.num_classes

                        vis_images.extend([img, true_mask, pred_mask])

                    titles = ['Original', 'True Mask', f'{model_name.upper()} Pred'] * 2

                    logger.save_image_grid(vis_images,
                                         f'transformer_seg_{model_name}_epoch_{epoch+1}.png',
                                         titles=titles,
                                         nrow=3)

    # ìµœì¢… ëª¨ë¸ë“¤ ì €ì¥
    for model_name, model in models.items():
        logger.save_model(model, f"medical_transformer_seg_{model_name}_final",
                         optimizer=optimizers[model_name], epoch=num_epochs,
                         config={'dataset_type': dataset_type, 'model_type': model_name})

    # í›ˆë ¨ ê³¡ì„  ì €ì¥
    plt.figure(figsize=(20, 5))

    plt.subplot(1, 4, 1)
    for model_name in models.keys():
        plt.plot(train_losses[model_name], label=f'{model_name.upper()} Train')
        plt.plot(val_losses[model_name], label=f'{model_name.upper()} Val')
    plt.title('Training Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True)

    plt.subplot(1, 4, 2)
    for model_name in models.keys():
        plt.plot(val_mious[model_name], label=f'{model_name.upper()}')
    plt.title('Validation mIoU')
    plt.xlabel('Epoch')
    plt.ylabel('mIoU')
    plt.legend()
    plt.grid(True)

    plt.subplot(1, 4, 3)
    # ìµœì¢… ì„±ëŠ¥ ë¹„êµ
    final_mious = [val_mious[name][-1] for name in models.keys()]
    model_names = [name.upper() for name in models.keys()]

    plt.bar(model_names, final_mious)
    plt.title('Final Model Comparison (mIoU)')
    plt.ylabel('mIoU')
    plt.ylim(0, 1)
    for i, v in enumerate(final_mious):
        plt.text(i, v + 0.01, f'{v:.3f}', ha='center')

    plt.subplot(1, 4, 4)
    # ì–´í…ì…˜ ë§µ ì‹œê°í™” (Basic ëª¨ë¸)
    models['basic'].eval()
    with torch.no_grad():
        sample_images, _ = next(iter(val_loader))
        sample_images = sample_images[:1].to(device)

        outputs = models['basic'](sample_images)

        if outputs['attention_weights']:
            # ë§ˆì§€ë§‰ ë ˆì´ì–´ì˜ ì–´í…ì…˜ ì‚¬ìš©
            last_attn = outputs['attention_weights'][-1][0, 0]  # [seq_len, seq_len]

            # í‰ê·  ì–´í…ì…˜ (ì²« ë²ˆì§¸ í† í° ì œì™¸)
            attn_map = last_attn.mean(dim=0).cpu().numpy()

            # íŒ¨ì¹˜ ê²©ìë¡œ ì¬êµ¬ì„±
            grid_size = int(np.sqrt(len(attn_map)))
            attn_map = attn_map.reshape(grid_size, grid_size)

            plt.imshow(attn_map, cmap='hot', interpolation='nearest')
            plt.title('Transformer Attention Map')
            plt.colorbar()

    plt.tight_layout()
    plt.savefig(os.path.join(logger.dirs['plots'], 'transformer_segmentation_analysis.png'),
                dpi=150, bbox_inches='tight')
    plt.close()

    logger.log("Medical Transformer Segmentation training completed successfully!")
    for model_name in models.keys():
        logger.log(f"Final {model_name.upper()} mIoU: {val_mious[model_name][-1]:.4f}")
    logger.log(f"Results saved in: {logger.dirs['base']}")

    return models, logger.dirs['base']

if __name__ == "__main__":
    print("ğŸ§  Transformer ê¸°ë°˜ ì˜ë£Œ ì˜ìƒ ë¶„í•  (Medical Image Segmentation with Transformers)")
    print("=" * 80)

    # í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •
    config = {
        'dataset_type': 'brain_mri',
        'num_epochs': 5,  # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ 5ë¡œ ì„¤ì •
        'batch_size': 2,  # TransformerëŠ” ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ë†’ìŒ
        'lr': 1e-4
    }

    print(f"Dataset: {config['dataset_type']}")
    print(f"Epochs: {config['num_epochs']}")
    print(f"Batch size: {config['batch_size']}")
    print(f"Learning rate: {config['lr']}")
    print()

    try:
        models, results_dir = train_medical_transformer_segmentation(
            dataset_type=config['dataset_type'],
            num_epochs=config['num_epochs'],
            batch_size=config['batch_size'],
            lr=config['lr']
        )

        print("\nâœ… Medical Transformer Segmentation training completed successfully!")
        print(f"ğŸ“ Results saved to: {results_dir}")

        print("\nğŸ“Š Generated files include:")
        print("- images/: Transformer segmentation visualizations")
        print("- models/: Trained Basic and Multi-scale Transformer models")
        print("- logs/: Training logs and configuration")
        print("- plots/: Training curves and attention analysis")
        print("- metrics/: Training metrics in JSON format")

        print("\nğŸ¯ Transformer Segmentation Features:")
        print("- Vision Transformer encoder for medical images")
        print("- Multi-scale patch processing")
        print("- 2D positional encoding")
        print("- Dice + Cross-Entropy loss")
        print("- Self-attention visualization")
        print("- Basic vs Multi-scale model comparison")

    except Exception as e:
        print(f"\nâŒ Error during Transformer segmentation training: {str(e)}")
        import traceback
        traceback.print_exc()