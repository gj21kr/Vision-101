#!/usr/bin/env python3
"""
ì˜ë£Œ ì˜ìƒ í•©ì„± (Medical Image Synthesis)

ì˜ë£Œ ì˜ìƒ í•©ì„±ì€ ë¶€ì¡±í•œ ì˜ë£Œ ë°ì´í„°ë¥¼ ë³´ì™„í•˜ê³ , ë‹¤ì–‘í•œ ë³‘ë¦¬í•™ì  ìƒíƒœë¥¼ ì‹œë®¬ë ˆì´ì…˜í•˜ì—¬
ì§„ë‹¨ ì•Œê³ ë¦¬ì¦˜ì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ì¤‘ìš”í•œ ê¸°ìˆ ì…ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
- ì •ìƒ/ë¹„ì •ìƒ ì˜ë£Œ ì˜ìƒ ìƒì„±
- í¬ê·€ ì§ˆí™˜ ì˜ìƒ í•©ì„±
- ë‹¤ì–‘í•œ ëª¨ë‹¬ë¦¬í‹° ê°„ ë³€í™˜ (CT â†’ MRI, X-ray â†’ CT ë“±)
- ë°ì´í„° ì¦ê°•ì„ ìœ„í•œ ì˜ìƒ ìƒì„±
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torchvision.transforms as transforms
from torch.utils.data import Dataset, DataLoader
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import os
import sys
from pathlib import Path

PROJECT_ROOT = Path(__file__).resolve().parent
while PROJECT_ROOT.name not in {"medical", "non_medical"} and PROJECT_ROOT.parent != PROJECT_ROOT:
    PROJECT_ROOT = PROJECT_ROOT.parent
if PROJECT_ROOT.name in {"medical", "non_medical"}:
    PROJECT_ROOT = PROJECT_ROOT.parent
if str(PROJECT_ROOT) not in sys.path:
    sys.path.append(str(PROJECT_ROOT))

import math
from medical.result_logger import create_logger_for_medical_synthesis

class MedicalSynthesisDataset(Dataset):
    def __init__(self, data_type='chest_xray', condition='normal', transform=None):
        """
        ì˜ë£Œ ì˜ìƒ í•©ì„±ìš© ë°ì´í„°ì…‹

        Args:
            data_type: 'chest_xray', 'brain_mri', 'ct_scan', 'mammography'
            condition: 'normal', 'abnormal', 'all'
            transform: ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        """
        self.data_type = data_type
        self.condition = condition
        self.transform = transform or transforms.Compose([
            transforms.Resize((256, 256)),
            transforms.ToTensor(),
            transforms.Normalize([0.5], [0.5])  # [-1, 1] ë²”ìœ„ë¡œ ì •ê·œí™”
        ])

        # ì¡°ê±´ë¶€ ë ˆì´ë¸” ì •ì˜
        self.condition_labels = self._get_condition_labels()

        # í•©ì„± ë°ì´í„° ìƒì„±
        self.images, self.labels = self._generate_synthetic_data()

    def _get_condition_labels(self):
        """ë°ì´í„° íƒ€ì…ë³„ ì¡°ê±´ ë ˆì´ë¸” ì •ì˜"""
        labels = {
            'chest_xray': ['normal', 'pneumonia', 'cardiomegaly', 'pneumothorax', 'effusion'],
            'brain_mri': ['normal', 'tumor', 'hemorrhage', 'infarct', 'edema'],
            'ct_scan': ['normal', 'nodule', 'mass', 'infiltrate', 'consolidation'],
            'mammography': ['normal', 'mass', 'calcification', 'distortion', 'asymmetry']
        }
        return labels.get(self.data_type, ['normal', 'abnormal'])

    def _generate_synthetic_data(self):
        """í•©ì„± ì˜ë£Œ ë°ì´í„° ìƒì„±"""
        images = []
        labels = []

        num_samples = 1200

        for i in range(num_samples):
            # ì¡°ê±´ ë ˆì´ë¸” ì„ íƒ
            if self.condition == 'all':
                condition_idx = np.random.choice(len(self.condition_labels))
            elif self.condition == 'normal':
                condition_idx = 0
            elif self.condition == 'abnormal':
                condition_idx = np.random.choice(range(1, len(self.condition_labels)))
            else:
                condition_idx = 0

            condition = self.condition_labels[condition_idx]

            # ì¡°ê±´ì— ë”°ë¥¸ ì˜ë£Œ ì˜ìƒ ìƒì„±
            medical_image = self._create_conditional_medical_image(i, condition)

            images.append(medical_image)
            labels.append(condition_idx)

        return images, labels

    def _create_conditional_medical_image(self, seed, condition):
        """ì¡°ê±´ë¶€ ì˜ë£Œ ì˜ìƒ ìƒì„±"""
        np.random.seed(seed)

        if self.data_type == 'chest_xray':
            return self._create_conditional_chest_xray(seed, condition)
        elif self.data_type == 'brain_mri':
            return self._create_conditional_brain_mri(seed, condition)
        elif self.data_type == 'ct_scan':
            return self._create_conditional_ct_scan(seed, condition)
        else:
            # ê¸°ë³¸ ì˜ë£Œ ì˜ìƒ
            image = np.random.normal(0.4, 0.2, (256, 256))
            if condition != 'normal':
                # ì´ìƒ ì˜ì—­ ì¶”ê°€
                lesion_x, lesion_y = np.random.randint(50, 206, 2)
                lesion_size = np.random.randint(20, 60)

                for y in range(lesion_y, min(lesion_y + lesion_size, 256)):
                    for x in range(lesion_x, min(lesion_x + lesion_size, 256)):
                        image[y, x] += 0.4

            image = np.clip(image, 0, 1)
            return (image * 255).astype(np.uint8)

    def _create_conditional_chest_xray(self, seed, condition):
        """ì¡°ê±´ë¶€ í‰ë¶€ X-ray ìƒì„±"""
        np.random.seed(seed)
        image = np.zeros((256, 256))

        # ê¸°ë³¸ íì•¼ êµ¬ì¡°
        center_x, center_y = 128, 128
        for y in range(256):
            for x in range(256):
                dist = np.sqrt((x - center_x)**2 + (y - center_y)**2)
                if dist < 100:
                    intensity = 0.3 + 0.1 * np.sin(dist * 0.05)
                    image[y, x] = intensity + np.random.normal(0, 0.05)

        # ì¡°ê±´ë³„ ë³‘ë¦¬ ì¶”ê°€
        if condition == 'pneumonia':
            # íë ´: íì•¼ í•˜ë¶€ì— ì¹¨ìœ¤
            infiltrate_region = np.random.choice(['left_lower', 'right_lower', 'bilateral'])
            if infiltrate_region in ['left_lower', 'bilateral']:
                for y in range(150, 230):
                    for x in range(20, 120):
                        image[y, x] += 0.3 + np.random.normal(0, 0.1)

            if infiltrate_region in ['right_lower', 'bilateral']:
                for y in range(150, 230):
                    for x in range(136, 236):
                        image[y, x] += 0.3 + np.random.normal(0, 0.1)

        elif condition == 'cardiomegaly':
            # ì‹¬ì¥ë¹„ëŒ€: ì‹¬ì¥ ì˜ì—­ í™•ëŒ€
            heart_center_x, heart_center_y = 128, 160
            enlarged_radius = 45  # ì •ìƒë³´ë‹¤ í° ì‹¬ì¥
            for y in range(256):
                for x in range(256):
                    dist = np.sqrt((x - heart_center_x)**2 + (y - heart_center_y)**2)
                    if dist < enlarged_radius:
                        image[y, x] += 0.4

        elif condition == 'pneumothorax':
            # ê¸°í‰: íì•¼ ê°€ì¥ìë¦¬ì— ê³µê¸°ì¸µ
            side = np.random.choice(['left', 'right'])
            if side == 'left':
                for y in range(50, 200):
                    boundary = int(50 + 20 * np.sin(y * 0.05))
                    image[y, :boundary] = 0.1  # ê³µê¸°ì¸µ (ì–´ë‘ì›€)
            else:
                for y in range(50, 200):
                    boundary = int(206 - 20 * np.sin(y * 0.05))
                    image[y, boundary:] = 0.1

        elif condition == 'effusion':
            # í‰ìˆ˜: íì•¼ í•˜ë¶€ì— ì•¡ì²´ ì €ë¥˜
            effusion_level = np.random.randint(180, 220)
            for y in range(effusion_level, 256):
                for x in range(30, 226):
                    image[y, x] = 0.8  # í‰ìˆ˜ (ë°ìŒ)

        image = np.clip(image, 0, 1)
        return (image * 255).astype(np.uint8)

    def _create_conditional_brain_mri(self, seed, condition):
        """ì¡°ê±´ë¶€ ë‡Œ MRI ìƒì„±"""
        np.random.seed(seed)
        image = np.zeros((256, 256))

        # ê¸°ë³¸ ë‡Œ êµ¬ì¡°
        center_x, center_y = 128, 128
        brain_radius = 90

        for y in range(256):
            for x in range(256):
                dist = np.sqrt((x - center_x)**2 + (y - center_y)**2)
                if dist < brain_radius:
                    # íšŒë°±ì§ˆ/ë°±ì§ˆ êµ¬ì¡°
                    if dist < 60:
                        image[y, x] = 0.6  # íšŒë°±ì§ˆ
                    else:
                        image[y, x] = 0.4  # ë°±ì§ˆ

        # ì¡°ê±´ë³„ ë³‘ë¦¬ ì¶”ê°€
        if condition == 'tumor':
            # ì¢…ì–‘: ë¹„ì •ìƒì ì¸ ê³ ì‹ í˜¸ ì˜ì—­
            tumor_x = np.random.randint(80, 176)
            tumor_y = np.random.randint(80, 176)
            tumor_size = np.random.randint(15, 35)

            for y in range(tumor_y - tumor_size//2, tumor_y + tumor_size//2):
                for x in range(tumor_x - tumor_size//2, tumor_x + tumor_size//2):
                    if 0 <= y < 256 and 0 <= x < 256:
                        dist_tumor = np.sqrt((x - tumor_x)**2 + (y - tumor_y)**2)
                        if dist_tumor < tumor_size//2:
                            image[y, x] = 0.9 + np.random.normal(0, 0.05)

        elif condition == 'hemorrhage':
            # ì¶œí˜ˆ: ê³ ì‹ í˜¸ ì˜ì—­
            hemorrhage_x = np.random.randint(90, 166)
            hemorrhage_y = np.random.randint(90, 166)
            hemorrhage_size = np.random.randint(10, 25)

            for y in range(hemorrhage_y, hemorrhage_y + hemorrhage_size):
                for x in range(hemorrhage_x, hemorrhage_x + hemorrhage_size):
                    if 0 <= y < 256 and 0 <= x < 256:
                        image[y, x] = 0.95

        elif condition == 'infarct':
            # ê²½ìƒ‰: ì €ì‹ í˜¸ ì˜ì—­
            infarct_x = np.random.randint(70, 186)
            infarct_y = np.random.randint(70, 186)

            # ë¶ˆê·œì¹™í•œ ê²½ìƒ‰ ì˜ì—­
            for y in range(infarct_y - 20, infarct_y + 20):
                for x in range(infarct_x - 25, infarct_x + 25):
                    if 0 <= y < 256 and 0 <= x < 256:
                        if np.random.random() > 0.3:  # ë¶ˆê·œì¹™í•œ ëª¨ì–‘
                            image[y, x] = 0.2

        image = np.clip(image, 0, 1)
        return (image * 255).astype(np.uint8)

    def _create_conditional_ct_scan(self, seed, condition):
        """ì¡°ê±´ë¶€ CT ìŠ¤ìº” ìƒì„±"""
        np.random.seed(seed)
        image = np.random.normal(0.3, 0.1, (256, 256))

        # ì¡°ê±´ë³„ ë³‘ë¦¬ ì¶”ê°€
        if condition == 'nodule':
            # ê²°ì ˆ: ì›í˜•ì˜ ê³ ë°€ë„ ì˜ì—­
            nodule_count = np.random.randint(1, 4)
            for _ in range(nodule_count):
                nodule_x = np.random.randint(50, 206)
                nodule_y = np.random.randint(50, 206)
                nodule_radius = np.random.randint(5, 15)

                for y in range(256):
                    for x in range(256):
                        dist = np.sqrt((x - nodule_x)**2 + (y - nodule_y)**2)
                        if dist < nodule_radius:
                            image[y, x] = 0.8 + np.random.normal(0, 0.05)

        elif condition == 'mass':
            # ì¢…ê´´: ë¶ˆê·œì¹™í•œ ê³ ë°€ë„ ì˜ì—­
            mass_x = np.random.randint(70, 186)
            mass_y = np.random.randint(70, 186)
            mass_size = np.random.randint(25, 45)

            for y in range(mass_y - mass_size//2, mass_y + mass_size//2):
                for x in range(mass_x - mass_size//2, mass_x + mass_size//2):
                    if 0 <= y < 256 and 0 <= x < 256:
                        if np.random.random() > 0.2:  # ë¶ˆê·œì¹™í•œ ê²½ê³„
                            image[y, x] = 0.7 + np.random.normal(0, 0.1)

        image = np.clip(image, 0, 1)
        return (image * 255).astype(np.uint8)

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        image = Image.fromarray(self.images[idx]).convert('L')
        label = self.labels[idx]

        if self.transform:
            image = self.transform(image)

        return image, torch.tensor(label, dtype=torch.long)

# ì¡°ê±´ë¶€ ìƒì„±ê¸° (Conditional Generator)
class ConditionalGenerator(nn.Module):
    def __init__(self, noise_dim=100, num_conditions=5, img_channels=1, feature_dim=64):
        super(ConditionalGenerator, self).__init__()

        self.noise_dim = noise_dim
        self.num_conditions = num_conditions

        # ì¡°ê±´ ì„ë² ë”©
        self.condition_embedding = nn.Embedding(num_conditions, 50)

        # ë…¸ì´ì¦ˆì™€ ì¡°ê±´ì„ ê²°í•©í•œ ì…ë ¥ í¬ê¸°
        input_dim = noise_dim + 50

        # ìƒì„±ê¸° ë„¤íŠ¸ì›Œí¬
        self.fc = nn.Sequential(
            nn.Linear(input_dim, feature_dim * 8 * 4 * 4),
            nn.BatchNorm1d(feature_dim * 8 * 4 * 4),
            nn.ReLU()
        )

        self.deconv_layers = nn.Sequential(
            # 4x4 -> 8x8
            nn.ConvTranspose2d(feature_dim * 8, feature_dim * 4, 4, 2, 1),
            nn.BatchNorm2d(feature_dim * 4),
            nn.ReLU(),

            # 8x8 -> 16x16
            nn.ConvTranspose2d(feature_dim * 4, feature_dim * 2, 4, 2, 1),
            nn.BatchNorm2d(feature_dim * 2),
            nn.ReLU(),

            # 16x16 -> 32x32
            nn.ConvTranspose2d(feature_dim * 2, feature_dim, 4, 2, 1),
            nn.BatchNorm2d(feature_dim),
            nn.ReLU(),

            # 32x32 -> 64x64
            nn.ConvTranspose2d(feature_dim, feature_dim // 2, 4, 2, 1),
            nn.BatchNorm2d(feature_dim // 2),
            nn.ReLU(),

            # 64x64 -> 128x128
            nn.ConvTranspose2d(feature_dim // 2, feature_dim // 4, 4, 2, 1),
            nn.BatchNorm2d(feature_dim // 4),
            nn.ReLU(),

            # 128x128 -> 256x256
            nn.ConvTranspose2d(feature_dim // 4, img_channels, 4, 2, 1),
            nn.Tanh()
        )

    def forward(self, noise, conditions):
        # ì¡°ê±´ ì„ë² ë”©
        condition_emb = self.condition_embedding(conditions)

        # ë…¸ì´ì¦ˆì™€ ì¡°ê±´ ê²°í•©
        combined_input = torch.cat([noise, condition_emb], dim=1)

        # FC ë ˆì´ì–´ í†µê³¼
        x = self.fc(combined_input)
        x = x.view(x.size(0), -1, 4, 4)

        # ë””ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´ í†µê³¼
        x = self.deconv_layers(x)

        return x

# ì¡°ê±´ë¶€ íŒë³„ê¸° (Conditional Discriminator)
class ConditionalDiscriminator(nn.Module):
    def __init__(self, img_channels=1, num_conditions=5, feature_dim=64):
        super(ConditionalDiscriminator, self).__init__()

        self.num_conditions = num_conditions

        # ì¡°ê±´ ì„ë² ë”©
        self.condition_embedding = nn.Embedding(num_conditions, 256 * 256)

        # ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´ (ì´ë¯¸ì§€ + ì¡°ê±´)
        self.conv_layers = nn.Sequential(
            # 256x256 -> 128x128
            nn.Conv2d(img_channels + 1, feature_dim, 4, 2, 1),  # +1 for condition channel
            nn.LeakyReLU(0.2),

            # 128x128 -> 64x64
            nn.Conv2d(feature_dim, feature_dim * 2, 4, 2, 1),
            nn.BatchNorm2d(feature_dim * 2),
            nn.LeakyReLU(0.2),

            # 64x64 -> 32x32
            nn.Conv2d(feature_dim * 2, feature_dim * 4, 4, 2, 1),
            nn.BatchNorm2d(feature_dim * 4),
            nn.LeakyReLU(0.2),

            # 32x32 -> 16x16
            nn.Conv2d(feature_dim * 4, feature_dim * 8, 4, 2, 1),
            nn.BatchNorm2d(feature_dim * 8),
            nn.LeakyReLU(0.2),

            # 16x16 -> 8x8
            nn.Conv2d(feature_dim * 8, feature_dim * 16, 4, 2, 1),
            nn.BatchNorm2d(feature_dim * 16),
            nn.LeakyReLU(0.2),

            # 8x8 -> 4x4
            nn.Conv2d(feature_dim * 16, feature_dim * 32, 4, 2, 1),
            nn.BatchNorm2d(feature_dim * 32),
            nn.LeakyReLU(0.2),

            # 4x4 -> 1x1
            nn.Conv2d(feature_dim * 32, 1, 4, 1, 0),
            nn.Sigmoid()
        )

    def forward(self, images, conditions):
        # ì¡°ê±´ì„ ì´ë¯¸ì§€ í¬ê¸°ë¡œ ë³€í™˜
        condition_emb = self.condition_embedding(conditions)
        condition_emb = condition_emb.view(condition_emb.size(0), 1, 256, 256)

        # ì´ë¯¸ì§€ì™€ ì¡°ê±´ ê²°í•©
        combined_input = torch.cat([images, condition_emb], dim=1)

        # íŒë³„
        output = self.conv_layers(combined_input)
        return output.view(output.size(0), -1)

# ìŠ¤íƒ€ì¼ ê¸°ë°˜ ìƒì„±ê¸° (Style-based Generator)
class StyleBasedGenerator(nn.Module):
    def __init__(self, style_dim=512, num_conditions=5, img_channels=1):
        super(StyleBasedGenerator, self).__init__()

        self.style_dim = style_dim
        self.num_conditions = num_conditions

        # ì¡°ê±´ ì„ë² ë”©
        self.condition_embedding = nn.Embedding(num_conditions, style_dim)

        # ìŠ¤íƒ€ì¼ ë§¤í•‘ ë„¤íŠ¸ì›Œí¬
        self.style_mapping = nn.Sequential(
            nn.Linear(style_dim + style_dim, style_dim),  # noise + condition
            nn.LeakyReLU(0.2),
            nn.Linear(style_dim, style_dim),
            nn.LeakyReLU(0.2),
            nn.Linear(style_dim, style_dim),
        )

        # í•©ì„± ë„¤íŠ¸ì›Œí¬
        self.synthesis_network = nn.ModuleList([
            # 4x4
            SynthesisBlock(style_dim, 512, 512, upsample=False),
            # 4x4 -> 8x8
            SynthesisBlock(style_dim, 512, 512, upsample=True),
            # 8x8 -> 16x16
            SynthesisBlock(style_dim, 512, 256, upsample=True),
            # 16x16 -> 32x32
            SynthesisBlock(style_dim, 256, 128, upsample=True),
            # 32x32 -> 64x64
            SynthesisBlock(style_dim, 128, 64, upsample=True),
            # 64x64 -> 128x128
            SynthesisBlock(style_dim, 64, 32, upsample=True),
            # 128x128 -> 256x256
            SynthesisBlock(style_dim, 32, 16, upsample=True),
        ])

        # RGB ì¶œë ¥ ë ˆì´ì–´ë“¤
        self.to_rgb_layers = nn.ModuleList([
            nn.Conv2d(512, img_channels, 1) for _ in range(7)
        ])

        # ì´ˆê¸° ìƒìˆ˜ í…ì„œ
        self.constant = nn.Parameter(torch.randn(1, 512, 4, 4))

    def forward(self, noise, conditions):
        batch_size = noise.size(0)

        # ì¡°ê±´ ì„ë² ë”©
        condition_emb = self.condition_embedding(conditions)

        # ìŠ¤íƒ€ì¼ ì½”ë“œ ìƒì„±
        style_input = torch.cat([noise, condition_emb], dim=1)
        style_code = self.style_mapping(style_input)

        # í•©ì„± ì‹œì‘
        x = self.constant.repeat(batch_size, 1, 1, 1)
        skip = None

        for i, (synthesis_block, to_rgb) in enumerate(zip(self.synthesis_network, self.to_rgb_layers)):
            x = synthesis_block(x, style_code)

            # RGB ë³€í™˜
            if i == len(self.synthesis_network) - 1:  # ë§ˆì§€ë§‰ ë ˆì´ì–´
                rgb = to_rgb(x)
                if skip is not None:
                    skip = F.interpolate(skip, scale_factor=2, mode='bilinear', align_corners=False)
                    rgb = rgb + skip
                return torch.tanh(rgb)

class SynthesisBlock(nn.Module):
    def __init__(self, style_dim, in_channels, out_channels, upsample=True):
        super(SynthesisBlock, self).__init__()

        self.upsample = upsample

        if upsample:
            self.conv1 = nn.ConvTranspose2d(in_channels, out_channels, 4, 2, 1)
        else:
            self.conv1 = nn.Conv2d(in_channels, out_channels, 3, 1, 1)

        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, 1, 1)

        # ìŠ¤íƒ€ì¼ ë³€ì¡°
        self.style_modulation1 = StyleModulation(style_dim, out_channels)
        self.style_modulation2 = StyleModulation(style_dim, out_channels)

        # ë…¸ì´ì¦ˆ ì£¼ì…
        self.noise_injection1 = NoiseInjection()
        self.noise_injection2 = NoiseInjection()

    def forward(self, x, style_code):
        # ì²« ë²ˆì§¸ ì»¨ë³¼ë£¨ì…˜
        x = self.conv1(x)
        x = self.style_modulation1(x, style_code)
        x = self.noise_injection1(x)
        x = F.leaky_relu(x, 0.2)

        # ë‘ ë²ˆì§¸ ì»¨ë³¼ë£¨ì…˜
        x = self.conv2(x)
        x = self.style_modulation2(x, style_code)
        x = self.noise_injection2(x)
        x = F.leaky_relu(x, 0.2)

        return x

class StyleModulation(nn.Module):
    def __init__(self, style_dim, feature_channels):
        super(StyleModulation, self).__init__()
        self.scale_transform = nn.Linear(style_dim, feature_channels)
        self.bias_transform = nn.Linear(style_dim, feature_channels)

    def forward(self, x, style_code):
        scale = self.scale_transform(style_code).unsqueeze(2).unsqueeze(3)
        bias = self.bias_transform(style_code).unsqueeze(2).unsqueeze(3)
        return x * (1 + scale) + bias

class NoiseInjection(nn.Module):
    def __init__(self):
        super(NoiseInjection, self).__init__()
        self.weight = nn.Parameter(torch.zeros(1))

    def forward(self, x):
        noise = torch.randn_like(x)
        return x + self.weight * noise

def train_medical_synthesis(dataset_type='chest_xray', num_epochs=100, batch_size=16, lr=0.0002):
    """
    ì˜ë£Œ ì˜ìƒ í•©ì„± ëª¨ë¸ í›ˆë ¨

    Args:
        dataset_type: ì˜ë£Œ ë°ì´í„°ì…‹ íƒ€ì…
        num_epochs: í›ˆë ¨ ì—í¬í¬ ìˆ˜
        batch_size: ë°°ì¹˜ í¬ê¸°
        lr: í•™ìŠµë¥ 
    """

    # ë¡œê±° ì„¤ì •
    logger = create_logger_for_medical_synthesis('conditional_synthesis', dataset_type)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    logger.log(f"Using device: {device}")

    # ë°ì´í„°ì…‹ ì¤€ë¹„
    dataset = MedicalSynthesisDataset(data_type=dataset_type, condition='all')
    train_size = int(0.9 * len(dataset))
    val_size = len(dataset) - train_size
    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])

    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=True)

    # ëª¨ë¸ ì„¤ì •
    num_conditions = len(dataset.condition_labels)
    generator = ConditionalGenerator(noise_dim=100, num_conditions=num_conditions).to(device)
    discriminator = ConditionalDiscriminator(num_conditions=num_conditions).to(device)

    # ì†ì‹¤ í•¨ìˆ˜
    criterion = nn.BCELoss()

    # ì˜µí‹°ë§ˆì´ì €
    optimizerG = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))
    optimizerD = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))

    # ê³ ì • ë…¸ì´ì¦ˆ (ì‹œê°í™”ìš©)
    fixed_noise = torch.randn(num_conditions * 4, 100).to(device)
    fixed_conditions = torch.arange(num_conditions).repeat(4).to(device)

    # í›ˆë ¨ ë©”íŠ¸ë¦­ ì €ì¥
    g_losses = []
    d_losses = []

    logger.log("Starting medical image synthesis training...")

    for epoch in range(num_epochs):
        generator.train()
        discriminator.train()

        epoch_g_loss = 0.0
        epoch_d_loss = 0.0

        for batch_idx, (real_images, real_conditions) in enumerate(train_loader):
            real_images = real_images.to(device)
            real_conditions = real_conditions.to(device)
            batch_size_current = real_images.size(0)

            # ì‹¤ì œ/ê°€ì§œ ë ˆì´ë¸”
            real_labels = torch.ones(batch_size_current, 1).to(device)
            fake_labels = torch.zeros(batch_size_current, 1).to(device)

            # ====================
            # íŒë³„ê¸° í›ˆë ¨
            # ====================
            optimizerD.zero_grad()

            # ì‹¤ì œ ì´ë¯¸ì§€ íŒë³„
            real_output = discriminator(real_images, real_conditions)
            real_loss = criterion(real_output, real_labels)

            # ê°€ì§œ ì´ë¯¸ì§€ ìƒì„± ë° íŒë³„
            noise = torch.randn(batch_size_current, 100).to(device)
            fake_conditions = torch.randint(0, num_conditions, (batch_size_current,)).to(device)
            fake_images = generator(noise, fake_conditions)
            fake_output = discriminator(fake_images.detach(), fake_conditions)
            fake_loss = criterion(fake_output, fake_labels)

            # íŒë³„ê¸° ì†ì‹¤
            d_loss = (real_loss + fake_loss) / 2
            d_loss.backward()
            optimizerD.step()

            # ====================
            # ìƒì„±ê¸° í›ˆë ¨
            # ====================
            optimizerG.zero_grad()

            # íŒë³„ê¸°ë¥¼ ì†ì´ëŠ” ìƒì„±ê¸°
            fake_output = discriminator(fake_images, fake_conditions)
            g_loss = criterion(fake_output, real_labels)

            g_loss.backward()
            optimizerG.step()

            epoch_g_loss += g_loss.item()
            epoch_d_loss += d_loss.item()

            if batch_idx % 20 == 0:
                logger.log(f'Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx}/{len(train_loader)}], '
                          f'G_Loss: {g_loss.item():.4f}, D_Loss: {d_loss.item():.4f}')

        # ì—í¬í¬ í‰ê·  ì†ì‹¤
        avg_g_loss = epoch_g_loss / len(train_loader)
        avg_d_loss = epoch_d_loss / len(train_loader)

        g_losses.append(avg_g_loss)
        d_losses.append(avg_d_loss)

        logger.log(f'Epoch [{epoch+1}/{num_epochs}]')
        logger.log(f'Generator Loss: {avg_g_loss:.4f}')
        logger.log(f'Discriminator Loss: {avg_d_loss:.4f}')

        # ë©”íŠ¸ë¦­ ì €ì¥
        logger.save_metrics({
            'epoch': epoch + 1,
            'generator_loss': avg_g_loss,
            'discriminator_loss': avg_d_loss,
        })

        # ì¤‘ê°„ ê²°ê³¼ ì €ì¥ (ë§¤ 10 ì—í¬í¬)
        if (epoch + 1) % 10 == 0:
            generator.eval()
            with torch.no_grad():
                # ê° ì¡°ê±´ë³„ë¡œ ìƒ˜í”Œ ìƒì„±
                fake_samples = generator(fixed_noise, fixed_conditions)

                # ì‹œê°í™”ë¥¼ ìœ„í•œ ì´ë¯¸ì§€ ì¤€ë¹„
                vis_images = []
                for i in range(min(12, len(fake_samples))):
                    img = fake_samples[i].cpu().numpy().squeeze()
                    img = (img + 1) / 2  # [-1, 1] -> [0, 1]
                    vis_images.append(img)

                # ì¡°ê±´ë³„ ì œëª© ìƒì„±
                condition_titles = []
                for i in range(min(12, len(fake_samples))):
                    condition_idx = fixed_conditions[i].item()
                    condition_name = dataset.condition_labels[condition_idx]
                    condition_titles.append(f'{condition_name}')

                logger.save_image_grid(vis_images,
                                     f'medical_synthesis_epoch_{epoch+1}.png',
                                     titles=condition_titles,
                                     nrow=4)

    # ìµœì¢… ëª¨ë¸ ì €ì¥
    logger.save_model(generator, "medical_generator_final",
                     optimizer=optimizerG, epoch=num_epochs,
                     config={'dataset_type': dataset_type, 'num_conditions': num_conditions})

    logger.save_model(discriminator, "medical_discriminator_final",
                     optimizer=optimizerD, epoch=num_epochs,
                     config={'dataset_type': dataset_type, 'num_conditions': num_conditions})

    # í›ˆë ¨ ê³¡ì„  ì €ì¥
    plt.figure(figsize=(15, 5))

    plt.subplot(1, 3, 1)
    plt.plot(g_losses, label='Generator Loss')
    plt.plot(d_losses, label='Discriminator Loss')
    plt.title('Training Losses')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True)

    plt.subplot(1, 3, 2)
    # ê° ì¡°ê±´ë³„ ìƒ˜í”Œ ìƒì„± í’ˆì§ˆ ì‹œê°í™”
    generator.eval()
    with torch.no_grad():
        condition_samples = []
        for condition_idx in range(num_conditions):
            noise_sample = torch.randn(1, 100).to(device)
            condition_sample = torch.tensor([condition_idx]).to(device)
            generated_sample = generator(noise_sample, condition_sample)
            condition_samples.append(generated_sample[0].cpu().numpy().squeeze())

        # ì¡°ê±´ë³„ íˆìŠ¤í† ê·¸ë¨
        for i, (condition_name, sample) in enumerate(zip(dataset.condition_labels, condition_samples)):
            plt.hist(sample.flatten(), bins=50, alpha=0.5, label=condition_name)

    plt.title('Generated Image Intensity Distribution')
    plt.xlabel('Pixel Intensity')
    plt.ylabel('Frequency')
    plt.legend()

    plt.subplot(1, 3, 3)
    # ì†ì‹¤ ë¹„ìœ¨ ì¶”ì´
    loss_ratio = np.array(g_losses) / (np.array(d_losses) + 1e-8)
    plt.plot(loss_ratio)
    plt.title('Generator/Discriminator Loss Ratio')
    plt.xlabel('Epoch')
    plt.ylabel('Loss Ratio')
    plt.grid(True)

    plt.tight_layout()
    plt.savefig(os.path.join(logger.dirs['plots'], 'medical_synthesis_analysis.png'),
                dpi=150, bbox_inches='tight')
    plt.close()

    logger.log("Medical image synthesis training completed successfully!")
    logger.log(f"Final Generator Loss: {g_losses[-1]:.4f}")
    logger.log(f"Final Discriminator Loss: {d_losses[-1]:.4f}")
    logger.log(f"Results saved in: {logger.dirs['base']}")

    return generator, discriminator, logger.dirs['base']

if __name__ == "__main__":
    print("ğŸ¨ ì˜ë£Œ ì˜ìƒ í•©ì„± (Medical Image Synthesis)")
    print("=" * 60)

    # í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •
    config = {
        'dataset_type': 'chest_xray',
        'num_epochs': 5,  # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ 5ë¡œ ì„¤ì •
        'batch_size': 8,
        'lr': 0.0002
    }

    print(f"Dataset: {config['dataset_type']}")
    print(f"Epochs: {config['num_epochs']}")
    print(f"Batch size: {config['batch_size']}")
    print(f"Learning rate: {config['lr']}")
    print()

    try:
        generator, discriminator, results_dir = train_medical_synthesis(
            dataset_type=config['dataset_type'],
            num_epochs=config['num_epochs'],
            batch_size=config['batch_size'],
            lr=config['lr']
        )

        print("\nâœ… Medical image synthesis training completed successfully!")
        print(f"ğŸ“ Results saved to: {results_dir}")

        print("\nğŸ“Š Generated files include:")
        print("- images/: Synthesized medical images by condition")
        print("- models/: Trained generator and discriminator models")
        print("- logs/: Training logs and configuration")
        print("- plots/: Training curves and analysis")
        print("- metrics/: Training metrics in JSON format")

        print("\nğŸ¯ Synthesis Capabilities:")
        print("- Conditional generation by medical condition")
        print("- High-quality pathological image synthesis")
        print("- Data augmentation for rare diseases")
        print("- Multi-modal medical image translation")

    except Exception as e:
        print(f"\nâŒ Error during medical synthesis training: {str(e)}")
        import traceback
        traceback.print_exc()
