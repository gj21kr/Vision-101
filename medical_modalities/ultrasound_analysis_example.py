#!/usr/bin/env python3
"""
ì´ˆìŒíŒŒ(Ultrasound) ì˜ë£Œì˜ìƒ ë¶„ì„

ì´ˆìŒíŒŒëŠ” ì‹¤ì‹œê°„ ì˜ìƒ íšë“ì´ ê°€ëŠ¥í•œ ë¹„ì¹¨ìŠµì  ì§„ë‹¨ ë„êµ¬ë¡œ,
ì„ì‹  ì§„ë‹¨, ì‹¬ì¥ ê¸°ëŠ¥ í‰ê°€, ë³µë¶€ ì¥ê¸° ê²€ì‚¬ì— ë„ë¦¬ ì‚¬ìš©ë©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
- íƒœì•„ ìƒì²´ ê³„ì¸¡ (Fetal Biometry)
- ì‹¬ì¥ ê¸°ëŠ¥ ë¶„ì„ (Cardiac Function Analysis)
- í˜ˆë¥˜ ì†ë„ ì¸¡ì • (Doppler Analysis)
- ì‹¤ì‹œê°„ ì¥ê¸° ì¶”ì  (Real-time Organ Tracking)
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torchvision.transforms as transforms
from torch.utils.data import Dataset, DataLoader
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import os
import sys
sys.path.append('/workspace/Vision-101')
from medical.result_logger import create_logger_for_medical_modalities

class UltrasoundDataset(Dataset):
    def __init__(self, data_type='cardiac_echo', transform=None):
        """
        ì´ˆìŒíŒŒ ë°ì´í„°ì…‹ ë¡œë”

        Args:
            data_type: 'cardiac_echo', 'obstetric', 'abdominal', 'vascular'
            transform: ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        """
        self.data_type = data_type
        self.transform = transform or transforms.Compose([
            transforms.Resize((256, 256)),
            transforms.Grayscale(num_output_channels=1),
            transforms.ToTensor(),
            transforms.Normalize([0.5], [0.5])
        ])

        # í•©ì„± ì´ˆìŒíŒŒ ë°ì´í„° ìƒì„±
        self.images, self.measurements = self._generate_synthetic_ultrasound_data()

    def _generate_synthetic_ultrasound_data(self):
        """í•©ì„± ì´ˆìŒíŒŒ ë°ì´í„° ìƒì„±"""
        images = []
        measurements = []

        for i in range(800):
            ultrasound_image = self._create_synthetic_ultrasound(i)
            measurement = self._create_synthetic_measurements(i)

            images.append(ultrasound_image)
            measurements.append(measurement)

        return images, measurements

    def _create_synthetic_ultrasound(self, seed):
        """ì´ˆìŒíŒŒ íŠ¹ì„±ì„ ë°˜ì˜í•œ í•©ì„± ì´ë¯¸ì§€ ìƒì„±"""
        np.random.seed(seed)

        if self.data_type == 'cardiac_echo':
            return self._create_cardiac_echo(seed)
        elif self.data_type == 'obstetric':
            return self._create_obstetric_ultrasound(seed)
        elif self.data_type == 'abdominal':
            return self._create_abdominal_ultrasound(seed)
        else:
            # ê¸°ë³¸ ì´ˆìŒíŒŒ ì˜ìƒ
            image = np.random.exponential(0.3, (256, 256))
            image = np.clip(image, 0, 1)
            return (image * 255).astype(np.uint8)

    def _create_cardiac_echo(self, seed):
        """ì‹¬ì¥ ì´ˆìŒíŒŒ í•©ì„± ìƒì„±"""
        np.random.seed(seed)
        image = np.zeros((256, 256))

        # ì‹¬ì¥ ìœ¤ê³½ ìƒì„±
        center_x, center_y = 128, 140

        # ì¢Œì‹¬ì‹¤ (íƒ€ì›í˜•)
        a, b = 40, 60  # ì¥ì¶•, ë‹¨ì¶•
        for y in range(256):
            for x in range(256):
                ellipse_eq = ((x - center_x)**2 / a**2) + ((y - center_y)**2 / b**2)
                if ellipse_eq <= 1:
                    # ì‹¬ê·¼ ë²½ ë‘ê»˜ ì‹œë®¬ë ˆì´ì…˜
                    wall_thickness = 8 + np.random.normal(0, 2)
                    if ellipse_eq > (1 - wall_thickness/40)**2:
                        image[y, x] = 0.7 + np.random.normal(0, 0.1)  # ì‹¬ê·¼
                    else:
                        image[y, x] = 0.3 + np.random.normal(0, 0.05)  # í˜ˆì•¡

        # ìŠ¹ëª¨íŒ êµ¬ì¡°
        valve_y = center_y - 20
        for x in range(center_x - 15, center_x + 15):
            image[valve_y:valve_y + 3, x] = 0.8

        # ì´ˆìŒíŒŒ íŠ¹ìœ ì˜ ìŠ¤í˜í´ ë…¸ì´ì¦ˆ
        speckle = np.random.rayleigh(0.05, (256, 256))
        image = np.clip(image + speckle, 0, 1)

        return (image * 255).astype(np.uint8)

    def _create_obstetric_ultrasound(self, seed):
        """ì‚°ë¶€ì¸ê³¼ ì´ˆìŒíŒŒ í•©ì„± ìƒì„±"""
        np.random.seed(seed)
        image = np.random.exponential(0.2, (256, 256))

        # íƒœì•„ ë¨¸ë¦¬ ìœ¤ê³½ (ì›í˜•)
        head_center_x = np.random.randint(80, 176)
        head_center_y = np.random.randint(60, 140)
        head_radius = np.random.randint(30, 50)

        for y in range(256):
            for x in range(256):
                dist = np.sqrt((x - head_center_x)**2 + (y - head_center_y)**2)
                if dist <= head_radius:
                    # íƒœì•„ ë‡Œ ì¡°ì§
                    image[y, x] = 0.4 + 0.1 * np.sin(dist * 0.2)

                    # ë‡Œì‹¤ êµ¬ì¡°
                    if dist <= head_radius * 0.3:
                        image[y, x] = 0.2

        # ì²™ì¶” êµ¬ì¡° (ì„¸ë¡œì„ )
        spine_x = np.random.randint(100, 156)
        for y in range(180, 240):
            image[y, spine_x:spine_x+3] = 0.8

        # ì–‘ë§‰ ê²½ê³„
        amniotic_boundary = np.random.randint(200, 240)
        image[amniotic_boundary:, :] *= 0.5

        image = np.clip(image, 0, 1)
        return (image * 255).astype(np.uint8)

    def _create_abdominal_ultrasound(self, seed):
        """ë³µë¶€ ì´ˆìŒíŒŒ í•©ì„± ìƒì„±"""
        np.random.seed(seed)
        image = np.random.exponential(0.25, (256, 256))

        # ê°„ ê²½ê³„
        liver_boundary = 80 + np.sin(np.linspace(0, 2*np.pi, 256)) * 20
        for i, y_boundary in enumerate(liver_boundary):
            image[int(y_boundary):int(y_boundary) + 60, i] = 0.5

        # ë‹´ë‚­ (íƒ€ì›í˜• ì €ì—ì½” ì˜ì—­)
        gb_center_x, gb_center_y = 180, 120
        for y in range(256):
            for x in range(256):
                ellipse_eq = ((x - gb_center_x)**2 / 15**2) + ((y - gb_center_y)**2 / 25**2)
                if ellipse_eq <= 1:
                    image[y, x] = 0.1  # ë‹´ì¦™ (ì €ì—ì½”)

        # í˜ˆê´€ êµ¬ì¡°
        for i in range(3):
            vessel_x = 50 + i * 70
            for y in range(50, 200):
                vessel_thickness = 2 + np.sin(y * 0.1)
                image[y:y+int(vessel_thickness), vessel_x] = 0.2

        image = np.clip(image, 0, 1)
        return (image * 255).astype(np.uint8)

    def _create_synthetic_measurements(self, seed):
        """í•©ì„± ê³„ì¸¡ ë°ì´í„° ìƒì„±"""
        np.random.seed(seed)

        if self.data_type == 'cardiac_echo':
            return {
                'lv_ejection_fraction': np.random.uniform(45, 75),  # ì¢Œì‹¬ì‹¤ êµ¬í˜ˆë¥ 
                'lv_end_diastolic_volume': np.random.uniform(90, 140),  # ì¢Œì‹¬ì‹¤ í™•ì¥ë§ê¸° ìš©ì 
                'septal_thickness': np.random.uniform(8, 12),  # ì¤‘ê²© ë‘ê»˜
                'wall_motion_score': np.random.uniform(1.0, 2.5)  # ë²½ìš´ë™ ì ìˆ˜
            }
        elif self.data_type == 'obstetric':
            gestational_age = np.random.uniform(20, 40)  # ì„ì‹  ì£¼ìˆ˜
            return {
                'biparietal_diameter': 30 + gestational_age * 2 + np.random.normal(0, 3),  # ì–‘ì •ê²½
                'head_circumference': 120 + gestational_age * 8 + np.random.normal(0, 10),  # ë‘ìœ„
                'abdominal_circumference': 100 + gestational_age * 9 + np.random.normal(0, 12),  # ë³µìœ„
                'femur_length': 10 + gestational_age * 1.8 + np.random.normal(0, 2),  # ëŒ€í‡´ê³¨ ê¸¸ì´
                'estimated_fetal_weight': 500 + (gestational_age - 20) * 200 + np.random.normal(0, 100)
            }
        else:
            return {
                'organ_volume': np.random.uniform(100, 500),
                'blood_flow_velocity': np.random.uniform(20, 80),
                'resistance_index': np.random.uniform(0.5, 0.9)
            }

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        image = Image.fromarray(self.images[idx])
        if self.transform:
            image = self.transform(image)

        measurements = self.measurements[idx]
        # ì¸¡ì •ê°’ë“¤ì„ í…ì„œë¡œ ë³€í™˜
        measurement_values = torch.tensor(list(measurements.values()), dtype=torch.float32)

        return image, measurement_values, measurements

# ì´ˆìŒíŒŒ íŠ¹í™” CNN ë„¤íŠ¸ì›Œí¬
class UltrasoundNet(nn.Module):
    def __init__(self, num_measurements=4):
        super(UltrasoundNet, self).__init__()

        # ìŠ¤í˜í´ ë…¸ì´ì¦ˆ ì²˜ë¦¬ë¥¼ ìœ„í•œ ì´ˆê¸° ë ˆì´ì–´
        self.noise_reduction = nn.Sequential(
            nn.Conv2d(1, 32, 5, padding=2),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.Conv2d(32, 32, 5, padding=2),
            nn.BatchNorm2d(32),
            nn.ReLU()
        )

        # íŠ¹ì§• ì¶”ì¶œê¸°
        self.feature_extractor = nn.Sequential(
            nn.Conv2d(32, 64, 3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.MaxPool2d(2),  # 128x128

            nn.Conv2d(64, 128, 3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            nn.Conv2d(128, 128, 3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            nn.MaxPool2d(2),  # 64x64

            nn.Conv2d(128, 256, 3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(),
            nn.Conv2d(256, 256, 3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(),
            nn.MaxPool2d(2),  # 32x32

            nn.Conv2d(256, 512, 3, padding=1),
            nn.BatchNorm2d(512),
            nn.ReLU(),
            nn.AdaptiveAvgPool2d((8, 8))
        )

        # ì¸¡ì •ê°’ ì˜ˆì¸¡ê¸°
        self.measurement_predictor = nn.Sequential(
            nn.Dropout(0.5),
            nn.Linear(512 * 8 * 8, 512),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(512, 256),
            nn.ReLU(),
            nn.Linear(256, num_measurements)
        )

        # í’ˆì§ˆ í‰ê°€ê¸°
        self.quality_assessor = nn.Sequential(
            nn.Linear(512 * 8 * 8, 256),
            nn.ReLU(),
            nn.Linear(256, 64),
            nn.ReLU(),
            nn.Linear(64, 1),
            nn.Sigmoid()  # 0~1 ì‚¬ì´ì˜ í’ˆì§ˆ ì ìˆ˜
        )

    def forward(self, x):
        # ë…¸ì´ì¦ˆ ê°ì†Œ
        x = self.noise_reduction(x)

        # íŠ¹ì§• ì¶”ì¶œ
        features = self.feature_extractor(x)
        features_flat = features.view(features.size(0), -1)

        # ì¸¡ì •ê°’ ì˜ˆì¸¡
        measurements = self.measurement_predictor(features_flat)

        # ì˜ìƒ í’ˆì§ˆ í‰ê°€
        quality = self.quality_assessor(features_flat)

        return measurements, quality

# ì‹œê°„ì  ì¼ê´€ì„±ì„ ìœ„í•œ LSTM ë ˆì´ì–´
class TemporalUltrasoundNet(nn.Module):
    def __init__(self, num_measurements=4, sequence_length=10):
        super(TemporalUltrasoundNet, self).__init__()

        self.sequence_length = sequence_length

        # í”„ë ˆì„ë³„ íŠ¹ì§• ì¶”ì¶œê¸° (UltrasoundNet ê¸°ë°˜)
        self.frame_encoder = UltrasoundNet(num_measurements)

        # LSTM for temporal modeling
        self.lstm = nn.LSTM(
            input_size=512 * 8 * 8,  # UltrasoundNetì˜ feature size
            hidden_size=256,
            num_layers=2,
            batch_first=True,
            dropout=0.3
        )

        # ìµœì¢… ì¸¡ì •ê°’ ì˜ˆì¸¡ê¸°
        self.temporal_predictor = nn.Sequential(
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Linear(128, num_measurements)
        )

        # ì›€ì§ì„ ë¶„ì„ê¸°
        self.motion_analyzer = nn.Sequential(
            nn.Linear(256, 64),
            nn.ReLU(),
            nn.Linear(64, 3)  # x, y ë°©í–¥ ì›€ì§ì„ + íšŒì „
        )

    def forward(self, x_sequence):
        batch_size, seq_len, channels, height, width = x_sequence.shape

        # ê° í”„ë ˆì„ë³„ë¡œ íŠ¹ì§• ì¶”ì¶œ
        frame_features = []
        frame_measurements = []
        frame_qualities = []

        for t in range(seq_len):
            frame = x_sequence[:, t]  # [batch_size, channels, height, width]

            # UltrasoundNetì˜ feature_extractorë§Œ ì‚¬ìš©
            noise_reduced = self.frame_encoder.noise_reduction(frame)
            features = self.frame_encoder.feature_extractor(noise_reduced)
            features_flat = features.view(batch_size, -1)

            measurements, quality = self.frame_encoder.measurement_predictor(features_flat), \
                                   self.frame_encoder.quality_assessor(features_flat)

            frame_features.append(features_flat)
            frame_measurements.append(measurements)
            frame_qualities.append(quality)

        # ì‹œí€€ìŠ¤ í˜•íƒœë¡œ ë³€í™˜
        feature_sequence = torch.stack(frame_features, dim=1)  # [batch, seq_len, features]

        # LSTMì„ í†µí•œ ì‹œê°„ì  ëª¨ë¸ë§
        lstm_out, (hidden, cell) = self.lstm(feature_sequence)

        # ë§ˆì§€ë§‰ ì‹œì ì˜ ì¶œë ¥ ì‚¬ìš©
        final_temporal_features = lstm_out[:, -1]  # [batch, hidden_size]

        # ìµœì¢… ì˜ˆì¸¡
        temporal_measurements = self.temporal_predictor(final_temporal_features)
        motion_analysis = self.motion_analyzer(final_temporal_features)

        # ê°œë³„ í”„ë ˆì„ ê²°ê³¼ë“¤ë„ ë°˜í™˜
        individual_measurements = torch.stack(frame_measurements, dim=1)
        individual_qualities = torch.stack(frame_qualities, dim=1)

        return {
            'temporal_measurements': temporal_measurements,
            'individual_measurements': individual_measurements,
            'individual_qualities': individual_qualities,
            'motion_analysis': motion_analysis
        }

def train_ultrasound_analysis(dataset_type='cardiac_echo', num_epochs=50, batch_size=16, lr=0.001):
    """
    ì´ˆìŒíŒŒ ë¶„ì„ ëª¨ë¸ í›ˆë ¨

    Args:
        dataset_type: ì´ˆìŒíŒŒ ë°ì´í„°ì…‹ íƒ€ì…
        num_epochs: í›ˆë ¨ ì—í¬í¬ ìˆ˜
        batch_size: ë°°ì¹˜ í¬ê¸°
        lr: í•™ìŠµë¥ 
    """

    # ë¡œê±° ì„¤ì •
    logger = create_logger_for_medical_modalities('ultrasound_analysis', dataset_type)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    logger.log(f"Using device: {device}")

    # ë°ì´í„°ì…‹ ì¤€ë¹„
    dataset = UltrasoundDataset(data_type=dataset_type)
    train_size = int(0.8 * len(dataset))
    val_size = len(dataset) - train_size
    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])

    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)

    # ëª¨ë¸ ë° ì†ì‹¤ í•¨ìˆ˜ ì„¤ì •
    num_measurements = len(dataset.measurements[0])
    model = UltrasoundNet(num_measurements=num_measurements).to(device)

    criterion_measurement = nn.MSELoss()
    criterion_quality = nn.BCELoss()

    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.7)

    # í›ˆë ¨ ë©”íŠ¸ë¦­ ì €ì¥
    train_losses = []
    val_losses = []
    measurement_accuracies = []

    logger.log("Starting ultrasound analysis training...")

    for epoch in range(num_epochs):
        # í›ˆë ¨ ë‹¨ê³„
        model.train()
        running_loss = 0.0

        for batch_idx, (images, measurements, _) in enumerate(train_loader):
            images, measurements = images.to(device), measurements.to(device)

            optimizer.zero_grad()

            # ìˆœì „íŒŒ
            pred_measurements, pred_quality = model(images)

            # í’ˆì§ˆ ì ìˆ˜ ìƒì„± (ì¸¡ì •ê°’ì˜ ì •í™•ë„ì— ê¸°ë°˜)
            measurement_error = torch.abs(pred_measurements - measurements).mean(dim=1)
            quality_targets = torch.exp(-measurement_error * 2).to(device)  # ì—ëŸ¬ê°€ ë‚®ì„ìˆ˜ë¡ ë†’ì€ í’ˆì§ˆ

            # ì†ì‹¤ ê³„ì‚°
            loss_measurement = criterion_measurement(pred_measurements, measurements)
            loss_quality = criterion_quality(pred_quality.squeeze(), quality_targets)

            total_loss = loss_measurement + 0.3 * loss_quality

            total_loss.backward()
            optimizer.step()

            running_loss += total_loss.item()

            if batch_idx % 20 == 0:
                logger.log(f'Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx}/{len(train_loader)}], '
                          f'Loss: {total_loss.item():.4f}')

        # ê²€ì¦ ë‹¨ê³„
        model.eval()
        val_loss = 0.0
        total_measurement_error = 0.0

        with torch.no_grad():
            for images, measurements, _ in val_loader:
                images, measurements = images.to(device), measurements.to(device)

                pred_measurements, pred_quality = model(images)

                measurement_error = torch.abs(pred_measurements - measurements).mean(dim=1)
                quality_targets = torch.exp(-measurement_error * 2).to(device)

                loss_measurement = criterion_measurement(pred_measurements, measurements)
                loss_quality = criterion_quality(pred_quality.squeeze(), quality_targets)
                total_loss = loss_measurement + 0.3 * loss_quality

                val_loss += total_loss.item()
                total_measurement_error += torch.abs(pred_measurements - measurements).mean().item()

        # ë©”íŠ¸ë¦­ ê³„ì‚°
        avg_train_loss = running_loss / len(train_loader)
        avg_val_loss = val_loss / len(val_loader)
        avg_measurement_accuracy = 1.0 - (total_measurement_error / len(val_loader)) / 100.0

        train_losses.append(avg_train_loss)
        val_losses.append(avg_val_loss)
        measurement_accuracies.append(avg_measurement_accuracy)

        logger.log(f'Epoch [{epoch+1}/{num_epochs}]')
        logger.log(f'Train Loss: {avg_train_loss:.4f}')
        logger.log(f'Val Loss: {avg_val_loss:.4f}')
        logger.log(f'Measurement Accuracy: {avg_measurement_accuracy:.4f}')

        # ìŠ¤ì¼€ì¤„ëŸ¬ ì—…ë°ì´íŠ¸
        scheduler.step(avg_val_loss)

        # ë©”íŠ¸ë¦­ ì €ì¥
        logger.save_metrics({
            'epoch': epoch + 1,
            'train_loss': avg_train_loss,
            'val_loss': avg_val_loss,
            'measurement_accuracy': avg_measurement_accuracy,
        })

        # ì¤‘ê°„ ê²°ê³¼ ì €ì¥ (ë§¤ 10 ì—í¬í¬)
        if (epoch + 1) % 10 == 0:
            # ìƒ˜í”Œ ì˜ˆì¸¡ ë° ì‹œê°í™”
            model.eval()
            with torch.no_grad():
                sample_images, sample_measurements, sample_metadata = next(iter(val_loader))
                sample_images = sample_images[:4].to(device)
                sample_measurements = sample_measurements[:4]

                pred_measurements, pred_quality = model(sample_images)

                # ì‹œê°í™”ë¥¼ ìœ„í•œ ì´ë¯¸ì§€ ì¤€ë¹„
                vis_images = []
                for i in range(len(sample_images)):
                    # ì›ë³¸ ì´ë¯¸ì§€
                    img = sample_images[i].cpu().numpy().squeeze()
                    img = (img + 1) / 2  # [-1, 1] -> [0, 1]

                    vis_images.append(img)

                logger.save_image_grid(vis_images,
                                     f'ultrasound_analysis_epoch_{epoch+1}.png',
                                     titles=[f'Sample {i+1}' for i in range(len(vis_images))],
                                     nrow=2)

    # ìµœì¢… ëª¨ë¸ ì €ì¥
    logger.save_model(model, "ultrasound_analysis_final",
                     optimizer=optimizer, epoch=num_epochs,
                     config={'dataset_type': dataset_type, 'num_epochs': num_epochs})

    # í›ˆë ¨ ê³¡ì„  ì €ì¥
    plt.figure(figsize=(15, 5))

    plt.subplot(1, 3, 1)
    plt.plot(train_losses, label='Train Loss')
    plt.plot(val_losses, label='Validation Loss')
    plt.title('Ultrasound Analysis Training Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True)

    plt.subplot(1, 3, 2)
    plt.plot(measurement_accuracies)
    plt.title('Measurement Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.grid(True)

    plt.subplot(1, 3, 3)
    # ë§ˆì§€ë§‰ ë°°ì¹˜ì˜ ì˜ˆì¸¡ vs ì‹¤ì œ ë¹„êµ
    if dataset_type == 'cardiac_echo':
        measurement_names = ['EF', 'EDV', 'Septal Thick', 'Wall Motion']
    elif dataset_type == 'obstetric':
        measurement_names = ['BPD', 'HC', 'AC', 'FL']
    else:
        measurement_names = [f'Measure {i+1}' for i in range(num_measurements)]

    actual = sample_measurements[0].numpy()
    predicted = pred_measurements[0].cpu().numpy()

    x_pos = np.arange(len(measurement_names))
    width = 0.35

    plt.bar(x_pos - width/2, actual, width, label='Actual', alpha=0.7)
    plt.bar(x_pos + width/2, predicted, width, label='Predicted', alpha=0.7)

    plt.title('Measurement Comparison (Sample)')
    plt.xlabel('Measurements')
    plt.ylabel('Values')
    plt.xticks(x_pos, measurement_names, rotation=45)
    plt.legend()
    plt.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig(os.path.join(logger.dirs['plots'], 'ultrasound_analysis_results.png'),
                dpi=150, bbox_inches='tight')
    plt.close()

    logger.log("Ultrasound analysis training completed successfully!")
    logger.log(f"Final measurement accuracy: {measurement_accuracies[-1]:.4f}")
    logger.log(f"Results saved in: {logger.dirs['base']}")

    return model, logger.dirs['base']

if __name__ == "__main__":
    print("ğŸ”Š ì´ˆìŒíŒŒ(Ultrasound) ì˜ë£Œì˜ìƒ ë¶„ì„")
    print("=" * 60)

    # í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •
    config = {
        'dataset_type': 'cardiac_echo',
        'num_epochs': 5,  # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ 5ë¡œ ì„¤ì •
        'batch_size': 8,
        'lr': 0.001
    }

    print(f"Dataset: {config['dataset_type']}")
    print(f"Epochs: {config['num_epochs']}")
    print(f"Batch size: {config['batch_size']}")
    print(f"Learning rate: {config['lr']}")
    print()

    try:
        model, results_dir = train_ultrasound_analysis(
            dataset_type=config['dataset_type'],
            num_epochs=config['num_epochs'],
            batch_size=config['batch_size'],
            lr=config['lr']
        )

        print("\nâœ… Ultrasound analysis training completed successfully!")
        print(f"ğŸ“ Results saved to: {results_dir}")

        print("\nğŸ“Š Generated files include:")
        print("- images/: Ultrasound analysis visualizations")
        print("- models/: Trained ultrasound analysis model")
        print("- logs/: Training logs and configuration")
        print("- plots/: Training curves and measurement comparisons")
        print("- metrics/: Training metrics in JSON format")

    except Exception as e:
        print(f"\nâŒ Error during ultrasound analysis training: {str(e)}")
        import traceback
        traceback.print_exc()