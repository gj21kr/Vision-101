#!/usr/bin/env python3
"""
OCT (Optical Coherence Tomography) ì˜ë£Œì˜ìƒ ë¶„ì„
OCTëŠ” ë§ë§‰ì˜ ì¸µë³„ êµ¬ì¡°ë¥¼ ë§ˆì´í¬ë¡œë¯¸í„° ë‹¨ìœ„ë¡œ ë¶„ì„í•˜ëŠ” ë¹„ì¹¨ìŠµ ì˜ìƒê¸°ë²•ì…ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
- ë§ë§‰ì¸µ ë¶„í•  (Layer Segmentation)
- ë³‘ë³€ ê²€ì¶œ (Lesion Detection)
- ë§ë§‰ ë‘ê»˜ ì¸¡ì • (Thickness Analysis)
- ë“œë£¨ì   ê²€ì¶œ (Drusen Detection)
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torchvision.transforms as transforms
from torch.utils.data import Dataset, DataLoader
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import os
import sys
sys.path.append('/workspace/Vision-101')
from result_logger import create_logger_for_medical_modalities

# OCT ì „ìš© ë°ì´í„°ë¡œë”
class OCTDataset(Dataset):
    def __init__(self, data_type='retinal_oct', transform=None):
        """
        OCT ë°ì´í„°ì…‹ ë¡œë”

        Args:
            data_type: 'retinal_oct', 'macular_oct', 'optic_disc_oct'
            transform: ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        """
        self.data_type = data_type
        self.transform = transform or transforms.Compose([
            transforms.Resize((512, 512)),
            transforms.Grayscale(num_output_channels=1),
            transforms.ToTensor(),
            transforms.Normalize([0.5], [0.5])
        ])

        # í•©ì„± OCT ë°ì´í„° ìƒì„±
        self.images, self.labels = self._generate_synthetic_oct_data()

    def _generate_synthetic_oct_data(self):
        """í•©ì„± OCT ë°ì´í„° ìƒì„±"""
        images = []
        labels = []

        for i in range(1000):
            # OCT íŠ¹ì„±ì„ ë°˜ì˜í•œ í•©ì„± ì´ë¯¸ì§€ ìƒì„±
            oct_image = self._create_synthetic_oct(i)

            # ë³‘ë³€ ë¼ë²¨ ìƒì„± (0: ì •ìƒ, 1: AMD, 2: DME, 3: CNV)
            label = np.random.choice([0, 1, 2, 3], p=[0.4, 0.2, 0.2, 0.2])

            images.append(oct_image)
            labels.append(label)

        return images, labels

    def _create_synthetic_oct(self, seed):
        """OCT íŠ¹ì„±ì„ ë°˜ì˜í•œ í•©ì„± ì´ë¯¸ì§€ ìƒì„±"""
        np.random.seed(seed)

        # ê¸°ë³¸ ë§ë§‰ êµ¬ì¡° ìƒì„±
        image = np.zeros((512, 512))

        # ë§ë§‰ ì¸µ êµ¬ì¡° ì‹œë®¬ë ˆì´ì…˜
        for layer in range(10):  # 10ê°œ ë§ë§‰ì¸µ
            y_pos = 50 + layer * 40
            thickness = np.random.uniform(3, 8)

            # ê° ì¸µì˜ ê°•ë„ íŒ¨í„´
            for x in range(512):
                noise = np.random.normal(0, 0.1)
                intensity = 0.3 + layer * 0.05 + noise

                for dy in range(int(thickness)):
                    if y_pos + dy < 512:
                        image[int(y_pos + dy), x] = intensity

        # í˜ˆê´€ êµ¬ì¡° ì¶”ê°€
        for _ in range(5):
            start_x = np.random.randint(0, 512)
            start_y = np.random.randint(100, 400)

            for t in range(100):
                x = start_x + int(t * 0.5 + np.random.normal(0, 2))
                y = start_y + int(np.sin(t * 0.1) * 10 + np.random.normal(0, 1))

                if 0 <= x < 512 and 0 <= y < 512:
                    image[y, x] = 0.8

        # ì •ê·œí™”
        image = np.clip(image, 0, 1)
        return (image * 255).astype(np.uint8)

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        image = Image.fromarray(self.images[idx])
        if self.transform:
            image = self.transform(image)

        label = torch.tensor(self.labels[idx], dtype=torch.long)
        return image, label

# OCT ë¶„ì„ìš© ë„¤íŠ¸ì›Œí¬
class OCTAnalysisNet(nn.Module):
    def __init__(self, num_classes=4):
        super(OCTAnalysisNet, self).__init__()

        # ë§ë§‰ì¸µ íŠ¹ì§• ì¶”ì¶œê¸°
        self.layer_extractor = nn.Sequential(
            nn.Conv2d(1, 64, 3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.Conv2d(64, 64, 3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.MaxPool2d(2)  # 256x256
        )

        # êµ¬ì¡°ì  íŠ¹ì§• ë¶„ì„ê¸°
        self.structure_analyzer = nn.Sequential(
            nn.Conv2d(64, 128, 3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            nn.Conv2d(128, 128, 3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            nn.MaxPool2d(2)  # 128x128
        )

        # ë³‘ë³€ ê²€ì¶œê¸°
        self.lesion_detector = nn.Sequential(
            nn.Conv2d(128, 256, 3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(),
            nn.Conv2d(256, 256, 3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(),
            nn.MaxPool2d(2),  # 64x64

            nn.Conv2d(256, 512, 3, padding=1),
            nn.BatchNorm2d(512),
            nn.ReLU(),
            nn.AdaptiveAvgPool2d((4, 4))
        )

        # ë¶„ë¥˜ê¸°
        self.classifier = nn.Sequential(
            nn.Dropout(0.5),
            nn.Linear(512 * 4 * 4, 512),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(512, num_classes)
        )

        # íšŒê·€ê¸° (ë‘ê»˜ ì¸¡ì •)
        self.thickness_regressor = nn.Sequential(
            nn.Linear(512 * 4 * 4, 256),
            nn.ReLU(),
            nn.Linear(256, 10)  # 10ê°œ ë§ë§‰ì¸µ ë‘ê»˜
        )

    def forward(self, x):
        # íŠ¹ì§• ì¶”ì¶œ
        layer_features = self.layer_extractor(x)
        structure_features = self.structure_analyzer(layer_features)
        lesion_features = self.lesion_detector(structure_features)

        # í‰í™œí™”
        features = lesion_features.view(lesion_features.size(0), -1)

        # ë¶„ë¥˜ ë° íšŒê·€ ì¶œë ¥
        classification = self.classifier(features)
        thickness = self.thickness_regressor(features)

        return classification, thickness

# ë§ë§‰ì¸µ ë¶„í•  ë„¤íŠ¸ì›Œí¬
class RetinalLayerSegmentation(nn.Module):
    def __init__(self, num_layers=10):
        super(RetinalLayerSegmentation, self).__init__()

        # U-Net ê¸°ë°˜ ì•„í‚¤í…ì²˜
        self.encoder1 = self._make_encoder_block(1, 64)
        self.encoder2 = self._make_encoder_block(64, 128)
        self.encoder3 = self._make_encoder_block(128, 256)
        self.encoder4 = self._make_encoder_block(256, 512)

        self.center = self._make_encoder_block(512, 1024)

        self.decoder4 = self._make_decoder_block(1024, 512)
        self.decoder3 = self._make_decoder_block(1024, 256)  # 512 + 512 from skip
        self.decoder2 = self._make_decoder_block(512, 128)   # 256 + 256 from skip
        self.decoder1 = self._make_decoder_block(256, 64)    # 128 + 128 from skip

        self.final = nn.Conv2d(128, num_layers, 1)  # 64 + 64 from skip

    def _make_encoder_block(self, in_channels, out_channels):
        return nn.Sequential(
            nn.Conv2d(in_channels, out_channels, 3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, 3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )

    def _make_decoder_block(self, in_channels, out_channels):
        return nn.Sequential(
            nn.Conv2d(in_channels, out_channels, 3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, 3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )

    def forward(self, x):
        # ì¸ì½”ë”
        enc1 = self.encoder1(x)
        enc2 = self.encoder2(F.max_pool2d(enc1, 2))
        enc3 = self.encoder3(F.max_pool2d(enc2, 2))
        enc4 = self.encoder4(F.max_pool2d(enc3, 2))

        center = self.center(F.max_pool2d(enc4, 2))

        # ë””ì½”ë”
        dec4 = self.decoder4(F.interpolate(center, scale_factor=2))
        dec4 = torch.cat([dec4, enc4], dim=1)

        dec3 = self.decoder3(F.interpolate(dec4, scale_factor=2))
        dec3 = torch.cat([dec3, enc3], dim=1)

        dec2 = self.decoder2(F.interpolate(dec3, scale_factor=2))
        dec2 = torch.cat([dec2, enc2], dim=1)

        dec1 = self.decoder1(F.interpolate(dec2, scale_factor=2))
        dec1 = torch.cat([dec1, enc1], dim=1)

        return self.final(dec1)

def train_oct_analysis(dataset_type='retinal_oct', num_epochs=50, batch_size=32, lr=0.001):
    """
    OCT ë¶„ì„ ëª¨ë¸ í›ˆë ¨

    Args:
        dataset_type: OCT ë°ì´í„°ì…‹ íƒ€ì…
        num_epochs: í›ˆë ¨ ì—í¬í¬ ìˆ˜
        batch_size: ë°°ì¹˜ í¬ê¸°
        lr: í•™ìŠµë¥ 
    """

    # ë¡œê±° ì„¤ì •
    logger = create_logger_for_medical_modalities('oct_analysis', dataset_type)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    logger.log(f"Using device: {device}")

    # ë°ì´í„°ì…‹ ì¤€ë¹„
    dataset = OCTDataset(data_type=dataset_type)
    train_size = int(0.8 * len(dataset))
    val_size = len(dataset) - train_size
    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])

    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)

    # ëª¨ë¸ ë° ì†ì‹¤ í•¨ìˆ˜ ì„¤ì •
    model = OCTAnalysisNet(num_classes=4).to(device)
    segmentation_model = RetinalLayerSegmentation(num_layers=10).to(device)

    criterion_class = nn.CrossEntropyLoss()
    criterion_thickness = nn.MSELoss()
    criterion_seg = nn.CrossEntropyLoss()

    optimizer = optim.Adam(list(model.parameters()) + list(segmentation_model.parameters()), lr=lr)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.5)

    # í›ˆë ¨ ë©”íŠ¸ë¦­ ì €ì¥
    train_losses = []
    val_losses = []
    val_accuracies = []

    logger.log("Starting OCT analysis training...")

    for epoch in range(num_epochs):
        # í›ˆë ¨ ë‹¨ê³„
        model.train()
        segmentation_model.train()
        running_loss = 0.0

        for batch_idx, (data, targets) in enumerate(train_loader):
            data, targets = data.to(device), targets.to(device)

            optimizer.zero_grad()

            # ë¶„ë¥˜ ë° ë‘ê»˜ ì˜ˆì¸¡
            class_output, thickness_output = model(data)

            # ë¶„í•  ì˜ˆì¸¡ (í•©ì„± ë ˆì´ë¸” ìƒì„±)
            seg_targets = torch.randint(0, 10, (data.size(0), data.size(2), data.size(3))).to(device)
            seg_output = segmentation_model(data)

            # ì†ì‹¤ ê³„ì‚°
            loss_class = criterion_class(class_output, targets)

            # ë‘ê»˜ íƒ€ê²Ÿ ìƒì„± (ì •ìƒí™”ëœ ê°’)
            thickness_targets = torch.randn(data.size(0), 10).to(device) * 0.1 + 0.3
            loss_thickness = criterion_thickness(thickness_output, thickness_targets)

            loss_seg = criterion_seg(seg_output, seg_targets)

            # ì´ ì†ì‹¤
            total_loss = loss_class + 0.5 * loss_thickness + 0.3 * loss_seg

            total_loss.backward()
            optimizer.step()

            running_loss += total_loss.item()

            if batch_idx % 10 == 0:
                logger.log(f'Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx}/{len(train_loader)}], '
                          f'Loss: {total_loss.item():.4f}')

        # ê²€ì¦ ë‹¨ê³„
        model.eval()
        segmentation_model.eval()
        val_loss = 0.0
        correct = 0
        total = 0

        with torch.no_grad():
            for data, targets in val_loader:
                data, targets = data.to(device), targets.to(device)

                class_output, thickness_output = model(data)
                seg_targets = torch.randint(0, 10, (data.size(0), data.size(2), data.size(3))).to(device)
                seg_output = segmentation_model(data)

                loss_class = criterion_class(class_output, targets)
                thickness_targets = torch.randn(data.size(0), 10).to(device) * 0.1 + 0.3
                loss_thickness = criterion_thickness(thickness_output, thickness_targets)
                loss_seg = criterion_seg(seg_output, seg_targets)

                total_loss = loss_class + 0.5 * loss_thickness + 0.3 * loss_seg
                val_loss += total_loss.item()

                _, predicted = torch.max(class_output.data, 1)
                total += targets.size(0)
                correct += (predicted == targets).sum().item()

        # ë©”íŠ¸ë¦­ ê³„ì‚°
        avg_train_loss = running_loss / len(train_loader)
        avg_val_loss = val_loss / len(val_loader)
        val_accuracy = 100 * correct / total

        train_losses.append(avg_train_loss)
        val_losses.append(avg_val_loss)
        val_accuracies.append(val_accuracy)

        logger.log(f'Epoch [{epoch+1}/{num_epochs}]')
        logger.log(f'Train Loss: {avg_train_loss:.4f}')
        logger.log(f'Val Loss: {avg_val_loss:.4f}')
        logger.log(f'Val Accuracy: {val_accuracy:.2f}%')

        # í•™ìŠµë¥  ì¡°ì •
        scheduler.step(avg_val_loss)

        # ë©”íŠ¸ë¦­ ì €ì¥
        logger.save_metrics({
            'epoch': epoch + 1,
            'train_loss': avg_train_loss,
            'val_loss': avg_val_loss,
            'val_accuracy': val_accuracy,
        })

        # ì¤‘ê°„ ê²°ê³¼ ì €ì¥ (ë§¤ 10 ì—í¬í¬)
        if (epoch + 1) % 10 == 0:
            # ìƒ˜í”Œ ì´ë¯¸ì§€ ìƒì„± ë° ì €ì¥
            model.eval()
            segmentation_model.eval()
            with torch.no_grad():
                sample_data, sample_targets = next(iter(val_loader))
                sample_data = sample_data[:8].to(device)

                class_pred, thickness_pred = model(sample_data)
                seg_pred = segmentation_model(sample_data)

                # ë¶„í•  ê²°ê³¼ ì‹œê°í™”
                sample_images = sample_data.cpu().numpy()
                seg_results = torch.argmax(seg_pred, dim=1).cpu().numpy()

                # ì´ë¯¸ì§€ ì €ì¥ì„ ìœ„í•œ ë°°ì—´ ì¤€ë¹„
                visualization_images = []
                for i in range(min(4, len(sample_images))):
                    original = sample_images[i, 0]  # (H, W)
                    segmentation = seg_results[i]   # (H, W)

                    # ì •ê·œí™”
                    original = (original + 1) / 2  # [-1, 1] -> [0, 1]
                    segmentation = segmentation / 9.0  # [0, 9] -> [0, 1]

                    visualization_images.extend([original, segmentation])

                logger.save_image_grid(visualization_images,
                                     f'oct_analysis_epoch_{epoch+1}.png',
                                     titles=['Original', 'Layer Seg'] * 4,
                                     nrow=2)

    # ìµœì¢… ëª¨ë¸ ì €ì¥
    logger.save_model(model, "oct_analysis_final",
                     optimizer=optimizer, epoch=num_epochs,
                     config={'dataset_type': dataset_type, 'num_epochs': num_epochs})

    logger.save_model(segmentation_model, "oct_segmentation_final",
                     optimizer=optimizer, epoch=num_epochs,
                     config={'num_layers': 10})

    # í›ˆë ¨ ê³¡ì„  ì €ì¥
    plt.figure(figsize=(15, 5))

    plt.subplot(1, 3, 1)
    plt.plot(train_losses, label='Train Loss')
    plt.plot(val_losses, label='Validation Loss')
    plt.title('Training and Validation Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True)

    plt.subplot(1, 3, 2)
    plt.plot(val_accuracies)
    plt.title('Validation Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy (%)')
    plt.grid(True)

    plt.subplot(1, 3, 3)
    # ë‘ê»˜ ë¶„ì„ ê²°ê³¼ ì‹œê°í™” (ë§ˆì§€ë§‰ ë°°ì¹˜)
    thickness_sample = thickness_pred[:4].cpu().numpy()
    layers = ['NFL', 'GCL', 'IPL', 'INL', 'OPL', 'ONL', 'ELM', 'IS/OS', 'RPE', 'Choroid']
    x_pos = np.arange(len(layers))

    for i in range(4):
        plt.plot(x_pos, thickness_sample[i], label=f'Sample {i+1}')

    plt.title('Retinal Layer Thickness Analysis')
    plt.xlabel('Retinal Layers')
    plt.ylabel('Thickness (normalized)')
    plt.xticks(x_pos, layers, rotation=45)
    plt.legend()
    plt.grid(True)

    plt.tight_layout()
    plt.savefig(os.path.join(logger.dirs['plots'], 'oct_training_results.png'),
                dpi=150, bbox_inches='tight')
    plt.close()

    logger.log("OCT analysis training completed successfully!")
    logger.log(f"Final validation accuracy: {val_accuracies[-1]:.2f}%")
    logger.log(f"Results saved in: {logger.dirs['base']}")

    return model, segmentation_model, logger.dirs['base']

if __name__ == "__main__":
    print("ğŸ”¬ OCT (Optical Coherence Tomography) ì˜ë£Œì˜ìƒ ë¶„ì„")
    print("=" * 60)

    # í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •
    config = {
        'dataset_type': 'retinal_oct',
        'num_epochs': 5,  # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ 5ë¡œ ì„¤ì •
        'batch_size': 16,
        'lr': 0.001
    }

    print(f"Dataset: {config['dataset_type']}")
    print(f"Epochs: {config['num_epochs']}")
    print(f"Batch size: {config['batch_size']}")
    print(f"Learning rate: {config['lr']}")
    print()

    try:
        model, seg_model, results_dir = train_oct_analysis(
            dataset_type=config['dataset_type'],
            num_epochs=config['num_epochs'],
            batch_size=config['batch_size'],
            lr=config['lr']
        )

        print("\nâœ… OCT analysis training completed successfully!")
        print(f"ğŸ“ Results saved to: {results_dir}")

        print("\nğŸ“Š Generated files include:")
        print("- images/: OCT analysis visualizations and layer segmentation")
        print("- models/: Trained OCT analysis and segmentation models")
        print("- logs/: Training logs and configuration")
        print("- plots/: Training curves and thickness analysis")
        print("- metrics/: Training metrics in JSON format")

    except Exception as e:
        print(f"\nâŒ Error during OCT analysis training: {str(e)}")
        import traceback
        traceback.print_exc()